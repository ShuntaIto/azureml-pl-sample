{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1621437808549
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from azureml.core import Workspace\n",
        "from azureml.core import Environment\n",
        "from azureml.core import ScriptRunConfig, Experiment\n",
        "from azureml.widgets import RunDetails\n",
        "from azureml.core import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1621437809680
        }
      },
      "outputs": [],
      "source": [
        "# AMLワークスペースへの接続\n",
        "ws = Workspace.from_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1621437809904
        }
      },
      "outputs": [],
      "source": [
        "# training script\n",
        "source_dir = \"train\"\n",
        "script_name = \"train_bert.py\"\n",
        "\n",
        "# environment file\n",
        "environment_file = os.path.join(\"train\", \"train_bert_env.yml\")\n",
        "\n",
        "# azure ml settings\n",
        "environment_name = \"pl-env-lang\"\n",
        "experiment_name = \"bert-livedoor\"\n",
        "compute_name = \"shuit-gpu-ins02\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1621437810055
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n"
          ]
        }
      ],
      "source": [
        "# 学習環境作成、初回のみ長時間\n",
        "env = Environment.from_conda_specification(environment_name, environment_file)\n",
        "\n",
        "env.docker.enabled = True\n",
        "env.docker.base_image = (\n",
        "    \"mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.0.3-cudnn8-ubuntu18.04\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1621437810224
        }
      },
      "outputs": [],
      "source": [
        "# 学習設定\n",
        "src = ScriptRunConfig(\n",
        "    source_directory=source_dir,\n",
        "    script=script_name,\n",
        "    arguments=[\"--batch_size\", 256, \"--max_epochs\", 20, \"--gpus\", 1],\n",
        "    compute_target=compute_name,\n",
        "    environment=env,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1621438249073
        },
        "tags": [
          "outputPrepend"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RunId: bert-livedoor_1641985249_7c0fba4c\n",
            "Web View: https://ml.azure.com/runs/bert-livedoor_1641985249_7c0fba4c?wsid=/subscriptions/902f236f-44df-463a-a5cb-1516ab2a9cd2/resourcegroups/shuit-common/workspaces/shuit-ml-workspace&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
            "\n",
            "Streaming azureml-logs/55_azureml-execution-tvmps_a46938a6323b6ff5d91a38cb3c6b0b117014b72f62bcb10efd1e5b630f41cd0e_d.txt\n",
            "========================================================================================================================\n",
            "\n",
            "2022-01-12T11:01:04Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=619058 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
            "2022-01-12T11:01:04Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/mounts/workspaceblobstore -- stdout/stderr: \n",
            "2022-01-12T11:01:04Z Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\n",
            ". Please ignore this if the GPUs don't utilize NVIDIA® NVLink® switches.\n",
            "2022-01-12T11:01:04Z Starting output-watcher...\n",
            "2022-01-12T11:01:04Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
            "2022-01-12T11:01:05Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
            "2022-01-12T11:01:05Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
            ">>>   \n",
            ">>>   \n",
            "Login Succeeded\n",
            "Using default tag: latest\n",
            "latest: Pulling from azureml/azureml_8a43a880a768bd8cbce04813af05a022\n",
            "Digest: sha256:cca4db841e30a9b9cb8244df0e6309075dd58200d0347e0f6c9a88e3ad82c4e0\n",
            "Status: Image is up to date for shuitmlcr.azurecr.io/azureml/azureml_8a43a880a768bd8cbce04813af05a022:latest\n",
            "shuitmlcr.azurecr.io/azureml/azureml_8a43a880a768bd8cbce04813af05a022:latest\n",
            "2022-01-12T11:01:06Z Check if container bert-livedoor_1641985249_7c0fba4c already exist exited with 0, \n",
            "\n",
            "ce7407daa8facb5510a1abbb1339393c9a3456ce9758419e0746b1afdf638b93\n",
            "2022-01-12T11:01:06Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
            "2022-01-12T11:01:06Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-8860a97aafafe2b8177c429f4dc07438-4b2819a1496f0290-01 -sshRequired=false] \n",
            "2022/01/12 11:01:06 Got JobInfoJson from env\n",
            "2022/01/12 11:01:06 Starting App Insight Logger for task:  containerSetup\n",
            "2022/01/12 11:01:06 Version: 3.0.01804.0002 Branch: 2021-12-12 Commit: 1704a55\n",
            "2022/01/12 11:01:06 Entered ContainerSetupTask - Preparing infiniband\n",
            "2022/01/12 11:01:06 Starting infiniband setup\n",
            "2022/01/12 11:01:06 Python Version found is Python 3.8.12\n",
            "\n",
            "2022/01/12 11:01:06 Returning Python Version as 3.8\n",
            "2022-01-12T11:01:06Z VMSize: standard_nc6s_v3, Host: ubuntu-18, Container: ubuntu-18.04\n",
            "2022/01/12 11:01:06 VMSize: standard_nc6s_v3, Host: ubuntu-18, Container: ubuntu-18.04\n",
            "2022/01/12 11:01:06 VMSize: standard_nc6s_v3, Host: ubuntu-18, Container: ubuntu-18.04\n",
            "2022/01/12 11:01:06 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
            "2022-01-12T11:01:06Z Not setting up Infiniband in Container\n",
            "2022/01/12 11:01:06 Not setting up Infiniband in Container\n",
            "2022/01/12 11:01:06 Not setting up Infiniband in Container\n",
            "2022/01/12 11:01:06 Python Version found is Python 3.8.12\n",
            "\n",
            "2022/01/12 11:01:06 Returning Python Version as 3.8\n",
            "2022/01/12 11:01:06 sshd inside container not required for job, skipping setup.\n",
            "2022/01/12 11:01:07 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n",
            "2022/01/12 11:01:07 App Insight Client has already been closed\n",
            "2022/01/12 11:01:07 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
            "Stopped: false\n",
            "OriginalData: 1\n",
            "FilteredData: 0.\n",
            "2022-01-12T11:01:07Z Starting docker container succeeded.\n",
            "2022-01-12T11:01:11Z Job environment preparation succeeded on 10.0.0.4. Output: \n",
            ">>>   2022/01/12 11:01:04 Got JobInfoJson from env\n",
            ">>>   2022/01/12 11:01:04 Starting App Insight Logger for task:  prepareJobEnvironment\n",
            ">>>   2022/01/12 11:01:04 Version: 3.0.01804.0002 Branch: 2021-12-12 Commit: 1704a55\n",
            ">>>   2022/01/12 11:01:04 Got JobInfoJson from env\n",
            ">>>   2022/01/12 11:01:04 runtime.GOOS linux\n",
            ">>>   2022/01/12 11:01:04 Checking if '/tmp' exists\n",
            ">>>   2022/01/12 11:01:04 Reading dyanamic configs\n",
            ">>>   2022/01/12 11:01:04 Container sas url: https://baiscriptskw1prod.blob.core.windows.net/aihosttools?sv=2018-03-28&sr=c&si=aihosttoolspolicy&sig=1ER%2FbMRBr59SFS0JFkoS0yHuLB0U%2BJ54OnzMqTSrAeQ%3D\n",
            ">>>   2022/01/12 11:01:04 Starting Azsecpack installation on machine: shuit-gpu-ins02#72f988bf-86f1-41af-91ab-2d7cd011db47#902f236f-44df-463a-a5cb-1516ab2a9cd2#shuit-common#shuit-ml-workspace#shuit-gpu-ins02#tvmps_a46938a6323b6ff5d91a38cb3c6b0b117014b72f62bcb10efd1e5b630f41cd0e_d\n",
            ">>>   2022/01/12 11:01:04 Azsecpack installation directory: /mnt/batch/tasks/startup/wd/az_resource, Is Azsecpack installer on host: true. Is Azsecpack installation enabled: true,AzSecPack_RoleInstance=\"diagnosticserver-8dbfd84b8-bk7wr\"\n",
            ">>>   2022/01/12 11:01:04 Is Azsecpack enabled: true, GetDisableVsatlsscan: true\n",
            ">>>   2022/01/12 11:01:04 Start preparing environment for azsecpack installation. MachineName is shuit-gpu-ins02 \n",
            ">>>   \n",
            ">>>   2022/01/12 11:01:04 \n",
            ">>>   2022/01/12 11:01:04 \n",
            ">>>   2022/01/12 11:01:04 bypass systemd resolved\n",
            ">>>   2022/01/12 11:01:04 Cluster Subscription Id: 902f236f-44df-463a-a5cb-1516ab2a9cd2\n",
            ">>>   2022/01/12 11:01:04 Cluster Workspace Name: shuit-ml-workspace\n",
            ">>>   2022/01/12 11:01:04 Cluster Name: shuit-gpu-ins02\n",
            ">>>   2022/01/12 11:01:04 VMsize: standard_nc6s_v3\n",
            ">>>   2022/01/12 11:01:04 GPU Count: 1\n",
            ">>>   2022/01/12 11:01:04 Job: AZ_BATCHAI_JOB_NAME does not turn on the DetonationChamber\n",
            ">>>   2022/01/12 11:01:04 Start to getting gpu count by running nvidia-smi command\n",
            ">>>   2022/01/12 11:01:04 GPU : GPU 0: Tesla V100-PCIE-16GB (UUID: GPU-2f27c965-afb2-d04d-c547-d594321601e0)\n",
            ">>>   2022/01/12 11:01:04 GPU count found on the node: 1\n",
            ">>>   2022/01/12 11:01:04 Mellanox Inbox drivers found (implying presence of SR-IOV)?: false\n",
            ">>>   2022/01/12 11:01:04 Disabling IB for NCCL.\n",
            ">>>   2022/01/12 11:01:04 AMLComputeXDSEndpoint:  https://japaneast.cert.api.azureml.ms/xdsbatchai\n",
            ">>>   2022/01/12 11:01:04 AMLComputeXDSApiVersion:  2018-02-01\n",
            ">>>   2022/01/12 11:01:04 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/config\n",
            ">>>   2022/01/12 11:01:04 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd\n",
            ">>>   2022/01/12 11:01:04 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/shared\n",
            ">>>   2022/01/12 11:01:04 WorkingDirPath is specified. Setting env AZ_BATCHAI_JOB_WORK_DIR=$AZ_BATCHAI_JOB_TEMP/azureml/bert-livedoor_1641985249_7c0fba4c\n",
            ">>>   2022/01/12 11:01:04 From the policy service, the filtering patterns is: , data store is \n",
            ">>>   2022/01/12 11:01:04 Mounting job level file systems\n",
            ">>>   2022/01/12 11:01:04 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/mounts\n",
            ">>>   2022/01/12 11:01:04 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/config/.amlcompute.datastorecredentials\n",
            ">>>   2022/01/12 11:01:04 Datastore credentials file not found, skipping.\n",
            ">>>   2022/01/12 11:01:04 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/config/.master.runtimesastokens\n",
            ">>>   2022/01/12 11:01:04 Runtime sas tokens file not found, skipping.\n",
            ">>>   2022/01/12 11:01:04 NFS mount is not enabled\n",
            ">>>   2022/01/12 11:01:04 No Azure File Shares configured\n",
            ">>>   2022/01/12 11:01:04 Mounting blob file systems\n",
            ">>>   2022/01/12 11:01:04 Blobfuse runtime version 1.4.1\n",
            ">>>   2022/01/12 11:01:04 Mounting azureml-blobstore-dd66df3a-a31d-494f-aea3-ce360c4cb8a1 container from shuitmlstorage account at /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/mounts/workspaceblobstore\n",
            ">>>   2022/01/12 11:01:04 Error opening env file:  open /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/config/.batchai.IdentityResponder.envlist: no such file or directory\n",
            ">>>   2022/01/12 11:01:04 Using Compute Identity to authenticate Blobfuse: false.\n",
            ">>>   2022/01/12 11:01:04 Using Compute Identity to authenticate Blobfuse: false.\n",
            ">>>   2022/01/12 11:01:04 Blobfuse cache size set to 619058 MB.\n",
            ">>>   2022/01/12 11:01:04 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=619058 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
            ">>>   2022/01/12 11:01:04 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=619058 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
            ">>>   2022/01/12 11:01:04 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/mounts/workspaceblobstore -- stdout/stderr: \n",
            ">>>   2022/01/12 11:01:04 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/mounts/workspaceblobstore -- stdout/stderr: \n",
            ">>>   2022/01/12 11:01:04 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/mounts/workspaceblobstore\n",
            ">>>   2022/01/12 11:01:04 Successfully mounted azureml-blobstore-dd66df3a-a31d-494f-aea3-ce360c4cb8a1 container from shuitmlstorage account at /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/mounts/workspaceblobstore\n",
            ">>>   2022/01/12 11:01:04 Failed to created run_id directory: /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/mounts/workspaceblobstore/azureml/bert-livedoor_1641985249_7c0fba4c, due to mkdir /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/mounts/workspaceblobstore/azureml/bert-livedoor_1641985249_7c0fba4c: read-only file system\n",
            ">>>   2022/01/12 11:01:04 No unmanaged file systems configured\n",
            ">>>   2022/01/12 11:01:04 Start to getting gpu count by running nvidia-smi command\n",
            ">>>   2022/01/12 11:01:04 GPU : GPU 0: Tesla V100-PCIE-16GB (UUID: GPU-2f27c965-afb2-d04d-c547-d594321601e0)\n",
            ">>>   2022/01/12 11:01:04 Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\n",
            ">>>   . Please ignore this if the GPUs don't utilize NVIDIA® NVLink® switches.\n",
            ">>>   2022/01/12 11:01:04 Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\n",
            ">>>   . Please ignore this if the GPUs don't utilize NVIDIA® NVLink® switches.\n",
            ">>>   2022/01/12 11:01:04 WorkingDirPath is specified. Setting env AZ_BATCHAI_JOB_WORK_DIR=$AZ_BATCHAI_JOB_TEMP/azureml/bert-livedoor_1641985249_7c0fba4c\n",
            ">>>   2022/01/12 11:01:04 From the policy service, the filtering patterns is: , data store is \n",
            ">>>   2022/01/12 11:01:04 Creating working directory: /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c\n",
            ">>>   2022/01/12 11:01:04 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c\n",
            ">>>   2022/01/12 11:01:04 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c\n",
            ">>>   2022/01/12 11:01:04 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c\n",
            ">>>   2022/01/12 11:01:04 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c/azureml_compute_logs\n",
            ">>>   2022/01/12 11:01:04 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c/azureml_compute_logs/tvmps_a46938a6323b6ff5d91a38cb3c6b0b117014b72f62bcb10efd1e5b630f41cd0e_d\n",
            ">>>   2022/01/12 11:01:04 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c/azureml_compute_logs/tvmps_a46938a6323b6ff5d91a38cb3c6b0b117014b72f62bcb10efd1e5b630f41cd0e_d/55_azureml-execution-tvmps_a46938a6323b6ff5d91a38cb3c6b0b117014b72f62bcb10efd1e5b630f41cd0e_d.txt\n",
            ">>>   2022/01/12 11:01:04 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c\n",
            ">>>   2022/01/12 11:01:04 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c/azureml_compute_logs\n",
            ">>>   2022/01/12 11:01:04 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c/azureml_compute_logs\n",
            ">>>   2022/01/12 11:01:04 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c/azureml_compute_logs\n",
            ">>>   2022/01/12 11:01:04 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c/azureml_compute_logs/tvmps_a46938a6323b6ff5d91a38cb3c6b0b117014b72f62bcb10efd1e5b630f41cd0e_d\n",
            ">>>   2022/01/12 11:01:04 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c/azureml_compute_logs/tvmps_a46938a6323b6ff5d91a38cb3c6b0b117014b72f62bcb10efd1e5b630f41cd0e_d/55_azureml-execution-tvmps_a46938a6323b6ff5d91a38cb3c6b0b117014b72f62bcb10efd1e5b630f41cd0e_d.txt\n",
            ">>>   2022/01/12 11:01:04 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c/azureml_compute_logs\n",
            ">>>   2022/01/12 11:01:04 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c/logs\n",
            ">>>   2022/01/12 11:01:04 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c/outputs\n",
            ">>>   2022/01/12 11:01:04 Starting output-watcher...\n",
            ">>>   2022/01/12 11:01:04 Single file input dataset is enabled.\n",
            ">>>   2022/01/12 11:01:04 SidecarEnabled:: isDetonationChamber: false, useDockerContainer: true\n",
            ">>>   2022/01/12 11:01:04 SidecarEnabled:: AmlDatasetContextManagerConfig exists: false\n",
            ">>>   2022/01/12 11:01:04 SidecarEnabled:: sidecar not enabled\n",
            ">>>   2022/01/12 11:01:04 Start to pulling docker image: shuitmlcr.azurecr.io/azureml/azureml_8a43a880a768bd8cbce04813af05a022\n",
            ">>>   2022/01/12 11:01:04 Start pull docker image: shuitmlcr.azurecr.io\n",
            ">>>   2022/01/12 11:01:04 Getting credentials for image shuitmlcr.azurecr.io/azureml/azureml_8a43a880a768bd8cbce04813af05a022 with url shuitmlcr.azurecr.io\n",
            ">>>   2022/01/12 11:01:04 Container registry is ACR.\n",
            ">>>   2022/01/12 11:01:04 Skip getting ACR Credentials from Identity and will be getting it from EMS\n",
            ">>>   2022/01/12 11:01:04 Getting ACR Credentials from EMS for environment pl-env-lang:Autosave_2022-01-12T10:41:18Z_59883712\n",
            ">>>   2022/01/12 11:01:04 Requesting XDS for registry details.\n",
            ">>>   2022/01/12 11:01:04 Attempt 1 of http call to https://japaneast.cert.api.azureml.ms/xdsbatchai/hosttoolapi/subscriptions/902f236f-44df-463a-a5cb-1516ab2a9cd2/resourceGroups/shuit-common/workspaces/shuit-ml-workspace/clusters/shuit-gpu-ins02/nodes/tvmps_a46938a6323b6ff5d91a38cb3c6b0b117014b72f62bcb10efd1e5b630f41cd0e_d?api-version=2018-02-01\n",
            ">>>   2022/01/12 11:01:05 Got container registry details from credentials service for registry address: shuitmlcr.azurecr.io.\n",
            ">>>   2022/01/12 11:01:05 Writing ACR Details to file...\n",
            ">>>   2022/01/12 11:01:05 Copying ACR Details file to worker nodes...\n",
            ">>>   2022/01/12 11:01:05 Executing 'Copy ACR Details file' on 10.0.0.4\n",
            ">>>   2022/01/12 11:01:05 Begin executing 'Copy ACR Details file' task on Node\n",
            ">>>   2022/01/12 11:01:05 'Copy ACR Details file' task Node result: succeeded\n",
            ">>>   2022/01/12 11:01:05 Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
            ">>>   >>>   \n",
            ">>>   >>>   \n",
            ">>>   2022/01/12 11:01:05 Successfully retrieved ACR Credentials from EMS.\n",
            ">>>   2022/01/12 11:01:05 EMS returned shuitmlcr.azurecr.io for environment pl-env-lang\n",
            ">>>   2022/01/12 11:01:05 Save docker credentials for image shuitmlcr.azurecr.io/azureml/azureml_8a43a880a768bd8cbce04813af05a022 in /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/docker_login_86A68BC276742321\n",
            ">>>   2022/01/12 11:01:05 Start login to the docker registry\n",
            ">>>   2022/01/12 11:01:05 Successfully logged into the docker registry.\n",
            ">>>   2022/01/12 11:01:05 Start run pull docker image command\n",
            ">>>   2022/01/12 11:01:05 Pull docker image succeeded.\n",
            ">>>   2022/01/12 11:01:05 Removed docker config dir /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/docker_login_86A68BC276742321\n",
            ">>>   2022/01/12 11:01:05 Pull docker image time: 1.128407392s\n",
            ">>>   \n",
            ">>>   2022/01/12 11:01:05 Docker Version that this nodes use are: 20.10.11+azure-1\n",
            ">>>   \n",
            ">>>   2022/01/12 11:01:05 Start to getting gpu count by running nvidia-smi command\n",
            ">>>   2022/01/12 11:01:05 GPU : GPU 0: Tesla V100-PCIE-16GB (UUID: GPU-2f27c965-afb2-d04d-c547-d594321601e0)\n",
            ">>>   2022/01/12 11:01:05 Setting the memory limit for docker container to be 112359 MB\n",
            ">>>   2022/01/12 11:01:05 The env variable file size is 39282 bytes\n",
            ">>>   2022/01/12 11:01:05 Creating parent cgroup 'bert-livedoor_1641985249_7c0fba4c' for Containers used in Job\n",
            ">>>   2022/01/12 11:01:06 Add parent cgroup 'bert-livedoor_1641985249_7c0fba4c' to container 'bert-livedoor_1641985249_7c0fba4c'\n",
            ">>>   2022/01/12 11:01:06 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
            ">>>   2022/01/12 11:01:06 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,bert-livedoor_1641985249_7c0fba4c,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/136419c8-4466-4717-8485-2040e3584f43/job-1/bert-livedoor_164198_b70e80c2-1b5d-4c8e-a6ee-ea1d1a967f06/certs:/mnt/batch/tasks/workitems/136419c8-4466-4717-8485-2040e3584f43/job-1/bert-livedoor_164198_b70e80c2-1b5d-4c8e-a6ee-ea1d1a967f06/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,--gpus,all,-m,112359m,-v,/mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c/azureml_compute_logs,-v,/mnt/batch/tasks/workitems/136419c8-4466-4717-8485-2040e3584f43/job-1/bert-livedoor_164198_b70e80c2-1b5d-4c8e-a6ee-ea1d1a967f06/wd:/mnt/batch/tasks/workitems/136419c8-4466-4717-8485-2040e3584f43/job-1/bert-livedoor_164198_b70e80c2-1b5d-4c8e-a6ee-ea1d1a967f06/wd,-v,/mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c:/mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c,-v,/mnt/batch/tasks/shared/LS_root/shared/tracing/bert-livedoor_1641985249_7c0fba4c/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/bert-livedoor_1641985249_7c0fba4c/logs/azureml/tracing,-w,/mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/config/.batchai.envlist,-v,/config.json:/config.json,--cgroup-parent=/bert-livedoor_1641985249_7c0fba4c/,--shm-size,2g\n",
            ">>>   2022/01/12 11:01:06 the binding /mnt/batch/tasks/shared/LS_root/shared/tracing/bert-livedoor_1641985249_7c0fba4c/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/bert-livedoor_1641985249_7c0fba4c/logs/azureml/tracing is discarded as we already have /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared \n",
            ">>>   2022/01/12 11:01:06 the binding /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c:/mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c \n",
            ">>>   2022/01/12 11:01:06 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,bert-livedoor_1641985249_7c0fba4c,--gpus,all,-m,112359m,-w,/mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/config/.batchai.envlist,--cgroup-parent=/bert-livedoor_1641985249_7c0fba4c/,--shm-size,2g,-v,/config.json:/config.json,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c:/mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c,-v,/mnt/batch/tasks/workitems/136419c8-4466-4717-8485-2040e3584f43/job-1/bert-livedoor_164198_b70e80c2-1b5d-4c8e-a6ee-ea1d1a967f06/wd:/mnt/batch/tasks/workitems/136419c8-4466-4717-8485-2040e3584f43/job-1/bert-livedoor_164198_b70e80c2-1b5d-4c8e-a6ee-ea1d1a967f06/wd,-v,/mnt/batch/tasks/workitems/136419c8-4466-4717-8485-2040e3584f43/job-1/bert-livedoor_164198_b70e80c2-1b5d-4c8e-a6ee-ea1d1a967f06/certs:/mnt/batch/tasks/workitems/136419c8-4466-4717-8485-2040e3584f43/job-1/bert-livedoor_164198_b70e80c2-1b5d-4c8e-a6ee-ea1d1a967f06/certs\n",
            ">>>   2022/01/12 11:01:06 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name bert-livedoor_1641985249_7c0fba4c --gpus all -m 112359m -w /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/config/.batchai.envlist --cgroup-parent=/bert-livedoor_1641985249_7c0fba4c/ --shm-size 2g -v /config.json:/config.json -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c:/mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c -v /mnt/batch/tasks/workitems/136419c8-4466-4717-8485-2040e3584f43/job-1/bert-livedoor_164198_b70e80c2-1b5d-4c8e-a6ee-ea1d1a967f06/wd:/mnt/batch/tasks/workitems/136419c8-4466-4717-8485-2040e3584f43/job-1/bert-livedoor_164198_b70e80c2-1b5d-4c8e-a6ee-ea1d1a967f06/wd -v /mnt/batch/tasks/workitems/136419c8-4466-4717-8485-2040e3584f43/job-1/bert-livedoor_164198_b70e80c2-1b5d-4c8e-a6ee-ea1d1a967f06/certs:/mnt/batch/tasks/workitems/136419c8-4466-4717-8485-2040e3584f43/job-1/bert-livedoor_164198_b70e80c2-1b5d-4c8e-a6ee-ea1d1a967f06/certs -d -it --privileged --net=host shuitmlcr.azurecr.io/azureml/azureml_8a43a880a768bd8cbce04813af05a022\n",
            ">>>   2022/01/12 11:01:06 Check if container bert-livedoor_1641985249_7c0fba4c already exist exited with 0, \n",
            ">>>   \n",
            ">>>   2022/01/12 11:01:06 Check if container bert-livedoor_1641985249_7c0fba4c already exist exited with 0, \n",
            ">>>   \n",
            ">>>   2022/01/12 11:01:06 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
            ">>>   2022/01/12 11:01:06 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
            ">>>   2022/01/12 11:01:06 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-8860a97aafafe2b8177c429f4dc07438-4b2819a1496f0290-01 -sshRequired=false] \n",
            ">>>   2022/01/12 11:01:06 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-8860a97aafafe2b8177c429f4dc07438-4b2819a1496f0290-01 -sshRequired=false] \n",
            ">>>   2022/01/12 11:01:07 Container ssh is not required for job type.\n",
            ">>>   2022/01/12 11:01:07 Starting docker container succeeded.\n",
            ">>>   2022/01/12 11:01:07 Starting docker container succeeded.\n",
            ">>>   2022/01/12 11:01:07 Disk space after starting docker container: 629094MB\n",
            ">>>   2022/01/12 11:01:07 SidecarEnabled:: isDetonationChamber: false, useDockerContainer: true\n",
            ">>>   2022/01/12 11:01:07 SidecarEnabled:: AmlDatasetContextManagerConfig exists: false\n",
            ">>>   2022/01/12 11:01:07 SidecarEnabled:: sidecar not enabled\n",
            ">>>   2022/01/12 11:01:07 Begin execution of runSpecialJobTask\n",
            ">>>   2022/01/12 11:01:07 Creating directory at $AZUREML_LOGDIRECTORY_PATH\n",
            ">>>   2022/01/12 11:01:07 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c/azureml-logs\n",
            ">>>   2022/01/12 11:01:07 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c/azureml_compute_logs\n",
            ">>>   2022/01/12 11:01:07 runSpecialJobTask: Raw cmd for preparation is passed is: /azureml-envs/azureml_584ec09f21d7bd53651130ea10a5c2a3/bin/python /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/mounts/workspaceblobstore/azureml/bert-livedoor_1641985249_7c0fba4c-setup/job_prep.py --snapshots '[{\"Id\":\"07893626-b7d0-4b7b-87fe-43b6d8cc9569\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
            ">>>   2022/01/12 11:01:07 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c/azureml_compute_logs/65_job_prep-tvmps_a46938a6323b6ff5d91a38cb3c6b0b117014b72f62bcb10efd1e5b630f41cd0e_d.txt\n",
            ">>>   2022/01/12 11:01:07 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c/azureml_compute_logs/65_job_prep-tvmps_a46938a6323b6ff5d91a38cb3c6b0b117014b72f62bcb10efd1e5b630f41cd0e_d.txt\n",
            ">>>   2022/01/12 11:01:07 native cmd: export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/136419c8-4466-4717-8485-2040e3584f43/job-1/bert-livedoor_164198_b70e80c2-1b5d-4c8e-a6ee-ea1d1a967f06/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c;/azureml-envs/azureml_584ec09f21d7bd53651130ea10a5c2a3/bin/python /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/mounts/workspaceblobstore/azureml/bert-livedoor_1641985249_7c0fba4c-setup/job_prep.py --snapshots '[{\"Id\":\"07893626-b7d0-4b7b-87fe-43b6d8cc9569\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
            ">>>   2022/01/12 11:01:07 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n",
            ">>>   2022/01/12 11:01:07 runSpecialJobTask: Running cmd: /usr/bin/docker exec -e AZUREML_SDK_TRACEPARENT=00-8860a97aafafe2b8177c429f4dc07438-d477684f08ab5bb4-01 -t bert-livedoor_1641985249_7c0fba4c bash -c source /etc/bash.bashrc; PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/136419c8-4466-4717-8485-2040e3584f43/job-1/bert-livedoor_164198_b70e80c2-1b5d-4c8e-a6ee-ea1d1a967f06/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c;/azureml-envs/azureml_584ec09f21d7bd53651130ea10a5c2a3/bin/python /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/mounts/workspaceblobstore/azureml/bert-livedoor_1641985249_7c0fba4c-setup/job_prep.py --snapshots '[{\"Id\":\"07893626-b7d0-4b7b-87fe-43b6d8cc9569\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
            ">>>   2022/01/12 11:01:09 Attempt 1 of http call to https://japaneast.api.azureml.ms/history/v1.0/private/subscriptions/902f236f-44df-463a-a5cb-1516ab2a9cd2/resourceGroups/shuit-common/providers/Microsoft.MachineLearningServices/workspaces/shuit-ml-workspace/runs/bert-livedoor_1641985249_7c0fba4c/spans\n",
            ">>>   2022/01/12 11:01:10 containerName:bert-livedoor_1641985249_7c0fba4c\n",
            ">>>   2022/01/12 11:01:10 sidecar containerName:bert-livedoor_1641985249_7c0fba4c\n",
            ">>>   2022/01/12 11:01:10 Docker Version that this nodes use are: 20.10.11+azure-1\n",
            ">>>   \n",
            ">>>   2022/01/12 11:01:10 Start to getting gpu count by running nvidia-smi command\n",
            ">>>   2022/01/12 11:01:10 GPU : GPU 0: Tesla V100-PCIE-16GB (UUID: GPU-2f27c965-afb2-d04d-c547-d594321601e0)\n",
            ">>>   2022/01/12 11:01:10 sidecar dockerLauncher:docker\n",
            ">>>   2022/01/12 11:01:10 sidecarContainerId:ce7407daa8facb5510a1abbb1339393c9a3456ce9758419e0746b1afdf638b93\n",
            ">>>   2022/01/12 11:01:10 Docker Version that this nodes use are: 20.10.11+azure-1\n",
            ">>>   \n",
            ">>>   2022/01/12 11:01:10 Start to getting gpu count by running nvidia-smi command\n",
            ">>>   2022/01/12 11:01:10 GPU : GPU 0: Tesla V100-PCIE-16GB (UUID: GPU-2f27c965-afb2-d04d-c547-d594321601e0)\n",
            ">>>   2022/01/12 11:01:10 Docker logs for bert-livedoor_1641985249_7c0fba4c\n",
            ">>>   \n",
            ">>>   2022/01/12 11:01:10 runSpecialJobTask: job preparation exited with code 0 and err <nil>\n",
            ">>>   \n",
            ">>>   2022/01/12 11:01:10 runSpecialJobTask: preparation: [2022-01-12T11:01:07.907310] Entering job preparation.\n",
            ">>>   2022/01/12 11:01:10 runSpecialJobTask: preparation: [2022-01-12T11:01:08.698898] Starting job preparation.\n",
            ">>>   2022/01/12 11:01:10 runSpecialJobTask: preparation: [2022-01-12T11:01:08.698927] Extracting the control code.\n",
            ">>>   2022/01/12 11:01:10 runSpecialJobTask: preparation: [2022-01-12T11:01:08.699138] Starting extract_project.\n",
            ">>>   2022/01/12 11:01:10 runSpecialJobTask: preparation: [2022-01-12T11:01:08.699177] Starting to extract zip file.\n",
            ">>>   2022/01/12 11:01:10 runSpecialJobTask: preparation: [2022-01-12T11:01:08.717874] Finished extracting zip file.\n",
            ">>>   2022/01/12 11:01:10 runSpecialJobTask: preparation: [2022-01-12T11:01:08.730103] Using urllib.request Python 3.0 or later\n",
            ">>>   2022/01/12 11:01:10 runSpecialJobTask: preparation: [2022-01-12T11:01:08.730142] Start fetching snapshots.\n",
            ">>>   2022/01/12 11:01:10 runSpecialJobTask: preparation: [2022-01-12T11:01:08.730169] Start fetching snapshot.\n",
            ">>>   2022/01/12 11:01:10 runSpecialJobTask: preparation: [2022-01-12T11:01:08.730183] Retrieving project from snapshot: 07893626-b7d0-4b7b-87fe-43b6d8cc9569\n",
            ">>>   2022/01/12 11:01:10 runSpecialJobTask: preparation: Starting the daemon thread to refresh tokens in background for process with pid = 42\n",
            ">>>   2022/01/12 11:01:10 runSpecialJobTask: preparation: [2022-01-12T11:01:09.870697] Finished fetching snapshot.\n",
            ">>>   2022/01/12 11:01:10 runSpecialJobTask: preparation: [2022-01-12T11:01:09.870738] Finished fetching snapshots.\n",
            ">>>   2022/01/12 11:01:10 runSpecialJobTask: preparation: [2022-01-12T11:01:09.870751] Finished extract_project.\n",
            ">>>   2022/01/12 11:01:10 runSpecialJobTask: preparation: [2022-01-12T11:01:09.870830] Finished fetching and extracting the control code.\n",
            ">>>   2022/01/12 11:01:10 runSpecialJobTask: preparation: [2022-01-12T11:01:09.874910] downloadDataStore - Download from datastores if requested.\n",
            ">>>   2022/01/12 11:01:10 runSpecialJobTask: preparation: [2022-01-12T11:01:09.875743] Start run_history_prep.\n",
            ">>>   2022/01/12 11:01:10 runSpecialJobTask: preparation: [2022-01-12T11:01:09.880489] Entering context manager injector.\n",
            ">>>   2022/01/12 11:01:10 runSpecialJobTask: preparation: [2022-01-12T11:01:09.883242] downloadDataStore completed\n",
            ">>>   2022/01/12 11:01:10 runSpecialJobTask: preparation: [2022-01-12T11:01:09.884477] Job preparation is complete.\n",
            ">>>   2022/01/12 11:01:10 DockerSideCarContainerLogs:\n",
            ">>>   \n",
            ">>>   2022/01/12 11:01:10 DockerSideCarContainerLogs End\n",
            ">>>   2022/01/12 11:01:10 Execution of runSpecialJobTask completed\n",
            ">>>   2022/01/12 11:01:10 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
            ">>>   Stopped: false\n",
            ">>>   OriginalData: 3\n",
            ">>>   FilteredData: 0.\n",
            ">>>   2022/01/12 11:01:10 Process Exiting with Code:  0\n",
            ">>>   2022/01/12 11:01:11 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n",
            ">>>   \n",
            "2022-01-12T11:01:11Z 127.0.0.1 slots=1 max-slots=1\n",
            "2022-01-12T11:01:11Z launching Custom job\n",
            "2022-01-12T11:01:16Z job exited with code 1\n",
            "2022-01-12T11:01:17Z PostJobNodeHealthCheck\n",
            "2022-01-12T11:01:17Z Executing 'Post job node health check' on 10.0.0.4\n",
            "2022-01-12T11:01:18Z Post job node health check succeeded on 10.0.0.4. Output: \n",
            ">>>   2022/01/12 11:01:17 Got JobInfoJson from env\n",
            ">>>   2022/01/12 11:01:17 Starting App Insight Logger for task:  postJobNodeHealthCheck\n",
            ">>>   2022/01/12 11:01:17 Version: 3.0.01804.0002 Branch: 2021-12-12 Commit: 1704a55\n",
            ">>>   2022/01/12 11:01:17 Start Post-job node health check\n",
            ">>>   2022/01/12 11:01:17 PostJobNodeHealthCheck\n",
            ">>>   2022/01/12 11:01:17 GetDBE: get DBE error\n",
            ">>>   2022/01/12 11:01:17 No system error was found\n",
            ">>>   2022/01/12 11:01:17 DBEOutput: \n",
            ">>>   2022/01/12 11:01:17 GetOOM: get OOM error\n",
            ">>>   2022/01/12 11:01:17 No system error was found\n",
            ">>>   2022/01/12 11:01:17 Postjob NCCL error check time: 300ns\n",
            ">>>   \n",
            ">>>   2022/01/12 11:01:17 Formatted output of nvidia-smi:\n",
            ">>>   \n",
            ">>>   ================GPUS================\n",
            ">>>   \n",
            ">>>   Index                         \t : 0\n",
            ">>>   Uuid                          \t : GPU-2f27c965-afb2-d04d-c547-d594321601e0\n",
            ">>>   Name                          \t : Tesla V100-PCIE-16GB\n",
            ">>>   Persistence Mode              \t : Enabled\n",
            ">>>   Pci Bus Id                    \t : 00000001:00:00.0\n",
            ">>>   Display Active                \t : Disabled\n",
            ">>>   Temperature Gpu               \t : 28\n",
            ">>>   Pstate                        \t : P0\n",
            ">>>   Memory Used [MiB]             \t : 0 MiB\n",
            ">>>   Memory Total [MiB]            \t : 16160 MiB\n",
            ">>>   Utilization Gpu [%]           \t : 0 %\n",
            ">>>   Compute Mode                  \t : Default\n",
            ">>>   \n",
            ">>>   ================PROCESSES================\n",
            ">>>   No output to display\n",
            ">>>   2022/01/12 11:01:17 Start to getting gpu count by running nvidia-smi command\n",
            ">>>   2022/01/12 11:01:17 GPU : GPU 0: Tesla V100-PCIE-16GB (UUID: GPU-2f27c965-afb2-d04d-c547-d594321601e0)\n",
            ">>>   2022/01/12 11:01:17 Output of nvidia-smi -q -d PAGE_RETIREMENT:\n",
            ">>>   \n",
            ">>>   ==============NVSMI LOG==============\n",
            ">>>   \n",
            ">>>   Timestamp                                 : Wed Jan 12 11:01:17 2022\n",
            ">>>   Driver Version                            : 470.82.01\n",
            ">>>   CUDA Version                              : 11.4\n",
            ">>>   \n",
            ">>>   Attached GPUs                             : 1\n",
            ">>>   GPU 00000001:00:00.0\n",
            ">>>       Retired Pages\n",
            ">>>           Single Bit ECC                    : 0\n",
            ">>>           Double Bit ECC                    : 0\n",
            ">>>           Pending Page Blacklist            : No\n",
            ">>>   \n",
            ">>>   \n",
            ">>>   2022/01/12 11:01:17 NvidiaGpuHealthCheckOutput: {TotalBitErrorCount:[0] PendingRetiredPages:[false]}\n",
            ">>>   2022/01/12 11:01:17 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
            ">>>   Stopped: false\n",
            ">>>   OriginalData: 1\n",
            ">>>   FilteredData: 0.\n",
            ">>>   2022/01/12 11:01:17 Process Exiting with Code:  0\n",
            ">>>   2022/01/12 11:01:18 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n",
            ">>>   \n",
            "2022-01-12T11:01:18Z Executing 'JobRelease task' on 10.0.0.4\n",
            "2022-01-12T11:01:21Z JobRelease task succeeded on 10.0.0.4. Output: \n",
            ">>>   2022/01/12 11:01:18 Got JobInfoJson from env\n",
            ">>>   2022/01/12 11:01:18 Starting App Insight Logger for task:  jobRelease\n",
            ">>>   2022/01/12 11:01:18 Version: 3.0.01804.0002 Branch: 2021-12-12 Commit: 1704a55\n",
            ">>>   2022/01/12 11:01:18 Got JobInfoJson from env\n",
            ">>>   2022/01/12 11:01:18 SidecarEnabled:: isDetonationChamber: false, useDockerContainer: true\n",
            ">>>   2022/01/12 11:01:18 SidecarEnabled:: AmlDatasetContextManagerConfig exists: false\n",
            ">>>   2022/01/12 11:01:18 SidecarEnabled:: sidecar not enabled\n",
            ">>>   2022/01/12 11:01:18 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c/azureml_compute_logs\n",
            ">>>   2022/01/12 11:01:18 runSpecialJobTask: Raw cmd for postprocessing is passed is: export AZ_BATCHAI_RUN_STATUS='FAILED';export AZ_BATCHAI_LOG_UPLOAD_FAILED='false';/azureml-envs/azureml_584ec09f21d7bd53651130ea10a5c2a3/bin/python $AZ_BATCHAI_JOB_TEMP/azureml/bert-livedoor_1641985249_7c0fba4c/azureml-setup/job_release.py\n",
            ">>>   2022/01/12 11:01:18 runSpecialJobTask: stdout path for postprocessing is passed is: /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c/azureml_compute_logs/75_job_post-tvmps_a46938a6323b6ff5d91a38cb3c6b0b117014b72f62bcb10efd1e5b630f41cd0e_d.txt\n",
            ">>>   2022/01/12 11:01:18 runSpecialJobTask: stderr path for postprocessing is passed is: /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c/azureml_compute_logs/75_job_post-tvmps_a46938a6323b6ff5d91a38cb3c6b0b117014b72f62bcb10efd1e5b630f41cd0e_d.txt\n",
            ">>>   2022/01/12 11:01:18 native cmd: export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/136419c8-4466-4717-8485-2040e3584f43/job-1/bert-livedoor_164198_b70e80c2-1b5d-4c8e-a6ee-ea1d1a967f06/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c;export AZ_BATCHAI_RUN_STATUS='FAILED';export AZ_BATCHAI_LOG_UPLOAD_FAILED='false';/azureml-envs/azureml_584ec09f21d7bd53651130ea10a5c2a3/bin/python $AZ_BATCHAI_JOB_TEMP/azureml/bert-livedoor_1641985249_7c0fba4c/azureml-setup/job_release.py\n",
            ">>>   2022/01/12 11:01:18 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n",
            ">>>   2022/01/12 11:01:18 runSpecialJobTask: Running cmd: /usr/bin/docker exec -e AZUREML_SDK_TRACEPARENT=00-8860a97aafafe2b8177c429f4dc07438-847d388f23b3e540-01 -t bert-livedoor_1641985249_7c0fba4c bash -c source /etc/bash.bashrc; PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/136419c8-4466-4717-8485-2040e3584f43/job-1/bert-livedoor_164198_b70e80c2-1b5d-4c8e-a6ee-ea1d1a967f06/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/bert-livedoor_1641985249_7c0fba4c/wd/azureml/bert-livedoor_1641985249_7c0fba4c;export AZ_BATCHAI_RUN_STATUS='FAILED';export AZ_BATCHAI_LOG_UPLOAD_FAILED='false';/azureml-envs/azureml_584ec09f21d7bd53651130ea10a5c2a3/bin/python $AZ_BATCHAI_JOB_TEMP/azureml/bert-livedoor_1641985249_7c0fba4c/azureml-setup/job_release.py\n",
            ">>>   2022/01/12 11:01:20 containerName:bert-livedoor_1641985249_7c0fba4c\n",
            ">>>   2022/01/12 11:01:20 sidecar containerName:bert-livedoor_1641985249_7c0fba4c\n",
            ">>>   2022/01/12 11:01:20 Docker Version that this nodes use are: 20.10.11+azure-1\n",
            ">>>   \n",
            ">>>   2022/01/12 11:01:20 Start to getting gpu count by running nvidia-smi command\n",
            ">>>   2022/01/12 11:01:20 GPU : GPU 0: Tesla V100-PCIE-16GB (UUID: GPU-2f27c965-afb2-d04d-c547-d594321601e0)\n",
            ">>>   2022/01/12 11:01:20 sidecar dockerLauncher:docker\n",
            ">>>   2022/01/12 11:01:20 sidecarContainerId:ce7407daa8facb5510a1abbb1339393c9a3456ce9758419e0746b1afdf638b93\n",
            ">>>   2022/01/12 11:01:20 Docker Version that this nodes use are: 20.10.11+azure-1\n",
            ">>>   \n",
            ">>>   2022/01/12 11:01:20 Start to getting gpu count by running nvidia-smi command\n",
            ">>>   2022/01/12 11:01:20 GPU : GPU 0: Tesla V100-PCIE-16GB (UUID: GPU-2f27c965-afb2-d04d-c547-d594321601e0)\n",
            ">>>   2022/01/12 11:01:20 Docker logs for bert-livedoor_1641985249_7c0fba4c\n",
            ">>>   \n",
            ">>>   2022/01/12 11:01:20 runSpecialJobTask: job postprocessing exited with code 0 and err <nil>\n",
            ">>>   \n",
            ">>>   2022/01/12 11:01:20 runSpecialJobTask: postprocessing: [2022-01-12T11:01:18.750756] Entering job release\n",
            ">>>   2022/01/12 11:01:20 runSpecialJobTask: postprocessing: [2022-01-12T11:01:19.566965] Starting job release\n",
            ">>>   2022/01/12 11:01:20 runSpecialJobTask: postprocessing: [2022-01-12T11:01:19.567378] Logging experiment finalizing status in history service.\n",
            ">>>   2022/01/12 11:01:20 runSpecialJobTask: postprocessing: [2022-01-12T11:01:19.568092] job release stage : upload_datastore starting...Starting the daemon thread to refresh tokens in background for process with pid = 129\n",
            ">>>   2022/01/12 11:01:20 runSpecialJobTask: postprocessing: \n",
            ">>>   2022/01/12 11:01:20 runSpecialJobTask: postprocessing: [2022-01-12T11:01:19.568546] job release stage : start importing azureml.history._tracking in run_history_release.\n",
            ">>>   2022/01/12 11:01:20 runSpecialJobTask: postprocessing: [2022-01-12T11:01:19.570218] job release stage : copy_batchai_cached_logs starting...[2022-01-12T11:01:19.570253] job release stage : execute_job_release starting...\n",
            ">>>   2022/01/12 11:01:20 runSpecialJobTask: postprocessing: [2022-01-12T11:01:19.570362] job release stage : copy_batchai_cached_logs completed...\n",
            ">>>   2022/01/12 11:01:20 runSpecialJobTask: postprocessing: \n",
            ">>>   2022/01/12 11:01:20 runSpecialJobTask: postprocessing: [2022-01-12T11:01:19.570883] Entering context manager injector.\n",
            ">>>   2022/01/12 11:01:20 runSpecialJobTask: postprocessing: [2022-01-12T11:01:19.639797] job release stage : upload_datastore completed...\n",
            ">>>   2022/01/12 11:01:20 runSpecialJobTask: postprocessing: [2022-01-12T11:01:19.716763] job release stage : send_run_telemetry starting...\n",
            ">>>   2022/01/12 11:01:20 runSpecialJobTask: postprocessing: [2022-01-12T11:01:19.731880] get vm size and vm region successfully.\n",
            ">>>   2022/01/12 11:01:20 runSpecialJobTask: postprocessing: [2022-01-12T11:01:19.741268] get compute meta data successfully.\n",
            ">>>   2022/01/12 11:01:20 runSpecialJobTask: postprocessing: [2022-01-12T11:01:19.958856] job release stage : execute_job_release completed...\n",
            ">>>   2022/01/12 11:01:20 runSpecialJobTask: postprocessing: [2022-01-12T11:01:19.972611] post artifact meta request successfully.\n",
            ">>>   2022/01/12 11:01:20 runSpecialJobTask: postprocessing: [2022-01-12T11:01:20.080228] upload compute record artifact successfully.\n",
            ">>>   2022/01/12 11:01:20 runSpecialJobTask: postprocessing: [2022-01-12T11:01:20.080286] job release stage : send_run_telemetry completed...\n",
            ">>>   2022/01/12 11:01:20 runSpecialJobTask: postprocessing: [2022-01-12T11:01:20.080482] Job release is complete\n",
            ">>>   2022/01/12 11:01:20 DockerSideCarContainerLogs:\n",
            ">>>   \n",
            ">>>   2022/01/12 11:01:20 DockerSideCarContainerLogs End\n",
            ">>>   2022/01/12 11:01:21 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n",
            ">>>   2022/01/12 11:01:21 App Insight Client has already been closed\n",
            ">>>   2022/01/12 11:01:21 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
            ">>>   Stopped: false\n",
            ">>>   OriginalData: 3\n",
            ">>>   FilteredData: 0.\n",
            ">>>   \n",
            "2022-01-12T11:01:21Z Executing 'Collect error information from workers' on 10.0.0.4\n",
            "2022-01-12T11:01:21Z Collect error information from workers succeeded on 10.0.0.4. Output: \n",
            ">>>   \n",
            ">>>   \n",
            "2022-01-12T11:01:21Z Executing 'Job environment clean-up' on 10.0.0.4\n",
            "2022-01-12T11:01:21Z Removing container bert-livedoor_1641985249_7c0fba4c exited with 0, bert-livedoor_1641985249_7c0fba4c\n",
            "\n",
            "\n",
            "\n",
            "Streaming azureml-logs/75_job_post-tvmps_a46938a6323b6ff5d91a38cb3c6b0b117014b72f62bcb10efd1e5b630f41cd0e_d.txt\n",
            "===============================================================================================================\n",
            "\n",
            "[2022-01-12T11:01:18.750756] Entering job release\n",
            "[2022-01-12T11:01:19.566965] Starting job release\n",
            "[2022-01-12T11:01:19.567378] Logging experiment finalizing status in history service.\n",
            "[2022-01-12T11:01:19.568092] job release stage : upload_datastore starting...Starting the daemon thread to refresh tokens in background for process with pid = 129\n",
            "\n",
            "[2022-01-12T11:01:19.568546] job release stage : start importing azureml.history._tracking in run_history_release.\n",
            "[2022-01-12T11:01:19.570218] job release stage : copy_batchai_cached_logs starting...[2022-01-12T11:01:19.570253] job release stage : execute_job_release starting...\n",
            "[2022-01-12T11:01:19.570362] job release stage : copy_batchai_cached_logs completed...\n",
            "\n",
            "[2022-01-12T11:01:19.570883] Entering context manager injector.\n",
            "[2022-01-12T11:01:19.639797] job release stage : upload_datastore completed...\n",
            "[2022-01-12T11:01:19.716763] job release stage : send_run_telemetry starting...\n",
            "[2022-01-12T11:01:19.731880] get vm size and vm region successfully.\n",
            "[2022-01-12T11:01:19.741268] get compute meta data successfully.\n",
            "[2022-01-12T11:01:19.958856] job release stage : execute_job_release completed...\n",
            "[2022-01-12T11:01:19.972611] post artifact meta request successfully.\n",
            "[2022-01-12T11:01:20.080228] upload compute record artifact successfully.\n",
            "[2022-01-12T11:01:20.080286] job release stage : send_run_telemetry completed...\n",
            "[2022-01-12T11:01:20.080482] Job release is complete\n",
            "\n",
            "Execution Summary\n",
            "=================\n",
            "RunId: bert-livedoor_1641985249_7c0fba4c\n",
            "Web View: https://ml.azure.com/runs/bert-livedoor_1641985249_7c0fba4c?wsid=/subscriptions/902f236f-44df-463a-a5cb-1516ab2a9cd2/resourcegroups/shuit-common/workspaces/shuit-ml-workspace&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
            "\n",
            "Warnings:\n",
            "{\n",
            "  \"error\": {\n",
            "    \"code\": \"UserError\",\n",
            "    \"severity\": null,\n",
            "    \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\",\n",
            "    \"messageFormat\": \"{Message}\",\n",
            "    \"messageParameters\": {\n",
            "      \"Message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\"\n",
            "    },\n",
            "    \"referenceCode\": null,\n",
            "    \"detailsUri\": null,\n",
            "    \"target\": null,\n",
            "    \"details\": [],\n",
            "    \"innerError\": {\n",
            "      \"code\": \"UserTrainingScriptFailed\",\n",
            "      \"innerError\": null\n",
            "    },\n",
            "    \"debugInfo\": null,\n",
            "    \"additionalInfo\": null\n",
            "  },\n",
            "  \"correlation\": {\n",
            "    \"operation\": \"7212039d82cc9146ab484c3b3f607576\",\n",
            "    \"request\": \"6a20772dd34e8e41\"\n",
            "  },\n",
            "  \"environment\": \"japaneast\",\n",
            "  \"location\": \"japaneast\",\n",
            "  \"time\": \"2022-01-12T11:01:31.833104+00:00\",\n",
            "  \"componentName\": \"globaljobdispatcher\"\n",
            "}\n",
            "\n"
          ]
        },
        {
          "ename": "ActivityFailedException",
          "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with ModuleNotFoundError: No module named 'torchmetrics'\",\n        \"messageParameters\": {},\n        \"detailsUri\": \"https://aka.ms/azureml-run-troubleshooting\",\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with ModuleNotFoundError: No module named 'torchmetrics'\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-run-troubleshooting\\\",\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_27105/1324130382.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 実行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m    824\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshow_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m                 self._stream_run_output(\n\u001b[0m\u001b[1;32m    827\u001b[0m                     \u001b[0mfile_handle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m                     \u001b[0mwait_post_processing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait_post_processing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36m_stream_run_output\u001b[0;34m(self, file_handle, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                 \u001b[0mfile_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mActivityFailedException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_details\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m         \u001b[0mfile_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with ModuleNotFoundError: No module named 'torchmetrics'\",\n        \"messageParameters\": {},\n        \"detailsUri\": \"https://aka.ms/azureml-run-troubleshooting\",\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with ModuleNotFoundError: No module named 'torchmetrics'\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-run-troubleshooting\\\",\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}"
          ]
        }
      ],
      "source": [
        "# 実行\n",
        "run = Experiment(ws, experiment_name).submit(src)\n",
        "run.wait_for_completion(show_output=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "gather": {
          "logged": 1621438249855
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Model(workspace=Workspace.create(name='shuit-ml-workspace', subscription_id='902f236f-44df-463a-a5cb-1516ab2a9cd2', resource_group='shuit-common'), name=bert-livedoor-model, id=bert-livedoor-model:4, version=4, tags={}, properties={})"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# モデル登録\n",
        "run.register_model(\n",
        "    model_name=\"bert-livedoor-model\",\n",
        "    model_path=os.path.join('outputs', 'model.onnx'),\n",
        "    model_framework=Model.Framework.ONNX,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "814635fff90d4fb7edb7cf7b4efbafc2586e819c8eea62750f0795f97ef3e14f"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
