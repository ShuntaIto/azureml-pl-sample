{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1621437823367
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from azureml.core import Workspace\n",
        "from azureml.core import Environment\n",
        "from azureml.core import ScriptRunConfig, Experiment\n",
        "from azureml.widgets import RunDetails\n",
        "from azureml.core import Model\n",
        "from azureml.core.runconfig import PyTorchConfiguration\n",
        "from azureml.core.runconfig import MpiConfiguration\n",
        "from azureml.core.runconfig import RunConfiguration, DockerConfiguration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1621437824132
        }
      },
      "outputs": [],
      "source": [
        "# AMLワークスペースへの接続\n",
        "ws = Workspace.from_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "gather": {
          "logged": 1621437824308
        }
      },
      "outputs": [],
      "source": [
        "# training script\n",
        "source_dir = \"train\"\n",
        "script_name = \"dist_train_bert.py\"\n",
        "\n",
        "# environment file\n",
        "environment_file = os.path.join(\"train\", \"dist_train_bert_env.yml\")\n",
        "\n",
        "# azure ml settings\n",
        "environment_name = \"pl-env-lang\"\n",
        "experiment_name = \"dist-bert-livedoor\"\n",
        "compute_name = \"shuit-gpu-clus04\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "gather": {
          "logged": 1621437824704
        }
      },
      "outputs": [],
      "source": [
        "# 学習環境作成、初回のみ長時間\n",
        "env = Environment.from_conda_specification(environment_name, environment_file)\n",
        "\n",
        "docker_config = DockerConfiguration(use_docker=True)\n",
        "\n",
        "env.docker.base_image = (\n",
        "    \"mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.1-cudnn8-ubuntu18.04:20211221.v1\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "gather": {
          "logged": 1621433610083
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:azureml._base_sdk_common._docstring_wrapper:Class KubernetesCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "WARNING:root:You might see network latency and increased data transfer costs if you chose a cluster in a location different from the location of your workspace\n"
          ]
        }
      ],
      "source": [
        "# 学習設定\n",
        "\n",
        "num_nodes = 4\n",
        "num_gpus = 1\n",
        "\n",
        "target_batch_size = 256\n",
        "lr = 0.0001\n",
        "\n",
        "cluster = ws.compute_targets[compute_name]\n",
        "#dist_config = PyTorchConfiguration(node_count=num_nodes)\n",
        "dist_config = MpiConfiguration(node_count=num_nodes)\n",
        "\n",
        "src = ScriptRunConfig(\n",
        "    source_directory=source_dir,\n",
        "    script=script_name,\n",
        "    arguments=[\n",
        "        \"--batch_size\", target_batch_size / (num_nodes * num_gpus),\n",
        "        \"--learning_rate\", lr,\n",
        "        \"--max_epochs\", 40,\n",
        "        \"--gpus\", num_gpus,\n",
        "        \"--strategy\", \"ddp\",\n",
        "        \"--num_nodes\", num_nodes,\n",
        "    ],\n",
        "    compute_target=cluster,\n",
        "    environment=env,\n",
        "    docker_runtime_config=docker_config,\n",
        "    distributed_job_config=dist_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "gather": {
          "logged": 1621434108189
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RunId: dist-bert-livedoor_1642179345_17da47fb\n",
            "Web View: https://ml.azure.com/runs/dist-bert-livedoor_1642179345_17da47fb?wsid=/subscriptions/902f236f-44df-463a-a5cb-1516ab2a9cd2/resourcegroups/shuit-common/workspaces/shuit-ml-workspace&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
            "\n",
            "Streaming azureml-logs/55_azureml-execution-tvmps_20ac39c4278412aef66907a79139a26b1c9a2ea2528715afc25a93a577e6bb9f_p.txt\n",
            "========================================================================================================================\n",
            "\n",
            "2022-01-14T16:56:06Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/dist-bert-livedoor_1642179345_17da47fb/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/dist-bert-livedoor_1642179345_17da47fb/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=679820 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/dist-bert-livedoor_1642179345_17da47fb/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
            "2022-01-14T16:56:07Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/dist-bert-livedoor_1642179345_17da47fb/mounts/workspaceblobstore -- stdout/stderr: \n",
            "2022-01-14T16:56:09Z Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\n",
            ". Please ignore this if the GPUs don't utilize NVIDIA® NVLink® switches.\n",
            "2022-01-14T16:56:09Z Starting output-watcher...\n",
            "2022-01-14T16:56:09Z IsDedicatedCompute == False, starting polling for Low-Pri Preemption\n",
            "Login Succeeded\n",
            "Using default tag: latest\n",
            "latest: Pulling from azureml/azureml_c75cbecb320e3ad76de6f35541429c36\n",
            "Digest: sha256:b0729c0834bfd4be29d1ebe6e5fce8f772a5f9c18b06d7f618c46ea0dbc90b31\n",
            "Status: Image is up to date for shuitmlcr.azurecr.io/azureml/azureml_c75cbecb320e3ad76de6f35541429c36:latest\n",
            "shuitmlcr.azurecr.io/azureml/azureml_c75cbecb320e3ad76de6f35541429c36:latest\n",
            "2022-01-14T16:56:11Z Check if container dist-bert-livedoor_1642179345_17da47fb already exist exited with 0, \n",
            "\n",
            "48ebbff6d61a291c55af20718a0972b62434166a4dde15ff895bde6dee60b87f\n",
            "2022-01-14T16:56:12Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to true \n",
            "2022-01-14T16:56:12Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-9c9485bb35b1450a2b80287618ab08f9-e15a1aa1f522e278-01 -sshRequired=true] \n",
            "2022/01/14 16:56:12 Got JobInfoJson from env\n",
            "2022/01/14 16:56:12 Starting App Insight Logger for task:  containerSetup\n",
            "2022/01/14 16:56:12 Version: 3.0.01830.0002 Branch: 2022-01-05 Commit: 3618b7d\n",
            "2022/01/14 16:56:12 Entered ContainerSetupTask - Preparing infiniband\n",
            "2022/01/14 16:56:12 Starting infiniband setup\n",
            "2022/01/14 16:56:12 Python Version found is Python 3.8.12\n",
            "\n",
            "2022/01/14 16:56:12 Returning Python Version as 3.8\n",
            "2022-01-14T16:56:12Z VMSize: standard_nc6s_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
            "2022/01/14 16:56:12 VMSize: standard_nc6s_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
            "2022/01/14 16:56:12 VMSize: standard_nc6s_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
            "2022/01/14 16:56:12 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
            "2022-01-14T16:56:12Z Not setting up Infiniband in Container\n",
            "2022/01/14 16:56:12 Not setting up Infiniband in Container\n",
            "2022/01/14 16:56:12 Not setting up Infiniband in Container\n",
            "2022/01/14 16:56:12 Python Version found is Python 3.8.12\n",
            "\n",
            "2022/01/14 16:56:12 Returning Python Version as 3.8\n",
            "2022/01/14 16:56:12 Starting setupPasswordLessSSH setup\n",
            "2022/01/14 16:56:12 sshd runtime has already been installed in the container\n",
            "ssh-keygen: generating new host keys: DSA \n",
            "2022/01/14 16:56:13 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n",
            "2022/01/14 16:56:13 App Insight Client has already been closed\n",
            "2022/01/14 16:56:13 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
            "Stopped: false\n",
            "OriginalData: 1\n",
            "FilteredData: 0.\n",
            "2022-01-14T16:56:13Z Starting docker container succeeded.\n",
            "\n",
            "Streaming azureml-logs/70_driver_log_0.txt\n",
            "==========================================\n",
            "\n",
            "[2022-01-14T16:56:29.481696] Entering context manager injector.\n",
            "[2022-01-14T16:56:29.981482] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['dist_train_bert.py', '--batch_size', '64', '--learning_rate', '0.0001', '--max_epochs', '40', '--accelerator', 'gpu', '--gpus', '1', '--strategy', 'ddp', '--num_nodes', '4'])\n",
            "This is an MPI job. Rank:0\n",
            "Script type = None\n",
            "[2022-01-14T16:56:29.985276] Entering Run History Context Manager.\n",
            "[2022-01-14T16:56:31.412336] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/dist-bert-livedoor_1642179345_17da47fb/wd/azureml/dist-bert-livedoor_1642179345_17da47fb\n",
            "[2022-01-14T16:56:31.412592] Preparing to call script [dist_train_bert.py] with arguments:['--batch_size', '64', '--learning_rate', '0.0001', '--max_epochs', '40', '--accelerator', 'gpu', '--gpus', '1', '--strategy', 'ddp', '--num_nodes', '4']\n",
            "[2022-01-14T16:56:31.412680] After variable expansion, calling script [dist_train_bert.py] with arguments:['--batch_size', '64', '--learning_rate', '0.0001', '--max_epochs', '40', '--accelerator', 'gpu', '--gpus', '1', '--strategy', 'ddp', '--num_nodes', '4']\n",
            "\n",
            "Global seed set to 42\n",
            "usage: dist_train_bert.py [-h] [--batch_size BATCH_SIZE]\n",
            "                          [--learning_rate LEARNING_RATE]\n",
            "                          [--max_epochs MAX_EPOCHS] [--num_nodes NUM_NODES]\n",
            "                          [--strategy STRATEGY] [--gpus GPUS]\n",
            "dist_train_bert.py: error: unrecognized arguments: --accelerator gpu\n",
            "\n",
            "\n",
            "[2022-01-14T16:56:33.077642] The experiment failed with exit code: 2. Finalizing run...\n",
            "Cleaning up all outstanding Run operations, waiting 900.0 seconds\n",
            "2 items cleaning up...\n",
            "Cleanup took 0.9002952575683594 seconds\n",
            "Traceback (most recent call last):\n",
            "  File \"dist_train_bert.py\", line 107, in <module>\n",
            "    cli_main()\n",
            "  File \"dist_train_bert.py\", line 27, in cli_main\n",
            "    args = parser.parse_args()\n",
            "  File \"/azureml-envs/azureml_4066df70c487d6e2083cc11b2bc57684/lib/python3.8/argparse.py\", line 1771, in parse_args\n",
            "    self.error(msg % ' '.join(argv))\n",
            "  File \"/azureml-envs/azureml_4066df70c487d6e2083cc11b2bc57684/lib/python3.8/argparse.py\", line 2521, in error\n",
            "    self.exit(2, _('%(prog)s: error: %(message)s\\n') % args)\n",
            "  File \"/azureml-envs/azureml_4066df70c487d6e2083cc11b2bc57684/lib/python3.8/argparse.py\", line 2508, in exit\n",
            "    _sys.exit(status)\n",
            "SystemExit: 2\n",
            "\n",
            "[2022-01-14T16:56:34.809672] Finished context manager injector with SystemExit exception.\n",
            "\n",
            "Streaming azureml-logs/75_job_post-tvmps_20ac39c4278412aef66907a79139a26b1c9a2ea2528715afc25a93a577e6bb9f_p.txt\n",
            "===============================================================================================================\n",
            "\n",
            "[2022-01-14T16:56:43.666991] Entering job release\n",
            "[2022-01-14T16:56:44.589823] job release stage : copy_batchai_cached_logs starting...\n",
            "[2022-01-14T16:56:44.589871] job release stage : copy_batchai_cached_logs completed...\n",
            "\n",
            "Execution Summary\n",
            "=================\n",
            "RunId: dist-bert-livedoor_1642179345_17da47fb\n",
            "Web View: https://ml.azure.com/runs/dist-bert-livedoor_1642179345_17da47fb?wsid=/subscriptions/902f236f-44df-463a-a5cb-1516ab2a9cd2/resourcegroups/shuit-common/workspaces/shuit-ml-workspace&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
            "\n",
            "Warnings:\n",
            "{\n",
            "  \"error\": {\n",
            "    \"code\": \"UserError\",\n",
            "    \"severity\": null,\n",
            "    \"message\": \"User program failed with SystemExit: 2\",\n",
            "    \"messageFormat\": null,\n",
            "    \"messageParameters\": {},\n",
            "    \"referenceCode\": null,\n",
            "    \"detailsUri\": \"https://aka.ms/azureml-run-troubleshooting\",\n",
            "    \"target\": null,\n",
            "    \"details\": [],\n",
            "    \"innerError\": null,\n",
            "    \"debugInfo\": null,\n",
            "    \"additionalInfo\": null\n",
            "  },\n",
            "  \"correlation\": null,\n",
            "  \"environment\": null,\n",
            "  \"location\": null,\n",
            "  \"time\": \"0001-01-01T00:00:00+00:00\",\n",
            "  \"componentName\": null\n",
            "}\n",
            "{\n",
            "  \"error\": {\n",
            "    \"code\": \"UserError\",\n",
            "    \"severity\": null,\n",
            "    \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\",\n",
            "    \"messageFormat\": \"{Message}\",\n",
            "    \"messageParameters\": {\n",
            "      \"Message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\"\n",
            "    },\n",
            "    \"referenceCode\": null,\n",
            "    \"detailsUri\": null,\n",
            "    \"target\": null,\n",
            "    \"details\": [],\n",
            "    \"innerError\": {\n",
            "      \"code\": \"UserTrainingScriptFailed\",\n",
            "      \"innerError\": null\n",
            "    },\n",
            "    \"debugInfo\": null,\n",
            "    \"additionalInfo\": null\n",
            "  },\n",
            "  \"correlation\": {\n",
            "    \"operation\": \"16af7aecdc1eae4e80e1ab9147aa0bd9\",\n",
            "    \"request\": \"680c982e59e9f4f0\"\n",
            "  },\n",
            "  \"environment\": \"japaneast\",\n",
            "  \"location\": \"japaneast\",\n",
            "  \"time\": \"2022-01-14T16:57:01.1734829+00:00\",\n",
            "  \"componentName\": \"globaljobdispatcher\"\n",
            "}\n",
            "\n"
          ]
        },
        {
          "ename": "ActivityFailedException",
          "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with SystemExit: 2\",\n        \"messageParameters\": {},\n        \"detailsUri\": \"https://aka.ms/azureml-run-troubleshooting\",\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with SystemExit: 2\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-run-troubleshooting\\\",\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_9667/2744437249.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 実行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m    824\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshow_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m                 self._stream_run_output(\n\u001b[0m\u001b[1;32m    827\u001b[0m                     \u001b[0mfile_handle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m                     \u001b[0mwait_post_processing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait_post_processing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36m_stream_run_output\u001b[0;34m(self, file_handle, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                 \u001b[0mfile_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mActivityFailedException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_details\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m         \u001b[0mfile_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with SystemExit: 2\",\n        \"messageParameters\": {},\n        \"detailsUri\": \"https://aka.ms/azureml-run-troubleshooting\",\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with SystemExit: 2\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-run-troubleshooting\\\",\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}"
          ]
        }
      ],
      "source": [
        "# 実行\n",
        "run = Experiment(ws, experiment_name).submit(src)\n",
        "run.wait_for_completion(show_output=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1621417896422
        }
      },
      "outputs": [
        {
          "ename": "ModelPathNotFoundException",
          "evalue": "ModelPathNotFoundException:\n\tMessage: Could not locate the provided model_path outputs/model.onnx in the set of files uploaded to the run: ['azureml-logs/55_azureml-execution-tvmps_0f93e9792dd9ffbd80a0b0cbeb00a8fab0b14be474a32b815609bb1f4bffa494_d.txt', 'azureml-logs/55_azureml-execution-tvmps_6ad0f50cd79742bed158768f299d376ef743927df3983464d8dc993376693eb2_d.txt', 'azureml-logs/65_job_prep-tvmps_0f93e9792dd9ffbd80a0b0cbeb00a8fab0b14be474a32b815609bb1f4bffa494_d.txt', 'azureml-logs/65_job_prep-tvmps_6ad0f50cd79742bed158768f299d376ef743927df3983464d8dc993376693eb2_d.txt', 'azureml-logs/70_driver_log_0.txt', 'azureml-logs/70_driver_log_1.txt', 'azureml-logs/70_mpi_log.txt', 'azureml-logs/75_job_post-tvmps_0f93e9792dd9ffbd80a0b0cbeb00a8fab0b14be474a32b815609bb1f4bffa494_d.txt', 'azureml-logs/75_job_post-tvmps_6ad0f50cd79742bed158768f299d376ef743927df3983464d8dc993376693eb2_d.txt', 'azureml-logs/process_info.json', 'azureml-logs/process_status.json', 'logs/azureml/0_140_azureml.log', 'logs/azureml/1_119_azureml.log', 'logs/azureml/job_prep_azureml.log', 'logs/azureml/job_release_azureml.log', 'outputs/model.ckpt']\n                See https://aka.ms/run-logging for more details.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Could not locate the provided model_path outputs/model.onnx in the set of files uploaded to the run: ['azureml-logs/55_azureml-execution-tvmps_0f93e9792dd9ffbd80a0b0cbeb00a8fab0b14be474a32b815609bb1f4bffa494_d.txt', 'azureml-logs/55_azureml-execution-tvmps_6ad0f50cd79742bed158768f299d376ef743927df3983464d8dc993376693eb2_d.txt', 'azureml-logs/65_job_prep-tvmps_0f93e9792dd9ffbd80a0b0cbeb00a8fab0b14be474a32b815609bb1f4bffa494_d.txt', 'azureml-logs/65_job_prep-tvmps_6ad0f50cd79742bed158768f299d376ef743927df3983464d8dc993376693eb2_d.txt', 'azureml-logs/70_driver_log_0.txt', 'azureml-logs/70_driver_log_1.txt', 'azureml-logs/70_mpi_log.txt', 'azureml-logs/75_job_post-tvmps_0f93e9792dd9ffbd80a0b0cbeb00a8fab0b14be474a32b815609bb1f4bffa494_d.txt', 'azureml-logs/75_job_post-tvmps_6ad0f50cd79742bed158768f299d376ef743927df3983464d8dc993376693eb2_d.txt', 'azureml-logs/process_info.json', 'azureml-logs/process_status.json', 'logs/azureml/0_140_azureml.log', 'logs/azureml/1_119_azureml.log', 'logs/azureml/job_prep_azureml.log', 'logs/azureml/job_release_azureml.log', 'outputs/model.ckpt']\\n                See https://aka.ms/run-logging for more details.\"\n    }\n}",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModelPathNotFoundException\u001b[0m                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-67703e415f2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# モデル登録\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m run.register_model(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bert-livedoor-model\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'outputs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model.onnx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel_framework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFramework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mONNX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36mregister_model\u001b[0;34m(self, model_name, model_path, tags, properties, model_framework, model_framework_version, description, datasets, sample_input_dataset, sample_output_dataset, resource_configuration, **kwargs)\u001b[0m\n\u001b[1;32m   2191\u001b[0m         \"\"\"\n\u001b[1;32m   2192\u001b[0m         \u001b[0mmodel_name_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2193\u001b[0;31m         return self._client.register_model(\n\u001b[0m\u001b[1;32m   2194\u001b[0m             \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_framework\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_framework_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2195\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_input_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_input_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_run_impl/run_history_facade.py\u001b[0m in \u001b[0;36mregister_model\u001b[0;34m(self, model_name, model_path, tags, properties, model_framework, model_framework_version, asset_id, sample_input_dataset, sample_output_dataset, resource_configuration, **kwargs)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcloud_file_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0mrun_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martifacts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_file_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_origin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_container_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             raise ModelPathNotFoundException(\n\u001b[0m\u001b[1;32m    444\u001b[0m                 \"\"\"Could not locate the provided model_path {} in the set of files uploaded to the run: {}\n\u001b[1;32m    445\u001b[0m                 See https://aka.ms/run-logging for more details.\"\"\".format(model_path, str(run_files)))\n",
            "\u001b[0;31mModelPathNotFoundException\u001b[0m: ModelPathNotFoundException:\n\tMessage: Could not locate the provided model_path outputs/model.onnx in the set of files uploaded to the run: ['azureml-logs/55_azureml-execution-tvmps_0f93e9792dd9ffbd80a0b0cbeb00a8fab0b14be474a32b815609bb1f4bffa494_d.txt', 'azureml-logs/55_azureml-execution-tvmps_6ad0f50cd79742bed158768f299d376ef743927df3983464d8dc993376693eb2_d.txt', 'azureml-logs/65_job_prep-tvmps_0f93e9792dd9ffbd80a0b0cbeb00a8fab0b14be474a32b815609bb1f4bffa494_d.txt', 'azureml-logs/65_job_prep-tvmps_6ad0f50cd79742bed158768f299d376ef743927df3983464d8dc993376693eb2_d.txt', 'azureml-logs/70_driver_log_0.txt', 'azureml-logs/70_driver_log_1.txt', 'azureml-logs/70_mpi_log.txt', 'azureml-logs/75_job_post-tvmps_0f93e9792dd9ffbd80a0b0cbeb00a8fab0b14be474a32b815609bb1f4bffa494_d.txt', 'azureml-logs/75_job_post-tvmps_6ad0f50cd79742bed158768f299d376ef743927df3983464d8dc993376693eb2_d.txt', 'azureml-logs/process_info.json', 'azureml-logs/process_status.json', 'logs/azureml/0_140_azureml.log', 'logs/azureml/1_119_azureml.log', 'logs/azureml/job_prep_azureml.log', 'logs/azureml/job_release_azureml.log', 'outputs/model.ckpt']\n                See https://aka.ms/run-logging for more details.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Could not locate the provided model_path outputs/model.onnx in the set of files uploaded to the run: ['azureml-logs/55_azureml-execution-tvmps_0f93e9792dd9ffbd80a0b0cbeb00a8fab0b14be474a32b815609bb1f4bffa494_d.txt', 'azureml-logs/55_azureml-execution-tvmps_6ad0f50cd79742bed158768f299d376ef743927df3983464d8dc993376693eb2_d.txt', 'azureml-logs/65_job_prep-tvmps_0f93e9792dd9ffbd80a0b0cbeb00a8fab0b14be474a32b815609bb1f4bffa494_d.txt', 'azureml-logs/65_job_prep-tvmps_6ad0f50cd79742bed158768f299d376ef743927df3983464d8dc993376693eb2_d.txt', 'azureml-logs/70_driver_log_0.txt', 'azureml-logs/70_driver_log_1.txt', 'azureml-logs/70_mpi_log.txt', 'azureml-logs/75_job_post-tvmps_0f93e9792dd9ffbd80a0b0cbeb00a8fab0b14be474a32b815609bb1f4bffa494_d.txt', 'azureml-logs/75_job_post-tvmps_6ad0f50cd79742bed158768f299d376ef743927df3983464d8dc993376693eb2_d.txt', 'azureml-logs/process_info.json', 'azureml-logs/process_status.json', 'logs/azureml/0_140_azureml.log', 'logs/azureml/1_119_azureml.log', 'logs/azureml/job_prep_azureml.log', 'logs/azureml/job_release_azureml.log', 'outputs/model.ckpt']\\n                See https://aka.ms/run-logging for more details.\"\n    }\n}"
          ]
        }
      ],
      "source": [
        "# モデル登録\n",
        "run.register_model(\n",
        "    model_name=\"bert-livedoor-model\",\n",
        "    model_path=os.path.join('outputs', 'model.ckpt'),\n",
        "    model_framework=Model.Framework.PYTORCH,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
