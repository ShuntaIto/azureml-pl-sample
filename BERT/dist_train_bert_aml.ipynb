{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "gather": {
          "logged": 1621437823367
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from azureml.core import Workspace\n",
        "from azureml.core import Environment\n",
        "from azureml.core import ScriptRunConfig, Experiment\n",
        "from azureml.widgets import RunDetails\n",
        "from azureml.core import Model\n",
        "from azureml.core.runconfig import PyTorchConfiguration\n",
        "from azureml.core.runconfig import MpiConfiguration\n",
        "from azureml.core.runconfig import RunConfiguration, DockerConfiguration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "gather": {
          "logged": 1621437824132
        }
      },
      "outputs": [],
      "source": [
        "# AMLワークスペースへの接続\n",
        "ws = Workspace.from_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "gather": {
          "logged": 1621437824308
        }
      },
      "outputs": [],
      "source": [
        "# training script\n",
        "source_dir = \"train\"\n",
        "script_name = \"dist_train_bert.py\"\n",
        "\n",
        "# environment file\n",
        "environment_file = os.path.join(\"train\", \"dist_train_bert_env.yml\")\n",
        "\n",
        "# azure ml settings\n",
        "environment_name = \"pl-env-lang\"\n",
        "experiment_name = \"dist-bert-livedoor\"\n",
        "compute_name = \"shuit-gpu-clus04\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "gather": {
          "logged": 1621437824704
        }
      },
      "outputs": [],
      "source": [
        "# 学習環境作成、初回のみ長時間\n",
        "env = Environment.from_conda_specification(environment_name, environment_file)\n",
        "\n",
        "docker_config = DockerConfiguration(use_docker=True)\n",
        "\n",
        "env.docker.base_image = (\n",
        "    \"mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.1-cudnn8-ubuntu18.04:20211221.v1\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "gather": {
          "logged": 1621433610083
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:azureml._base_sdk_common._docstring_wrapper:Class KubernetesCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "WARNING:root:You might see network latency and increased data transfer costs if you chose a cluster in a location different from the location of your workspace\n"
          ]
        }
      ],
      "source": [
        "# 学習設定\n",
        "\n",
        "num_nodes = 4\n",
        "num_gpus = 1\n",
        "\n",
        "target_batch_size = 256\n",
        "lr = 0.01\n",
        "\n",
        "cluster = ws.compute_targets[compute_name]\n",
        "#dist_config = PyTorchConfiguration(node_count=num_nodes)\n",
        "dist_config = MpiConfiguration(node_count=num_nodes)\n",
        "\n",
        "src = ScriptRunConfig(\n",
        "    source_directory=source_dir,\n",
        "    script=script_name,\n",
        "    arguments=[\n",
        "        \"--batch_size\", target_batch_size/(num_nodes*num_gpus),\n",
        "        \"--learning_rate\", lr,\n",
        "        \"--max_epochs\", 40,\n",
        "        \"--accelerator\", \"gpu\",\n",
        "        \"--gpus\", num_gpus,\n",
        "        \"--strategy\", \"ddp\",\n",
        "        \"--num_nodes\", num_nodes,\n",
        "    ],\n",
        "    compute_target=cluster,\n",
        "    environment=env,\n",
        "    docker_runtime_config=docker_config,\n",
        "    distributed_job_config=dist_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "gather": {
          "logged": 1621434108189
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RunId: dist-bert-livedoor_1642064366_3c2ffbd7\n",
            "Web View: https://ml.azure.com/runs/dist-bert-livedoor_1642064366_3c2ffbd7?wsid=/subscriptions/902f236f-44df-463a-a5cb-1516ab2a9cd2/resourcegroups/shuit-common/workspaces/shuit-ml-workspace&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
            "\n",
            "Streaming azureml-logs/55_azureml-execution-tvmps_01347f797116d84b8079b6e9045193ede103ba5d59e24451b715f3996fa90ce3_p.txt\n",
            "========================================================================================================================\n",
            "\n",
            "2022-01-13T09:02:28Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/dist-bert-livedoor_1642064366_3c2ffbd7/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/dist-bert-livedoor_1642064366_3c2ffbd7/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=692637 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/dist-bert-livedoor_1642064366_3c2ffbd7/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
            "2022-01-13T09:02:29Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/dist-bert-livedoor_1642064366_3c2ffbd7/mounts/workspaceblobstore -- stdout/stderr: \n",
            "2022-01-13T09:02:31Z Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\n",
            ". Please ignore this if the GPUs don't utilize NVIDIA® NVLink® switches.\n",
            "2022-01-13T09:02:31Z Starting output-watcher...\n",
            "2022-01-13T09:02:31Z IsDedicatedCompute == False, starting polling for Low-Pri Preemption\n",
            "Login Succeeded\n",
            "Using default tag: latest\n",
            "latest: Pulling from azureml/azureml_c75cbecb320e3ad76de6f35541429c36\n",
            "e4ca327ec0e7: Pulling fs layer\n",
            "0f8717bf56e4: Pulling fs layer\n",
            "0464d1949430: Pulling fs layer\n",
            "c533dc60c5ee: Pulling fs layer\n",
            "288b26039e83: Pulling fs layer\n",
            "cf20c9eb5de9: Pulling fs layer\n",
            "f616e013b614: Pulling fs layer\n",
            "6cba900d614c: Pulling fs layer\n",
            "13aeed0bdc77: Pulling fs layer\n",
            "00d2ad9dc845: Pulling fs layer\n",
            "a19751b20bcc: Pulling fs layer\n",
            "d4bed8e0d72b: Pulling fs layer\n",
            "8c80873be9df: Pulling fs layer\n",
            "0660a387a3e6: Pulling fs layer\n",
            "ecba251689a3: Pulling fs layer\n",
            "1f4b68e9ba9f: Pulling fs layer\n",
            "fc72b2d13c92: Pulling fs layer\n",
            "8991c32dc04e: Pulling fs layer\n",
            "fa2593692b8d: Pulling fs layer\n",
            "53e0f7a62ce4: Pulling fs layer\n",
            "8b4801e0743b: Pulling fs layer\n",
            "755e384b11a6: Pulling fs layer\n",
            "f00a998186a2: Pulling fs layer\n",
            "d306b158cd2b: Pulling fs layer\n",
            "5042e57d7aac: Pulling fs layer\n",
            "49ee9b8e6e4d: Pulling fs layer\n",
            "c56ada557245: Pulling fs layer\n",
            "af54446bfe66: Pulling fs layer\n",
            "3f61b13aa3c4: Pulling fs layer\n",
            "ed64177b8957: Pulling fs layer\n",
            "f5da3520b6d3: Pulling fs layer\n",
            "7045f18754ae: Pulling fs layer\n",
            "8991c32dc04e: Waiting\n",
            "5042e57d7aac: Waiting\n",
            "fa2593692b8d: Waiting\n",
            "53e0f7a62ce4: Waiting\n",
            "8b4801e0743b: Waiting\n",
            "49ee9b8e6e4d: Waiting\n",
            "d306b158cd2b: Waiting\n",
            "c56ada557245: Waiting\n",
            "755e384b11a6: Waiting\n",
            "af54446bfe66: Waiting\n",
            "3f61b13aa3c4: Waiting\n",
            "288b26039e83: Waiting\n",
            "ed64177b8957: Waiting\n",
            "cf20c9eb5de9: Waiting\n",
            "f5da3520b6d3: Waiting\n",
            "f00a998186a2: Waiting\n",
            "7045f18754ae: Waiting\n",
            "a19751b20bcc: Waiting\n",
            "f616e013b614: Waiting\n",
            "d4bed8e0d72b: Waiting\n",
            "6cba900d614c: Waiting\n",
            "8c80873be9df: Waiting\n",
            "ecba251689a3: Waiting\n",
            "13aeed0bdc77: Waiting\n",
            "fc72b2d13c92: Waiting\n",
            "c533dc60c5ee: Waiting\n",
            "1f4b68e9ba9f: Waiting\n",
            "0f8717bf56e4: Verifying Checksum\n",
            "0f8717bf56e4: Download complete\n",
            "0464d1949430: Verifying Checksum\n",
            "0464d1949430: Download complete\n",
            "c533dc60c5ee: Verifying Checksum\n",
            "c533dc60c5ee: Download complete\n",
            "288b26039e83: Verifying Checksum\n",
            "288b26039e83: Download complete\n",
            "e4ca327ec0e7: Download complete\n",
            "f616e013b614: Download complete\n",
            "e4ca327ec0e7: Pull complete\n",
            "13aeed0bdc77: Download complete\n",
            "0f8717bf56e4: Pull complete\n",
            "0464d1949430: Pull complete\n",
            "c533dc60c5ee: Pull complete\n",
            "288b26039e83: Pull complete\n",
            "00d2ad9dc845: Verifying Checksum\n",
            "00d2ad9dc845: Download complete\n",
            "a19751b20bcc: Verifying Checksum\n",
            "a19751b20bcc: Download complete\n",
            "6cba900d614c: Verifying Checksum\n",
            "6cba900d614c: Download complete\n",
            "d4bed8e0d72b: Verifying Checksum\n",
            "d4bed8e0d72b: Download complete\n",
            "8c80873be9df: Verifying Checksum\n",
            "8c80873be9df: Download complete\n",
            "ecba251689a3: Verifying Checksum\n",
            "ecba251689a3: Download complete\n",
            "0660a387a3e6: Verifying Checksum\n",
            "0660a387a3e6: Download complete\n",
            "1f4b68e9ba9f: Verifying Checksum\n",
            "1f4b68e9ba9f: Download complete\n",
            "fc72b2d13c92: Verifying Checksum\n",
            "fc72b2d13c92: Download complete\n",
            "8991c32dc04e: Verifying Checksum\n",
            "8991c32dc04e: Download complete\n",
            "53e0f7a62ce4: Verifying Checksum\n",
            "53e0f7a62ce4: Download complete\n",
            "fa2593692b8d: Verifying Checksum\n",
            "fa2593692b8d: Download complete\n",
            "755e384b11a6: Download complete\n",
            "8b4801e0743b: Verifying Checksum\n",
            "8b4801e0743b: Download complete\n",
            "f00a998186a2: Verifying Checksum\n",
            "f00a998186a2: Download complete\n",
            "d306b158cd2b: Verifying Checksum\n",
            "d306b158cd2b: Download complete\n",
            "49ee9b8e6e4d: Download complete\n",
            "5042e57d7aac: Download complete\n",
            "af54446bfe66: Verifying Checksum\n",
            "af54446bfe66: Download complete\n",
            "3f61b13aa3c4: Verifying Checksum\n",
            "3f61b13aa3c4: Download complete\n",
            "ed64177b8957: Verifying Checksum\n",
            "ed64177b8957: Download complete\n",
            "f5da3520b6d3: Verifying Checksum\n",
            "f5da3520b6d3: Download complete\n",
            "7045f18754ae: Verifying Checksum\n",
            "7045f18754ae: Download complete\n",
            "cf20c9eb5de9: Verifying Checksum\n",
            "cf20c9eb5de9: Download complete\n",
            "cf20c9eb5de9: Pull complete\n",
            "f616e013b614: Pull complete\n",
            "c56ada557245: Verifying Checksum\n",
            "c56ada557245: Download complete\n",
            "6cba900d614c: Pull complete\n",
            "13aeed0bdc77: Pull complete\n",
            "00d2ad9dc845: Pull complete\n",
            "a19751b20bcc: Pull complete\n",
            "d4bed8e0d72b: Pull complete\n",
            "8c80873be9df: Pull complete\n",
            "0660a387a3e6: Pull complete\n",
            "ecba251689a3: Pull complete\n",
            "1f4b68e9ba9f: Pull complete\n",
            "fc72b2d13c92: Pull complete\n",
            "8991c32dc04e: Pull complete\n",
            "fa2593692b8d: Pull complete\n",
            "53e0f7a62ce4: Pull complete\n",
            "8b4801e0743b: Pull complete\n",
            "755e384b11a6: Pull complete\n",
            "f00a998186a2: Pull complete\n",
            "d306b158cd2b: Pull complete\n",
            "5042e57d7aac: Pull complete\n",
            "49ee9b8e6e4d: Pull complete\n",
            "\n",
            "Streaming azureml-logs/65_job_prep-tvmps_01347f797116d84b8079b6e9045193ede103ba5d59e24451b715f3996fa90ce3_p.txt\n",
            "===============================================================================================================\n",
            "\n",
            "[2022-01-13T09:07:14.127814] Entering job preparation.\n",
            "[2022-01-13T09:07:20.791300] Starting job preparation.\n",
            "[2022-01-13T09:07:20.791387] Extracting the control code.\n",
            "[2022-01-13T09:07:20.791629] Starting extract_project.\n",
            "[2022-01-13T09:07:20.791680] Starting to extract zip file.\n",
            "[2022-01-13T09:07:21.099657] Finished extracting zip file.\n",
            "[2022-01-13T09:07:21.103264] Using urllib.request Python 3.0 or later\n",
            "[2022-01-13T09:07:21.103312] Start fetching snapshots.\n",
            "[2022-01-13T09:07:21.103382] Start fetching snapshot.\n",
            "Starting the daemon thread to refresh tokens in background for process with pid = 84\n",
            "[2022-01-13T09:07:24.835966] Finished fetching snapshot.\n",
            "[2022-01-13T09:07:24.836013] Finished fetching snapshots.\n",
            "[2022-01-13T09:07:24.836028] Finished extract_project.\n",
            "[2022-01-13T09:07:24.836116] Finished fetching and extracting the control code.\n",
            "[2022-01-13T09:07:24.840206] downloadDataStore - Download from datastores if requested.\n",
            "[2022-01-13T09:07:24.841201] Start run_history_prep.\n",
            "[2022-01-13T09:07:24.999540] Entering context manager injector.\n",
            "[2022-01-13T09:07:25.002708] downloadDataStore completed\n",
            "[2022-01-13T09:07:25.004588] Job preparation is complete.\n",
            "\n",
            "Streaming azureml-logs/70_driver_log_0.txt\n",
            "==========================================\n",
            "\n",
            "[2022-01-13T09:08:00.199296] Entering context manager injector.\n",
            "[2022-01-13T09:08:00.677424] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['dist_train_bert.py', '--batch_size', '64', '--max_epochs', '40', '--gpus', '1', '--strategy', 'ddp', '--num_nodes', '4'])\n",
            "This is an MPI job. Rank:0\n",
            "Script type = None\n",
            "[2022-01-13T09:08:00.681056] Entering Run History Context Manager.\n",
            "[2022-01-13T09:08:02.077381] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/dist-bert-livedoor_1642064366_3c2ffbd7/wd/azureml/dist-bert-livedoor_1642064366_3c2ffbd7\n",
            "[2022-01-13T09:08:02.077720] Preparing to call script [dist_train_bert.py] with arguments:['--batch_size', '64', '--max_epochs', '40', '--gpus', '1', '--strategy', 'ddp', '--num_nodes', '4']\n",
            "[2022-01-13T09:08:02.077781] After variable expansion, calling script [dist_train_bert.py] with arguments:['--batch_size', '64', '--max_epochs', '40', '--gpus', '1', '--strategy', 'ddp', '--num_nodes', '4']\n",
            "\n",
            "Global seed set to 1234\n",
            "MASTER_ADDR = 10.0.0.4\n",
            "MASTER_PORT = 6105\n",
            "NODE_RANK = 0\n",
            "\n",
            "Downloading:   0%|          | 0.00/252k [00:00<?, ?B/s]\n",
            "Downloading:   2%|▏         | 4.00k/252k [00:00<00:13, 18.2kB/s]\n",
            "Downloading:  14%|█▍        | 36.0k/252k [00:00<00:02, 92.5kB/s]\n",
            "Downloading:  35%|███▌      | 89.0k/252k [00:00<00:01, 159kB/s] \n",
            "Downloading:  80%|███████▉  | 201k/252k [00:00<00:00, 295kB/s] \n",
            "Downloading: 100%|██████████| 252k/252k [00:00<00:00, 283kB/s]\n",
            "\n",
            "Downloading:   0%|          | 0.00/110 [00:00<?, ?B/s]\n",
            "Downloading: 100%|██████████| 110/110 [00:00<00:00, 87.0kB/s]\n",
            "\n",
            "Downloading:   0%|          | 0.00/479 [00:00<?, ?B/s]\n",
            "Downloading: 100%|██████████| 479/479 [00:00<00:00, 411kB/s]\n",
            "\n",
            "Downloading:   0%|          | 0.00/424M [00:00<?, ?B/s]\n",
            "Downloading:   1%|          | 3.40M/424M [00:00<00:12, 35.4MB/s]\n",
            "Downloading:   2%|▏         | 6.77M/424M [00:00<00:13, 32.8MB/s]\n",
            "Downloading:   3%|▎         | 13.7M/424M [00:00<00:08, 49.8MB/s]\n",
            "Downloading:   5%|▍         | 20.5M/424M [00:00<00:07, 58.2MB/s]\n",
            "Downloading:   6%|▋         | 26.6M/424M [00:00<00:06, 60.2MB/s]\n",
            "Downloading:   8%|▊         | 34.0M/424M [00:00<00:06, 66.1MB/s]\n",
            "Downloading:  10%|▉         | 40.8M/424M [00:00<00:05, 67.8MB/s]\n",
            "Downloading:  11%|█         | 47.5M/424M [00:00<00:05, 68.6MB/s]\n",
            "Downloading:  13%|█▎        | 54.1M/424M [00:00<00:07, 55.0MB/s]\n",
            "Downloading:  14%|█▍        | 60.0M/424M [00:01<00:06, 56.9MB/s]\n",
            "Downloading:  15%|█▌        | 65.8M/424M [00:01<00:06, 57.1MB/s]\n",
            "Downloading:  17%|█▋        | 71.4M/424M [00:01<00:06, 57.1MB/s]\n",
            "Downloading:  18%|█▊        | 77.6M/424M [00:01<00:06, 59.2MB/s]\n",
            "Downloading:  20%|█▉        | 84.0M/424M [00:01<00:05, 61.4MB/s]\n",
            "Downloading:  22%|██▏       | 91.3M/424M [00:01<00:05, 66.0MB/s]\n",
            "Downloading:  23%|██▎       | 98.8M/424M [00:01<00:04, 69.5MB/s]\n",
            "Downloading:  25%|██▍       | 106M/424M [00:01<00:04, 70.5MB/s] \n",
            "Downloading:  27%|██▋       | 112M/424M [00:01<00:04, 70.7MB/s]\n",
            "Downloading:  28%|██▊       | 119M/424M [00:02<00:04, 70.6MB/s]\n",
            "Downloading:  30%|██▉       | 127M/424M [00:02<00:04, 72.6MB/s]\n",
            "Downloading:  32%|███▏      | 134M/424M [00:02<00:04, 73.6MB/s]\n",
            "Downloading:  33%|███▎      | 141M/424M [00:02<00:04, 68.4MB/s]\n",
            "Downloading:  35%|███▍      | 148M/424M [00:02<00:04, 69.0MB/s]\n",
            "Downloading:  36%|███▋      | 154M/424M [00:02<00:04, 68.5MB/s]\n",
            "Downloading:  38%|███▊      | 161M/424M [00:02<00:04, 59.5MB/s]\n",
            "Downloading:  40%|███▉      | 168M/424M [00:02<00:04, 63.5MB/s]\n",
            "Downloading:  41%|████      | 175M/424M [00:02<00:03, 65.7MB/s]\n",
            "Downloading:  43%|████▎     | 182M/424M [00:02<00:03, 68.6MB/s]\n",
            "Downloading:  44%|████▍     | 189M/424M [00:03<00:03, 69.2MB/s]\n",
            "Downloading:  46%|████▌     | 196M/424M [00:03<00:03, 70.3MB/s]\n",
            "Downloading:  48%|████▊     | 203M/424M [00:03<00:03, 72.7MB/s]\n",
            "Downloading:  50%|████▉     | 211M/424M [00:03<00:03, 74.4MB/s]\n",
            "Downloading:  51%|█████▏    | 218M/424M [00:03<00:02, 75.8MB/s]\n",
            "Downloading:  53%|█████▎    | 226M/424M [00:03<00:02, 74.5MB/s]\n",
            "Downloading:  55%|█████▍    | 233M/424M [00:03<00:02, 75.8MB/s]\n",
            "Downloading:  57%|█████▋    | 241M/424M [00:03<00:02, 76.9MB/s]\n",
            "Downloading:  58%|█████▊    | 248M/424M [00:03<00:02, 77.4MB/s]\n",
            "Downloading:  60%|██████    | 256M/424M [00:03<00:02, 77.7MB/s]\n",
            "Downloading:  62%|██████▏   | 263M/424M [00:04<00:02, 77.4MB/s]\n",
            "Downloading:  64%|██████▎   | 270M/424M [00:04<00:02, 77.5MB/s]\n",
            "Downloading:  65%|██████▌   | 278M/424M [00:04<00:01, 77.8MB/s]\n",
            "Downloading:  67%|██████▋   | 285M/424M [00:04<00:01, 78.1MB/s]\n",
            "Downloading:  69%|██████▉   | 293M/424M [00:04<00:01, 77.0MB/s]\n",
            "Downloading:  71%|███████   | 300M/424M [00:04<00:01, 77.3MB/s]\n",
            "Downloading:  73%|███████▎  | 308M/424M [00:04<00:01, 78.0MB/s]\n",
            "Downloading:  74%|███████▍  | 316M/424M [00:04<00:01, 78.5MB/s]\n",
            "Downloading:  76%|███████▌  | 323M/424M [00:04<00:01, 71.4MB/s]\n",
            "Downloading:  78%|███████▊  | 330M/424M [00:05<00:01, 71.4MB/s]\n",
            "Downloading:  79%|███████▉  | 337M/424M [00:05<00:01, 71.6MB/s]\n",
            "Downloading:  81%|████████  | 344M/424M [00:05<00:01, 72.0MB/s]\n",
            "Downloading:  83%|████████▎ | 351M/424M [00:05<00:01, 72.1MB/s]\n",
            "Downloading:  84%|████████▍ | 358M/424M [00:05<00:00, 72.1MB/s]\n",
            "Downloading:  86%|████████▌ | 365M/424M [00:05<00:00, 72.0MB/s]\n",
            "Downloading:  88%|████████▊ | 371M/424M [00:05<00:00, 71.3MB/s]\n",
            "Downloading:  89%|████████▉ | 378M/424M [00:05<00:00, 71.4MB/s]\n",
            "Downloading:  91%|█████████ | 385M/424M [00:05<00:00, 70.5MB/s]\n",
            "Downloading:  92%|█████████▏| 392M/424M [00:05<00:00, 70.7MB/s]\n",
            "Downloading:  94%|█████████▍| 399M/424M [00:06<00:00, 70.8MB/s]\n",
            "Downloading:  96%|█████████▌| 405M/424M [00:06<00:00, 66.5MB/s]\n",
            "Downloading:  97%|█████████▋| 412M/424M [00:06<00:00, 63.1MB/s]\n",
            "Downloading:  99%|█████████▊| 419M/424M [00:06<00:00, 65.7MB/s]\n",
            "Downloading: 100%|██████████| 424M/424M [00:06<00:00, 68.8MB/s]\n",
            "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "/azureml-envs/azureml_4066df70c487d6e2083cc11b2bc57684/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:735: LightningDeprecationWarning: `trainer.fit(train_dataloader)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.fit(train_dataloaders)` instead. HINT: added 's'\n",
            "  rank_zero_deprecation(\n",
            "Global seed set to 1234\n",
            "initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 4 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "0ff62089ea094918943234bd6c07d893000000:145:145 [0] NCCL INFO Bootstrap : Using eth0:10.0.0.4<0>\n",
            "0ff62089ea094918943234bd6c07d893000000:145:145 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation\n",
            "0ff62089ea094918943234bd6c07d893000000:145:145 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
            "0ff62089ea094918943234bd6c07d893000000:145:145 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.0.4<0>\n",
            "0ff62089ea094918943234bd6c07d893000000:145:145 [0] NCCL INFO Using network Socket\n",
            "NCCL version 2.10.3+cuda10.2\n",
            "0ff62089ea094918943234bd6c07d893000000:145:172 [0] NCCL INFO Channel 00/02 :    0   1   2   3\n",
            "0ff62089ea094918943234bd6c07d893000000:145:172 [0] NCCL INFO Channel 01/02 :    0   1   2   3\n",
            "0ff62089ea094918943234bd6c07d893000000:145:172 [0] NCCL INFO Trees [0] 2/-1/-1->0->-1 [1] -1/-1/-1->0->1\n",
            "0ff62089ea094918943234bd6c07d893000000:145:172 [0] NCCL INFO Setting affinity for GPU 0 to 3f\n",
            "0ff62089ea094918943234bd6c07d893000000:145:172 [0] NCCL INFO Channel 00 : 3[fa3700000] -> 0[5bb300000] [receive] via NET/Socket/0\n",
            "0ff62089ea094918943234bd6c07d893000000:145:172 [0] NCCL INFO Channel 01 : 3[fa3700000] -> 0[5bb300000] [receive] via NET/Socket/0\n",
            "0ff62089ea094918943234bd6c07d893000000:145:172 [0] NCCL INFO Channel 00 : 0[5bb300000] -> 1[873a00000] [send] via NET/Socket/0\n",
            "0ff62089ea094918943234bd6c07d893000000:145:172 [0] NCCL INFO Channel 01 : 0[5bb300000] -> 1[873a00000] [send] via NET/Socket/0\n",
            "0ff62089ea094918943234bd6c07d893000000:145:172 [0] NCCL INFO Connected all rings\n",
            "0ff62089ea094918943234bd6c07d893000000:145:172 [0] NCCL INFO Channel 00 : 2[bc8400000] -> 0[5bb300000] [receive] via NET/Socket/0\n",
            "0ff62089ea094918943234bd6c07d893000000:145:172 [0] NCCL INFO Channel 00 : 0[5bb300000] -> 2[bc8400000] [send] via NET/Socket/0\n",
            "0ff62089ea094918943234bd6c07d893000000:145:172 [0] NCCL INFO Channel 01 : 1[873a00000] -> 0[5bb300000] [receive] via NET/Socket/0\n",
            "0ff62089ea094918943234bd6c07d893000000:145:172 [0] NCCL INFO Connected all trees\n",
            "0ff62089ea094918943234bd6c07d893000000:145:172 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512\n",
            "0ff62089ea094918943234bd6c07d893000000:145:172 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\n",
            "0ff62089ea094918943234bd6c07d893000000:145:172 [0] NCCL INFO comm 0x7f82dc001200 rank 0 nranks 4 cudaDev 0 busId 5bb300000 - Init COMPLETE\n",
            "0ff62089ea094918943234bd6c07d893000000:145:145 [0] NCCL INFO Launch mode Parallel\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Missing logger folder: /mnt/batch/tasks/shared/LS_root/jobs/shuit-ml-workspace/azureml/dist-bert-livedoor_1642064366_3c2ffbd7/wd/azureml/dist-bert-livedoor_1642064366_3c2ffbd7/lightning_logs\n",
            "\n",
            "  | Name      | Type      | Params\n",
            "----------------------------------------\n",
            "0 | bert      | BertModel | 110 M \n",
            "1 | output    | Linear    | 6.9 K \n",
            "2 | train_acc | Accuracy  | 0     \n",
            "3 | val_acc   | Accuracy  | 0     \n",
            "4 | test_acc  | Accuracy  | 0     \n",
            "----------------------------------------\n",
            "7.1 M     Trainable params\n",
            "103 M     Non-trainable params\n",
            "110 M     Total params\n",
            "442.497   Total estimated model params size (MB)\n",
            "\n",
            "Validation sanity check: 0it [00:00, ?it/s]/azureml-envs/azureml_4066df70c487d6e2083cc11b2bc57684/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "\n",
            "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]\n",
            "Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  6.70it/s]\n",
            "Validation sanity check: 100%|██████████| 2/2 [00:00<00:00,  7.86it/s]\n",
            "                                                                      \n",
            "Global seed set to 1234\n",
            "/azureml-envs/azureml_4066df70c487d6e2083cc11b2bc57684/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "/azureml-envs/azureml_4066df70c487d6e2083cc11b2bc57684/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:428: UserWarning: The number of training samples (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  rank_zero_warn(\n",
            "\n",
            "Training: 0it [00:00, ?it/s]\n",
            "Training:   0%|          | 0/27 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/27 [00:00<?, ?it/s] [W reducer.cpp:1303] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
            "\n",
            "Epoch 0:   4%|▎         | 1/27 [00:00<00:07,  3.48it/s]\n",
            "Epoch 0:   4%|▎         | 1/27 [00:00<00:07,  3.47it/s, loss=2.2, v_num=0, loss_step=2.200]\n",
            "Epoch 0:   7%|▋         | 2/27 [00:00<00:06,  3.83it/s, loss=2.2, v_num=0, loss_step=2.200]\n",
            "Epoch 0:   7%|▋         | 2/27 [00:00<00:06,  3.83it/s, loss=2.2, v_num=0, loss_step=2.200]\n",
            "Epoch 0:  11%|█         | 3/27 [00:00<00:06,  3.72it/s, loss=2.2, v_num=0, loss_step=2.200]\n",
            "Epoch 0:  11%|█         | 3/27 [00:00<00:06,  3.72it/s, loss=2.2, v_num=0, loss_step=2.200]\n",
            "Epoch 0:  15%|█▍        | 4/27 [00:01<00:06,  3.82it/s, loss=2.2, v_num=0, loss_step=2.200]\n",
            "Epoch 0:  15%|█▍        | 4/27 [00:01<00:06,  3.82it/s, loss=2.19, v_num=0, loss_step=2.150]\n",
            "Epoch 0:  19%|█▊        | 5/27 [00:01<00:05,  3.81it/s, loss=2.19, v_num=0, loss_step=2.150]\n",
            "Epoch 0:  19%|█▊        | 5/27 [00:01<00:05,  3.81it/s, loss=2.2, v_num=0, loss_step=2.260] \n",
            "Epoch 0:  22%|██▏       | 6/27 [00:01<00:05,  3.85it/s, loss=2.2, v_num=0, loss_step=2.260]\n",
            "Epoch 0:  22%|██▏       | 6/27 [00:01<00:05,  3.85it/s, loss=2.2, v_num=0, loss_step=2.210]\n",
            "Epoch 0:  26%|██▌       | 7/27 [00:01<00:05,  3.88it/s, loss=2.2, v_num=0, loss_step=2.210]\n",
            "Epoch 0:  26%|██▌       | 7/27 [00:01<00:05,  3.87it/s, loss=2.21, v_num=0, loss_step=2.230]\n",
            "Epoch 0:  30%|██▉       | 8/27 [00:02<00:04,  3.89it/s, loss=2.21, v_num=0, loss_step=2.230]\n",
            "Epoch 0:  30%|██▉       | 8/27 [00:02<00:04,  3.89it/s, loss=2.21, v_num=0, loss_step=2.270]\n",
            "Epoch 0:  33%|███▎      | 9/27 [00:02<00:04,  3.90it/s, loss=2.21, v_num=0, loss_step=2.270]\n",
            "Epoch 0:  33%|███▎      | 9/27 [00:02<00:04,  3.89it/s, loss=2.22, v_num=0, loss_step=2.260]\n",
            "Epoch 0:  37%|███▋      | 10/27 [00:02<00:04,  3.93it/s, loss=2.22, v_num=0, loss_step=2.260]\n",
            "Epoch 0:  37%|███▋      | 10/27 [00:02<00:04,  3.92it/s, loss=2.22, v_num=0, loss_step=2.200]\n",
            "Epoch 0:  41%|████      | 11/27 [00:02<00:04,  3.92it/s, loss=2.22, v_num=0, loss_step=2.200]\n",
            "Epoch 0:  41%|████      | 11/27 [00:02<00:04,  3.92it/s, loss=2.21, v_num=0, loss_step=2.150]\n",
            "Epoch 0:  44%|████▍     | 12/27 [00:03<00:03,  3.93it/s, loss=2.21, v_num=0, loss_step=2.150]\n",
            "Epoch 0:  44%|████▍     | 12/27 [00:03<00:03,  3.93it/s, loss=2.21, v_num=0, loss_step=2.220]\n",
            "Epoch 0:  48%|████▊     | 13/27 [00:03<00:03,  3.91it/s, loss=2.21, v_num=0, loss_step=2.220]\n",
            "Epoch 0:  48%|████▊     | 13/27 [00:03<00:03,  3.91it/s, loss=2.21, v_num=0, loss_step=2.200]\n",
            "Epoch 0:  52%|█████▏    | 14/27 [00:03<00:03,  3.92it/s, loss=2.21, v_num=0, loss_step=2.200]\n",
            "Epoch 0:  52%|█████▏    | 14/27 [00:03<00:03,  3.92it/s, loss=2.21, v_num=0, loss_step=2.180]\n",
            "Epoch 0:  56%|█████▌    | 15/27 [00:03<00:03,  3.94it/s, loss=2.21, v_num=0, loss_step=2.180]\n",
            "Epoch 0:  56%|█████▌    | 15/27 [00:03<00:03,  3.94it/s, loss=2.21, v_num=0, loss_step=2.290]\n",
            "Epoch 0:  59%|█████▉    | 16/27 [00:04<00:02,  3.96it/s, loss=2.21, v_num=0, loss_step=2.290]\n",
            "Epoch 0:  59%|█████▉    | 16/27 [00:04<00:02,  3.96it/s, loss=2.22, v_num=0, loss_step=2.250]\n",
            "Epoch 0:  63%|██████▎   | 17/27 [00:04<00:02,  3.96it/s, loss=2.22, v_num=0, loss_step=2.250]\n",
            "Epoch 0:  63%|██████▎   | 17/27 [00:04<00:02,  3.96it/s, loss=2.21, v_num=0, loss_step=2.180]\n",
            "Epoch 0:  67%|██████▋   | 18/27 [00:04<00:02,  3.93it/s, loss=2.21, v_num=0, loss_step=2.180]\n",
            "Epoch 0:  67%|██████▋   | 18/27 [00:04<00:02,  3.93it/s, loss=2.21, v_num=0, loss_step=2.210]\n",
            "Epoch 0:  70%|███████   | 19/27 [00:04<00:02,  3.92it/s, loss=2.21, v_num=0, loss_step=2.210]\n",
            "Epoch 0:  70%|███████   | 19/27 [00:04<00:02,  3.92it/s, loss=2.21, v_num=0, loss_step=2.220]\n",
            "Epoch 0:  74%|███████▍  | 20/27 [00:05<00:01,  3.92it/s, loss=2.21, v_num=0, loss_step=2.220]\n",
            "Epoch 0:  74%|███████▍  | 20/27 [00:05<00:01,  3.92it/s, loss=2.21, v_num=0, loss_step=2.220]\n",
            "Epoch 0:  78%|███████▊  | 21/27 [00:05<00:01,  3.93it/s, loss=2.21, v_num=0, loss_step=2.220]\n",
            "Epoch 0:  78%|███████▊  | 21/27 [00:05<00:01,  3.93it/s, loss=2.21, v_num=0, loss_step=2.180]\n",
            "Epoch 0:  81%|████████▏ | 22/27 [00:05<00:01,  3.94it/s, loss=2.21, v_num=0, loss_step=2.180]\n",
            "Epoch 0:  81%|████████▏ | 22/27 [00:05<00:01,  3.94it/s, loss=2.22, v_num=0, loss_step=2.260]\n",
            "Epoch 0:  85%|████████▌ | 23/27 [00:05<00:01,  3.95it/s, loss=2.22, v_num=0, loss_step=2.260]\n",
            "Epoch 0:  85%|████████▌ | 23/27 [00:05<00:01,  3.95it/s, loss=2.22, v_num=0, loss_step=2.230]\n",
            "Epoch 0:  89%|████████▉ | 24/27 [00:05<00:00,  4.03it/s, loss=2.22, v_num=0, loss_step=2.230]\n",
            "Epoch 0:  89%|████████▉ | 24/27 [00:05<00:00,  4.03it/s, loss=2.21, v_num=0, loss_step=2.040]\n",
            "\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "\n",
            "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validating:  33%|███▎      | 1/3 [00:00<00:00,  6.96it/s]\u001b[A\n",
            "Epoch 0:  96%|█████████▋| 26/27 [00:06<00:00,  4.26it/s, loss=2.21, v_num=0, loss_step=2.040]\n",
            "\n",
            "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  8.03it/s]\u001b[A\n",
            "Epoch 0: 100%|██████████| 27/27 [00:06<00:00,  4.26it/s, loss=2.21, v_num=0, loss_step=2.040]\n",
            "\n",
            "                                                         \u001b[A[{'loss': tensor([2.1980, 2.1978, 2.2052, 2.1965], device='cuda:0')}, {'loss': tensor([2.2006, 2.2544, 2.1590, 2.2307], device='cuda:0')}, {'loss': tensor([2.1966, 2.1403, 2.1606, 2.1754], device='cuda:0')}, {'loss': tensor([2.1511, 2.0321, 2.0956, 2.1857], device='cuda:0')}, {'loss': tensor([2.2564, 2.1187, 2.1608, 2.1089], device='cuda:0')}, {'loss': tensor([2.2111, 2.0312, 2.1372, 2.0581], device='cuda:0')}, {'loss': tensor([2.2254, 2.0686, 2.0478, 1.9734], device='cuda:0')}, {'loss': tensor([2.2749, 2.0800, 2.0763, 2.0473], device='cuda:0')}, {'loss': tensor([2.2563, 2.0507, 2.2291, 2.0508], device='cuda:0')}, {'loss': tensor([2.1983, 2.0157, 2.1321, 2.0775], device='cuda:0')}, {'loss': tensor([2.1453, 2.0334, 2.1896, 1.9558], device='cuda:0')}, {'loss': tensor([2.2204, 2.1299, 2.1980, 2.0632], device='cuda:0')}, {'loss': tensor([2.2014, 2.0443, 2.1129, 2.0678], device='cuda:0')}, {'loss': tensor([2.1833, 2.0097, 2.1182, 2.0161], device='cuda:0')}, {'loss': tensor([2.2865, 2.0420, 1.9989, 2.0361], device='cuda:0')}, {'loss': tensor([2.2467, 2.0049, 2.1026, 2.1322], device='cuda:0')}, {'loss': tensor([2.1806, 2.0295, 2.0832, 2.0411], device='cuda:0')}, {'loss': tensor([2.2076, 1.9709, 2.1029, 1.9186], device='cuda:0')}, {'loss': tensor([2.2220, 2.0798, 1.9965, 1.9623], device='cuda:0')}, {'loss': tensor([2.2224, 2.1071, 2.0673, 1.8855], device='cuda:0')}, {'loss': tensor([2.1798, 2.1370, 2.0126, 2.0420], device='cuda:0')}, {'loss': tensor([2.2571, 2.0616, 1.9630, 1.9431], device='cuda:0')}, {'loss': tensor([2.2317, 2.0600, 2.0193, 1.9895], device='cuda:0')}, {'loss': tensor([2.0386, 1.7053, 2.3719, 1.5546], device='cuda:0')}]\n",
            "\n",
            "Epoch 0: 100%|██████████| 27/27 [00:06<00:00,  4.20it/s, loss=2.21, v_num=0, loss_step=2.040, loss_epoch=2.110]\n",
            "Epoch 0:   0%|          | 0/27 [00:00<?, ?it/s, loss=2.21, v_num=0, loss_step=2.040, loss_epoch=2.110]         \n",
            "Epoch 1:   0%|          | 0/27 [00:00<?, ?it/s, loss=2.21, v_num=0, loss_step=2.040, loss_epoch=2.110]\n",
            "Epoch 1:   4%|▎         | 1/27 [00:00<00:06,  4.18it/s, loss=2.21, v_num=0, loss_step=2.180, loss_epoch=2.110]\n",
            "Epoch 1:   7%|▋         | 2/27 [00:00<00:06,  3.98it/s, loss=2.21, v_num=0, loss_step=2.180, loss_epoch=2.110]\n",
            "Epoch 1:   7%|▋         | 2/27 [00:00<00:06,  3.98it/s, loss=2.21, v_num=0, loss_step=2.230, loss_epoch=2.110]\n",
            "Epoch 1:  11%|█         | 3/27 [00:00<00:06,  3.95it/s, loss=2.21, v_num=0, loss_step=2.180, loss_epoch=2.110]\n",
            "Epoch 1:  15%|█▍        | 4/27 [00:00<00:05,  4.02it/s, loss=2.21, v_num=0, loss_step=2.180, loss_epoch=2.110]\n",
            "Epoch 1:  15%|█▍        | 4/27 [00:00<00:05,  4.02it/s, loss=2.21, v_num=0, loss_step=2.270, loss_epoch=2.110]\n",
            "Epoch 1:  19%|█▊        | 5/27 [00:01<00:05,  4.04it/s, loss=2.2, v_num=0, loss_step=2.200, loss_epoch=2.110] \n",
            "Epoch 1:  22%|██▏       | 6/27 [00:01<00:05,  3.99it/s, loss=2.2, v_num=0, loss_step=2.200, loss_epoch=2.110]\n",
            "Epoch 1:  22%|██▏       | 6/27 [00:01<00:05,  3.99it/s, loss=2.21, v_num=0, loss_step=2.240, loss_epoch=2.110]\n",
            "Epoch 1:  26%|██▌       | 7/27 [00:01<00:04,  4.00it/s, loss=2.21, v_num=0, loss_step=2.210, loss_epoch=2.110]\n",
            "Epoch 1:  30%|██▉       | 8/27 [00:02<00:04,  3.97it/s, loss=2.21, v_num=0, loss_step=2.210, loss_epoch=2.110]\n",
            "Epoch 1:  30%|██▉       | 8/27 [00:02<00:04,  3.97it/s, loss=2.21, v_num=0, loss_step=2.190, loss_epoch=2.110]\n",
            "Epoch 1:  33%|███▎      | 9/27 [00:02<00:04,  4.00it/s, loss=2.21, v_num=0, loss_step=2.270, loss_epoch=2.110]\n",
            "Epoch 1:  37%|███▋      | 10/27 [00:02<00:04,  4.04it/s, loss=2.21, v_num=0, loss_step=2.270, loss_epoch=2.110]\n",
            "Epoch 1:  37%|███▋      | 10/27 [00:02<00:04,  4.04it/s, loss=2.22, v_num=0, loss_step=2.270, loss_epoch=2.110]\n",
            "Epoch 1:  41%|████      | 11/27 [00:02<00:03,  4.01it/s, loss=2.21, v_num=0, loss_step=2.230, loss_epoch=2.110]\n",
            "Epoch 1:  44%|████▍     | 12/27 [00:02<00:03,  4.00it/s, loss=2.21, v_num=0, loss_step=2.230, loss_epoch=2.110]\n",
            "Epoch 1:  44%|████▍     | 12/27 [00:02<00:03,  4.00it/s, loss=2.21, v_num=0, loss_step=2.230, loss_epoch=2.110]\n",
            "Epoch 1:  48%|████▊     | 13/27 [00:03<00:03,  3.99it/s, loss=2.21, v_num=0, loss_step=2.180, loss_epoch=2.110]\n",
            "Epoch 1:  52%|█████▏    | 14/27 [00:03<00:03,  3.99it/s, loss=2.21, v_num=0, loss_step=2.180, loss_epoch=2.110]\n",
            "Epoch 1:  52%|█████▏    | 14/27 [00:03<00:03,  3.99it/s, loss=2.22, v_num=0, loss_step=2.270, loss_epoch=2.110]\n",
            "Epoch 1:  56%|█████▌    | 15/27 [00:03<00:03,  3.98it/s, loss=2.21, v_num=0, loss_step=2.190, loss_epoch=2.110]\n",
            "Epoch 1:  59%|█████▉    | 16/27 [00:04<00:02,  3.97it/s, loss=2.21, v_num=0, loss_step=2.190, loss_epoch=2.110]\n",
            "Epoch 1:  59%|█████▉    | 16/27 [00:04<00:02,  3.97it/s, loss=2.21, v_num=0, loss_step=2.200, loss_epoch=2.110]\n",
            "Epoch 1:  63%|██████▎   | 17/27 [00:04<00:02,  3.92it/s, loss=2.22, v_num=0, loss_step=2.260, loss_epoch=2.110]\n",
            "Epoch 1:  67%|██████▋   | 18/27 [00:04<00:02,  3.91it/s, loss=2.22, v_num=0, loss_step=2.260, loss_epoch=2.110]\n",
            "Epoch 1:  67%|██████▋   | 18/27 [00:04<00:02,  3.91it/s, loss=2.21, v_num=0, loss_step=2.130, loss_epoch=2.110]\n",
            "Epoch 1:  70%|███████   | 19/27 [00:04<00:02,  3.87it/s, loss=2.21, v_num=0, loss_step=2.200, loss_epoch=2.110]\n",
            "Epoch 1:  74%|███████▍  | 20/27 [00:05<00:01,  3.87it/s, loss=2.21, v_num=0, loss_step=2.200, loss_epoch=2.110]\n",
            "Epoch 1:  74%|███████▍  | 20/27 [00:05<00:01,  3.87it/s, loss=2.22, v_num=0, loss_step=2.190, loss_epoch=2.110]\n",
            "Epoch 1:  78%|███████▊  | 21/27 [00:05<00:01,  3.88it/s, loss=2.22, v_num=0, loss_step=2.240, loss_epoch=2.110]\n",
            "Epoch 1:  81%|████████▏ | 22/27 [00:05<00:01,  3.90it/s, loss=2.22, v_num=0, loss_step=2.240, loss_epoch=2.110]\n",
            "Epoch 1:  81%|████████▏ | 22/27 [00:05<00:01,  3.90it/s, loss=2.22, v_num=0, loss_step=2.280, loss_epoch=2.110]\n",
            "Epoch 1:  85%|████████▌ | 23/27 [00:05<00:01,  3.91it/s, loss=2.22, v_num=0, loss_step=2.210, loss_epoch=2.110]\n",
            "Epoch 1:  89%|████████▉ | 24/27 [00:06<00:00,  4.00it/s, loss=2.22, v_num=0, loss_step=2.210, loss_epoch=2.110]\n",
            "Epoch 1:  89%|████████▉ | 24/27 [00:06<00:00,  4.00it/s, loss=2.21, v_num=0, loss_step=2.040, loss_epoch=2.110]\n",
            "\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "\n",
            "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validating:  33%|███▎      | 1/3 [00:00<00:00,  6.98it/s]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 26/27 [00:06<00:00,  4.23it/s, loss=2.21, v_num=0, loss_step=2.040, loss_epoch=2.110]\n",
            "\n",
            "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  8.04it/s]\u001b[A\n",
            "Epoch 1: 100%|██████████| 27/27 [00:06<00:00,  4.23it/s, loss=2.21, v_num=0, loss_step=2.040, loss_epoch=2.110]\n",
            "\n",
            "                                                         \u001b[A[{'loss': tensor([2.1767, 2.0417, 2.0370, 1.9497], device='cuda:0')}, {'loss': tensor([2.2291, 2.1439, 2.1100, 1.9842], device='cuda:0')}, {'loss': tensor([2.1842, 1.9880, 2.1374, 1.9507], device='cuda:0')}, {'loss': tensor([2.2703, 1.9969, 2.0966, 2.1110], device='cuda:0')}, {'loss': tensor([2.1976, 1.9944, 2.0826, 2.0442], device='cuda:0')}, {'loss': tensor([2.2450, 1.9682, 2.0910, 2.0275], device='cuda:0')}, {'loss': tensor([2.2119, 1.9118, 2.0869, 2.0852], device='cuda:0')}, {'loss': tensor([2.1919, 2.0121, 2.0166, 2.0882], device='cuda:0')}, {'loss': tensor([2.2710, 2.0496, 2.0208, 1.9976], device='cuda:0')}, {'loss': tensor([2.2720, 2.0070, 2.0276, 2.0497], device='cuda:0')}, {'loss': tensor([2.2275, 2.0428, 2.0658, 2.0871], device='cuda:0')}, {'loss': tensor([2.2319, 1.8850, 1.9402, 1.9861], device='cuda:0')}, {'loss': tensor([2.1800, 1.9786, 2.0007, 2.0213], device='cuda:0')}, {'loss': tensor([2.2712, 1.9759, 1.9788, 2.0016], device='cuda:0')}, {'loss': tensor([2.1921, 1.9545, 1.9035, 2.1112], device='cuda:0')}, {'loss': tensor([2.1992, 1.9816, 1.9532, 2.1444], device='cuda:0')}, {'loss': tensor([2.2606, 2.1036, 2.0932, 2.0697], device='cuda:0')}, {'loss': tensor([2.1342, 2.0040, 2.0886, 2.0566], device='cuda:0')}, {'loss': tensor([2.1993, 2.0666, 2.0885, 2.0421], device='cuda:0')}, {'loss': tensor([2.1872, 2.0144, 2.0412, 1.9315], device='cuda:0')}, {'loss': tensor([2.2398, 1.9239, 1.9678, 2.1057], device='cuda:0')}, {'loss': tensor([2.2759, 1.8862, 2.0197, 2.0438], device='cuda:0')}, {'loss': tensor([2.2073, 2.0082, 2.0519, 2.0352], device='cuda:0')}, {'loss': tensor([2.0386, 1.4578, 1.7053, 2.0717], device='cuda:0')}]\n",
            "\n",
            "Epoch 1: 100%|██████████| 27/27 [00:06<00:00,  4.16it/s, loss=2.21, v_num=0, loss_step=2.040, loss_epoch=2.070]\n",
            "Epoch 1:   0%|          | 0/27 [00:00<?, ?it/s, loss=2.21, v_num=0, loss_step=2.040, loss_epoch=2.070]         \n",
            "Epoch 2:   0%|          | 0/27 [00:00<?, ?it/s, loss=2.21, v_num=0, loss_step=2.040, loss_epoch=2.070]\n",
            "Epoch 2:   4%|▎         | 1/27 [00:00<00:06,  3.99it/s, loss=2.21, v_num=0, loss_step=2.230, loss_epoch=2.070]\n",
            "Epoch 2:   7%|▋         | 2/27 [00:00<00:06,  4.04it/s, loss=2.21, v_num=0, loss_step=2.230, loss_epoch=2.070]\n",
            "Epoch 2:   7%|▋         | 2/27 [00:00<00:06,  4.03it/s, loss=2.22, v_num=0, loss_step=2.300, loss_epoch=2.070]\n",
            "Epoch 2:  11%|█         | 3/27 [00:00<00:05,  4.11it/s, loss=2.22, v_num=0, loss_step=2.220, loss_epoch=2.070]\n",
            "Epoch 2:  15%|█▍        | 4/27 [00:00<00:05,  4.07it/s, loss=2.22, v_num=0, loss_step=2.220, loss_epoch=2.070]\n",
            "Epoch 2:  15%|█▍        | 4/27 [00:00<00:05,  4.07it/s, loss=2.22, v_num=0, loss_step=2.180, loss_epoch=2.070]\n",
            "Epoch 2:  19%|█▊        | 5/27 [00:01<00:05,  4.09it/s, loss=2.21, v_num=0, loss_step=2.240, loss_epoch=2.070]\n",
            "Epoch 2:  22%|██▏       | 6/27 [00:01<00:05,  4.14it/s, loss=2.21, v_num=0, loss_step=2.240, loss_epoch=2.070]\n",
            "Epoch 2:  22%|██▏       | 6/27 [00:01<00:05,  4.14it/s, loss=2.21, v_num=0, loss_step=2.250, loss_epoch=2.070]\n",
            "Epoch 2:  26%|██▌       | 7/27 [00:01<00:04,  4.13it/s, loss=2.21, v_num=0, loss_step=2.210, loss_epoch=2.070]\n",
            "Epoch 2:  30%|██▉       | 8/27 [00:01<00:04,  4.16it/s, loss=2.21, v_num=0, loss_step=2.210, loss_epoch=2.070]\n",
            "Epoch 2:  30%|██▉       | 8/27 [00:01<00:04,  4.16it/s, loss=2.21, v_num=0, loss_step=2.210, loss_epoch=2.070]\n",
            "Epoch 2:  33%|███▎      | 9/27 [00:02<00:04,  4.12it/s, loss=2.21, v_num=0, loss_step=2.130, loss_epoch=2.070]\n",
            "Epoch 2:  37%|███▋      | 10/27 [00:02<00:04,  4.13it/s, loss=2.21, v_num=0, loss_step=2.130, loss_epoch=2.070]\n",
            "Epoch 2:  37%|███▋      | 10/27 [00:02<00:04,  4.13it/s, loss=2.2, v_num=0, loss_step=2.170, loss_epoch=2.070] \n",
            "Epoch 2:  41%|████      | 11/27 [00:02<00:03,  4.12it/s, loss=2.2, v_num=0, loss_step=2.200, loss_epoch=2.070]\n",
            "Epoch 2:  44%|████▍     | 12/27 [00:02<00:03,  4.11it/s, loss=2.2, v_num=0, loss_step=2.200, loss_epoch=2.070]\n",
            "Epoch 2:  44%|████▍     | 12/27 [00:02<00:03,  4.11it/s, loss=2.21, v_num=0, loss_step=2.210, loss_epoch=2.070]\n",
            "Epoch 2:  48%|████▊     | 13/27 [00:03<00:03,  4.13it/s, loss=2.2, v_num=0, loss_step=2.230, loss_epoch=2.070] \n",
            "Epoch 2:  52%|█████▏    | 14/27 [00:03<00:03,  4.13it/s, loss=2.2, v_num=0, loss_step=2.230, loss_epoch=2.070]\n",
            "Epoch 2:  52%|█████▏    | 14/27 [00:03<00:03,  4.13it/s, loss=2.21, v_num=0, loss_step=2.150, loss_epoch=2.070]\n",
            "Epoch 2:  56%|█████▌    | 15/27 [00:03<00:02,  4.14it/s, loss=2.2, v_num=0, loss_step=2.110, loss_epoch=2.070] \n",
            "Epoch 2:  59%|█████▉    | 16/27 [00:03<00:02,  4.14it/s, loss=2.2, v_num=0, loss_step=2.110, loss_epoch=2.070]\n",
            "Epoch 2:  59%|█████▉    | 16/27 [00:03<00:02,  4.14it/s, loss=2.2, v_num=0, loss_step=2.210, loss_epoch=2.070]\n",
            "Epoch 2:  63%|██████▎   | 17/27 [00:04<00:02,  4.16it/s, loss=2.2, v_num=0, loss_step=2.130, loss_epoch=2.070]\n",
            "Epoch 2:  67%|██████▋   | 18/27 [00:04<00:02,  4.15it/s, loss=2.2, v_num=0, loss_step=2.130, loss_epoch=2.070]\n",
            "Epoch 2:  67%|██████▋   | 18/27 [00:04<00:02,  4.15it/s, loss=2.19, v_num=0, loss_step=2.240, loss_epoch=2.070]\n",
            "Epoch 2:  70%|███████   | 19/27 [00:04<00:01,  4.16it/s, loss=2.19, v_num=0, loss_step=2.170, loss_epoch=2.070]\n",
            "Epoch 2:  74%|███████▍  | 20/27 [00:04<00:01,  4.15it/s, loss=2.19, v_num=0, loss_step=2.170, loss_epoch=2.070]\n",
            "Epoch 2:  74%|███████▍  | 20/27 [00:04<00:01,  4.15it/s, loss=2.2, v_num=0, loss_step=2.140, loss_epoch=2.070] \n",
            "Epoch 2:  78%|███████▊  | 21/27 [00:05<00:01,  4.12it/s, loss=2.2, v_num=0, loss_step=2.200, loss_epoch=2.070]\n",
            "Epoch 2:  81%|████████▏ | 22/27 [00:05<00:01,  4.07it/s, loss=2.2, v_num=0, loss_step=2.200, loss_epoch=2.070]\n",
            "Epoch 2:  81%|████████▏ | 22/27 [00:05<00:01,  4.07it/s, loss=2.19, v_num=0, loss_step=2.120, loss_epoch=2.070]\n",
            "Epoch 2:  85%|████████▌ | 23/27 [00:05<00:00,  4.08it/s, loss=2.19, v_num=0, loss_step=2.200, loss_epoch=2.070]\n",
            "Epoch 2:  89%|████████▉ | 24/27 [00:05<00:00,  4.16it/s, loss=2.19, v_num=0, loss_step=2.200, loss_epoch=2.070]\n",
            "Epoch 2:  89%|████████▉ | 24/27 [00:05<00:00,  4.16it/s, loss=2.2, v_num=0, loss_step=2.370, loss_epoch=2.070] \n",
            "\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "\n",
            "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validating:  33%|███▎      | 1/3 [00:00<00:00,  6.99it/s]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 26/27 [00:05<00:00,  4.39it/s, loss=2.2, v_num=0, loss_step=2.370, loss_epoch=2.070]\n",
            "\n",
            "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  8.04it/s]\u001b[A\n",
            "Epoch 2: 100%|██████████| 27/27 [00:06<00:00,  4.39it/s, loss=2.2, v_num=0, loss_step=2.370, loss_epoch=2.070]\n",
            "\n",
            "                                                         \u001b[A[{'loss': tensor([2.2328, 1.9280, 2.0700, 2.0854], device='cuda:0')}, {'loss': tensor([2.2961, 1.9636, 2.0375, 1.9889], device='cuda:0')}, {'loss': tensor([2.2224, 1.9063, 2.1301, 2.0989], device='cuda:0')}, {'loss': tensor([2.1818, 2.0521, 2.1071, 2.1814], device='cuda:0')}, {'loss': tensor([2.2440, 1.9931, 2.0446, 2.0722], device='cuda:0')}, {'loss': tensor([2.2533, 1.9591, 2.0881, 2.1305], device='cuda:0')}, {'loss': tensor([2.2081, 1.9505, 2.0793, 2.1226], device='cuda:0')}, {'loss': tensor([2.2136, 1.9813, 2.0549, 2.1115], device='cuda:0')}, {'loss': tensor([2.1333, 1.9738, 2.0847, 2.0639], device='cuda:0')}, {'loss': tensor([2.1684, 1.9324, 2.0451, 2.0930], device='cuda:0')}, {'loss': tensor([2.2025, 1.9272, 2.1011, 2.1482], device='cuda:0')}, {'loss': tensor([2.2146, 1.9148, 2.0596, 2.0962], device='cuda:0')}, {'loss': tensor([2.2329, 1.9344, 2.0809, 2.0299], device='cuda:0')}, {'loss': tensor([2.1538, 1.9154, 2.0794, 2.1354], device='cuda:0')}, {'loss': tensor([2.1099, 1.9136, 2.1123, 2.1059], device='cuda:0')}, {'loss': tensor([2.2148, 1.9828, 2.1660, 2.0995], device='cuda:0')}, {'loss': tensor([2.1320, 1.8798, 1.9272, 2.0288], device='cuda:0')}, {'loss': tensor([2.2373, 1.8707, 2.1002, 1.9877], device='cuda:0')}, {'loss': tensor([2.1686, 2.0412, 2.0457, 2.0850], device='cuda:0')}, {'loss': tensor([2.1359, 1.9787, 1.9672, 2.0801], device='cuda:0')}, {'loss': tensor([2.2028, 2.0110, 2.1654, 2.0821], device='cuda:0')}, {'loss': tensor([2.1215, 1.8689, 2.0549, 2.0325], device='cuda:0')}, {'loss': tensor([2.1989, 1.9577, 2.0174, 2.0145], device='cuda:0')}, {'loss': tensor([2.3719, 1.7059, 2.0386, 2.0314], device='cuda:0')}]\n",
            "\n",
            "Epoch 2: 100%|██████████| 27/27 [00:06<00:00,  4.34it/s, loss=2.2, v_num=0, loss_step=2.370, loss_epoch=2.070]\n",
            "Epoch 2:   0%|          | 0/27 [00:00<?, ?it/s, loss=2.2, v_num=0, loss_step=2.370, loss_epoch=2.070]         \n",
            "Epoch 3:   0%|          | 0/27 [00:00<?, ?it/s, loss=2.2, v_num=0, loss_step=2.370, loss_epoch=2.070]\n",
            "Epoch 3:   4%|▎         | 1/27 [00:00<00:06,  4.19it/s, loss=2.19, v_num=0, loss_step=2.040, loss_epoch=2.070]\n",
            "Epoch 3:   7%|▋         | 2/27 [00:00<00:06,  4.06it/s, loss=2.19, v_num=0, loss_step=2.040, loss_epoch=2.070]\n",
            "Epoch 3:   7%|▋         | 2/27 [00:00<00:06,  4.06it/s, loss=2.18, v_num=0, loss_step=2.180, loss_epoch=2.070]\n",
            "Epoch 3:  11%|█         | 3/27 [00:00<00:05,  4.21it/s, loss=2.18, v_num=0, loss_step=2.120, loss_epoch=2.070]\n",
            "Epoch 3:  15%|█▍        | 4/27 [00:00<00:05,  4.25it/s, loss=2.18, v_num=0, loss_step=2.120, loss_epoch=2.070]\n",
            "Epoch 3:  15%|█▍        | 4/27 [00:00<00:05,  4.24it/s, loss=2.18, v_num=0, loss_step=2.240, loss_epoch=2.070]\n",
            "Epoch 3:  19%|█▊        | 5/27 [00:01<00:05,  4.28it/s, loss=2.18, v_num=0, loss_step=2.210, loss_epoch=2.070]\n",
            "Epoch 3:  22%|██▏       | 6/27 [00:01<00:05,  4.19it/s, loss=2.18, v_num=0, loss_step=2.210, loss_epoch=2.070]\n",
            "Epoch 3:  22%|██▏       | 6/27 [00:01<00:05,  4.19it/s, loss=2.19, v_num=0, loss_step=2.230, loss_epoch=2.070]\n",
            "Epoch 3:  26%|██▌       | 7/27 [00:01<00:04,  4.20it/s, loss=2.19, v_num=0, loss_step=2.220, loss_epoch=2.070]\n",
            "Epoch 3:  30%|██▉       | 8/27 [00:01<00:04,  4.23it/s, loss=2.19, v_num=0, loss_step=2.220, loss_epoch=2.070]\n",
            "Epoch 3:  30%|██▉       | 8/27 [00:01<00:04,  4.23it/s, loss=2.19, v_num=0, loss_step=2.190, loss_epoch=2.070]\n",
            "Epoch 3:  33%|███▎      | 9/27 [00:02<00:04,  4.25it/s, loss=2.18, v_num=0, loss_step=2.120, loss_epoch=2.070]\n",
            "Epoch 3:  37%|███▋      | 10/27 [00:02<00:04,  4.25it/s, loss=2.18, v_num=0, loss_step=2.120, loss_epoch=2.070]\n",
            "Epoch 3:  37%|███▋      | 10/27 [00:02<00:04,  4.25it/s, loss=2.18, v_num=0, loss_step=2.200, loss_epoch=2.070]\n",
            "Epoch 3:  41%|████      | 11/27 [00:02<00:03,  4.23it/s, loss=2.19, v_num=0, loss_step=2.260, loss_epoch=2.070]\n",
            "Epoch 3:  44%|████▍     | 12/27 [00:02<00:03,  4.24it/s, loss=2.19, v_num=0, loss_step=2.260, loss_epoch=2.070]\n",
            "Epoch 3:  44%|████▍     | 12/27 [00:02<00:03,  4.24it/s, loss=2.18, v_num=0, loss_step=2.100, loss_epoch=2.070]\n",
            "Epoch 3:  48%|████▊     | 13/27 [00:03<00:03,  4.27it/s, loss=2.19, v_num=0, loss_step=2.150, loss_epoch=2.070]\n",
            "Epoch 3:  52%|█████▏    | 14/27 [00:03<00:03,  4.28it/s, loss=2.19, v_num=0, loss_step=2.150, loss_epoch=2.070]\n",
            "Epoch 3:  52%|█████▏    | 14/27 [00:03<00:03,  4.28it/s, loss=2.18, v_num=0, loss_step=2.160, loss_epoch=2.070]\n",
            "Epoch 3:  56%|█████▌    | 15/27 [00:03<00:02,  4.26it/s, loss=2.18, v_num=0, loss_step=2.160, loss_epoch=2.070]\n",
            "Epoch 3:  59%|█████▉    | 16/27 [00:03<00:02,  4.19it/s, loss=2.18, v_num=0, loss_step=2.160, loss_epoch=2.070]\n",
            "Epoch 3:  59%|█████▉    | 16/27 [00:03<00:02,  4.19it/s, loss=2.18, v_num=0, loss_step=2.200, loss_epoch=2.070]\n",
            "Epoch 3:  63%|██████▎   | 17/27 [00:04<00:02,  4.17it/s, loss=2.18, v_num=0, loss_step=2.040, loss_epoch=2.070]\n",
            "Epoch 3:  67%|██████▋   | 18/27 [00:04<00:02,  4.14it/s, loss=2.18, v_num=0, loss_step=2.040, loss_epoch=2.070]\n",
            "Epoch 3:  67%|██████▋   | 18/27 [00:04<00:02,  4.14it/s, loss=2.18, v_num=0, loss_step=2.100, loss_epoch=2.070]\n",
            "Epoch 3:  70%|███████   | 19/27 [00:04<00:01,  4.15it/s, loss=2.18, v_num=0, loss_step=2.200, loss_epoch=2.070]\n",
            "Epoch 3:  74%|███████▍  | 20/27 [00:04<00:01,  4.14it/s, loss=2.18, v_num=0, loss_step=2.200, loss_epoch=2.070]\n",
            "Epoch 3:  74%|███████▍  | 20/27 [00:04<00:01,  4.14it/s, loss=2.17, v_num=0, loss_step=2.220, loss_epoch=2.070]\n",
            "Epoch 3:  78%|███████▊  | 21/27 [00:05<00:01,  4.13it/s, loss=2.18, v_num=0, loss_step=2.220, loss_epoch=2.070]\n",
            "Epoch 3:  81%|████████▏ | 22/27 [00:05<00:01,  4.14it/s, loss=2.18, v_num=0, loss_step=2.220, loss_epoch=2.070]\n",
            "Epoch 3:  81%|████████▏ | 22/27 [00:05<00:01,  4.14it/s, loss=2.18, v_num=0, loss_step=2.180, loss_epoch=2.070]\n",
            "Epoch 3:  85%|████████▌ | 23/27 [00:05<00:00,  4.16it/s, loss=2.17, v_num=0, loss_step=2.070, loss_epoch=2.070]\n",
            "Epoch 3:  89%|████████▉ | 24/27 [00:05<00:00,  4.26it/s, loss=2.17, v_num=0, loss_step=2.070, loss_epoch=2.070]\n",
            "Epoch 3:  89%|████████▉ | 24/27 [00:05<00:00,  4.26it/s, loss=2.18, v_num=0, loss_step=2.360, loss_epoch=2.070]\n",
            "\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "\n",
            "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validating:  33%|███▎      | 1/3 [00:00<00:00,  6.93it/s]\u001b[A\n",
            "Epoch 3:  96%|█████████▋| 26/27 [00:05<00:00,  4.50it/s, loss=2.18, v_num=0, loss_step=2.360, loss_epoch=2.070]\n",
            "\n",
            "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  8.01it/s]\u001b[A\n",
            "Epoch 3: 100%|██████████| 27/27 [00:06<00:00,  4.50it/s, loss=2.18, v_num=0, loss_step=2.360, loss_epoch=2.070]\n",
            "\n",
            "                                                         \u001b[A[{'loss': tensor([2.0409, 1.9872, 2.0840, 2.1201], device='cuda:0')}, {'loss': tensor([2.1837, 1.9615, 2.0509, 1.9320], device='cuda:0')}, {'loss': tensor([2.1191, 1.9441, 2.0323, 2.1038], device='cuda:0')}, {'loss': tensor([2.2434, 1.9131, 1.9657, 2.1002], device='cuda:0')}, {'loss': tensor([2.2098, 2.0762, 2.0450, 2.0792], device='cuda:0')}, {'loss': tensor([2.2272, 1.9877, 2.0737, 1.9440], device='cuda:0')}, {'loss': tensor([2.2214, 1.9764, 2.0200, 2.0738], device='cuda:0')}, {'loss': tensor([2.1853, 1.8858, 2.0056, 2.1018], device='cuda:0')}, {'loss': tensor([2.1180, 2.0554, 2.0856, 2.0243], device='cuda:0')}, {'loss': tensor([2.2038, 2.1077, 2.1175, 2.0469], device='cuda:0')}, {'loss': tensor([2.2628, 1.9877, 2.0465, 2.1205], device='cuda:0')}, {'loss': tensor([2.1041, 2.0257, 2.0120, 2.0915], device='cuda:0')}, {'loss': tensor([2.1531, 2.0018, 2.0376, 2.0275], device='cuda:0')}, {'loss': tensor([2.1613, 1.8897, 1.9028, 1.8706], device='cuda:0')}, {'loss': tensor([2.1608, 1.9983, 2.0252, 2.0269], device='cuda:0')}, {'loss': tensor([2.1991, 1.9334, 1.9848, 2.1110], device='cuda:0')}, {'loss': tensor([2.0429, 1.9801, 2.0433, 2.0005], device='cuda:0')}, {'loss': tensor([2.0989, 1.8711, 2.0277, 2.1369], device='cuda:0')}, {'loss': tensor([2.1996, 1.9009, 2.0069, 2.0376], device='cuda:0')}, {'loss': tensor([2.2206, 1.9968, 2.1564, 2.1973], device='cuda:0')}, {'loss': tensor([2.2182, 1.9062, 2.0642, 2.0790], device='cuda:0')}, {'loss': tensor([2.1832, 1.8891, 2.1652, 2.0309], device='cuda:0')}, {'loss': tensor([2.0659, 1.9041, 2.0865, 2.1607], device='cuda:0')}, {'loss': tensor([2.3589, 2.3647, 2.0300, 2.0376], device='cuda:0')}]\n",
            "\n",
            "Epoch 3: 100%|██████████| 27/27 [00:06<00:00,  4.40it/s, loss=2.18, v_num=0, loss_step=2.360, loss_epoch=2.060]\n",
            "Epoch 3:   0%|          | 0/27 [00:00<?, ?it/s, loss=2.18, v_num=0, loss_step=2.360, loss_epoch=2.060]         \n",
            "Epoch 4:   0%|          | 0/27 [00:00<?, ?it/s, loss=2.18, v_num=0, loss_step=2.360, loss_epoch=2.060]\n",
            "Epoch 4:   4%|▎         | 1/27 [00:00<00:06,  4.25it/s, loss=2.18, v_num=0, loss_step=2.180, loss_epoch=2.060]\n",
            "Epoch 4:   7%|▋         | 2/27 [00:00<00:06,  4.15it/s, loss=2.18, v_num=0, loss_step=2.180, loss_epoch=2.060]\n",
            "Epoch 4:   7%|▋         | 2/27 [00:00<00:06,  4.14it/s, loss=2.17, v_num=0, loss_step=2.130, loss_epoch=2.060]\n",
            "Epoch 4:  11%|█         | 3/27 [00:00<00:05,  4.13it/s, loss=2.17, v_num=0, loss_step=2.180, loss_epoch=2.060]\n",
            "Epoch 4:  15%|█▍        | 4/27 [00:00<00:05,  4.19it/s, loss=2.17, v_num=0, loss_step=2.180, loss_epoch=2.060]\n",
            "Epoch 4:  15%|█▍        | 4/27 [00:00<00:05,  4.19it/s, loss=2.17, v_num=0, loss_step=2.180, loss_epoch=2.060]\n",
            "Epoch 4:  19%|█▊        | 5/27 [00:01<00:05,  4.26it/s, loss=2.18, v_num=0, loss_step=2.240, loss_epoch=2.060]\n",
            "Epoch 4:  22%|██▏       | 6/27 [00:01<00:04,  4.21it/s, loss=2.18, v_num=0, loss_step=2.240, loss_epoch=2.060]\n",
            "Epoch 4:  22%|██▏       | 6/27 [00:01<00:04,  4.21it/s, loss=2.18, v_num=0, loss_step=2.180, loss_epoch=2.060]\n",
            "Epoch 4:  26%|██▌       | 7/27 [00:01<00:04,  4.19it/s, loss=2.17, v_num=0, loss_step=2.210, loss_epoch=2.060]\n",
            "Epoch 4:  30%|██▉       | 8/27 [00:01<00:04,  4.17it/s, loss=2.17, v_num=0, loss_step=2.210, loss_epoch=2.060]\n",
            "Epoch 4:  30%|██▉       | 8/27 [00:01<00:04,  4.17it/s, loss=2.18, v_num=0, loss_step=2.300, loss_epoch=2.060]\n",
            "Epoch 4:  33%|███▎      | 9/27 [00:02<00:04,  4.18it/s, loss=2.18, v_num=0, loss_step=2.140, loss_epoch=2.060]\n",
            "Epoch 4:  37%|███▋      | 10/27 [00:02<00:04,  4.17it/s, loss=2.18, v_num=0, loss_step=2.140, loss_epoch=2.060]\n",
            "Epoch 4:  37%|███▋      | 10/27 [00:02<00:04,  4.17it/s, loss=2.18, v_num=0, loss_step=2.180, loss_epoch=2.060]\n",
            "Epoch 4:  41%|████      | 11/27 [00:02<00:03,  4.19it/s, loss=2.18, v_num=0, loss_step=2.150, loss_epoch=2.060]\n",
            "Epoch 4:  44%|████▍     | 12/27 [00:02<00:03,  4.23it/s, loss=2.18, v_num=0, loss_step=2.150, loss_epoch=2.060]\n",
            "Epoch 4:  44%|████▍     | 12/27 [00:02<00:03,  4.23it/s, loss=2.18, v_num=0, loss_step=2.210, loss_epoch=2.060]\n",
            "Epoch 4:  48%|████▊     | 13/27 [00:03<00:03,  4.21it/s, loss=2.19, v_num=0, loss_step=2.110, loss_epoch=2.060]\n",
            "Epoch 4:  52%|█████▏    | 14/27 [00:03<00:03,  4.20it/s, loss=2.19, v_num=0, loss_step=2.110, loss_epoch=2.060]\n",
            "Epoch 4:  52%|█████▏    | 14/27 [00:03<00:03,  4.20it/s, loss=2.2, v_num=0, loss_step=2.250, loss_epoch=2.060] \n",
            "Epoch 4:  56%|█████▌    | 15/27 [00:03<00:02,  4.20it/s, loss=2.19, v_num=0, loss_step=2.180, loss_epoch=2.060]\n",
            "Epoch 4:  59%|█████▉    | 16/27 [00:03<00:02,  4.15it/s, loss=2.19, v_num=0, loss_step=2.180, loss_epoch=2.060]\n",
            "Epoch 4:  59%|█████▉    | 16/27 [00:03<00:02,  4.15it/s, loss=2.2, v_num=0, loss_step=2.230, loss_epoch=2.060] \n",
            "Epoch 4:  63%|██████▎   | 17/27 [00:04<00:02,  4.10it/s, loss=2.2, v_num=0, loss_step=2.250, loss_epoch=2.060]\n",
            "Epoch 4:  67%|██████▋   | 18/27 [00:04<00:02,  4.10it/s, loss=2.2, v_num=0, loss_step=2.250, loss_epoch=2.060]\n",
            "Epoch 4:  67%|██████▋   | 18/27 [00:04<00:02,  4.10it/s, loss=2.2, v_num=0, loss_step=2.170, loss_epoch=2.060]\n",
            "Epoch 4:  70%|███████   | 19/27 [00:04<00:01,  4.11it/s, loss=2.2, v_num=0, loss_step=2.150, loss_epoch=2.060]\n",
            "Epoch 4:  74%|███████▍  | 20/27 [00:04<00:01,  4.13it/s, loss=2.2, v_num=0, loss_step=2.150, loss_epoch=2.060]\n",
            "Epoch 4:  74%|███████▍  | 20/27 [00:04<00:01,  4.13it/s, loss=2.19, v_num=0, loss_step=2.130, loss_epoch=2.060]\n",
            "Epoch 4:  78%|███████▊  | 21/27 [00:05<00:01,  4.13it/s, loss=2.19, v_num=0, loss_step=2.150, loss_epoch=2.060]\n",
            "Epoch 4:  81%|████████▏ | 22/27 [00:05<00:01,  4.13it/s, loss=2.19, v_num=0, loss_step=2.150, loss_epoch=2.060]\n",
            "Epoch 4:  81%|████████▏ | 22/27 [00:05<00:01,  4.13it/s, loss=2.19, v_num=0, loss_step=2.150, loss_epoch=2.060]\n",
            "Epoch 4:  85%|████████▌ | 23/27 [00:05<00:00,  4.10it/s, loss=2.19, v_num=0, loss_step=2.150, loss_epoch=2.060]\n",
            "Epoch 4:  89%|████████▉ | 24/27 [00:05<00:00,  4.18it/s, loss=2.19, v_num=0, loss_step=2.150, loss_epoch=2.060]\n",
            "Epoch 4:  89%|████████▉ | 24/27 [00:05<00:00,  4.18it/s, loss=2.2, v_num=0, loss_step=2.370, loss_epoch=2.060] \n",
            "\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "\n",
            "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validating:  33%|███▎      | 1/3 [00:00<00:00,  6.92it/s]\u001b[A\n",
            "Epoch 4:  96%|█████████▋| 26/27 [00:05<00:00,  4.42it/s, loss=2.2, v_num=0, loss_step=2.370, loss_epoch=2.060]\n",
            "\n",
            "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  8.01it/s]\u001b[A\n",
            "Epoch 4: 100%|██████████| 27/27 [00:06<00:00,  4.41it/s, loss=2.2, v_num=0, loss_step=2.370, loss_epoch=2.060]\n",
            "\n",
            "                                                         \u001b[A[{'loss': tensor([2.1795, 1.8781, 1.9927, 2.0534], device='cuda:0')}, {'loss': tensor([2.1337, 1.8632, 2.0788, 2.0196], device='cuda:0')}, {'loss': tensor([2.1848, 1.9906, 2.0818, 1.9742], device='cuda:0')}, {'loss': tensor([2.1828, 2.0110, 2.0446, 1.9800], device='cuda:0')}, {'loss': tensor([2.2444, 1.9495, 2.0261, 2.1232], device='cuda:0')}, {'loss': tensor([2.1819, 2.1195, 2.1467, 2.0351], device='cuda:0')}, {'loss': tensor([2.2122, 2.0069, 1.9978, 2.1532], device='cuda:0')}, {'loss': tensor([2.3001, 1.9252, 2.0618, 2.1532], device='cuda:0')}, {'loss': tensor([2.1361, 1.8589, 2.0747, 2.0439], device='cuda:0')}, {'loss': tensor([2.1787, 2.0105, 2.0466, 2.1018], device='cuda:0')}, {'loss': tensor([2.1520, 2.0022, 2.0426, 1.9960], device='cuda:0')}, {'loss': tensor([2.2136, 1.9786, 2.0522, 2.1485], device='cuda:0')}, {'loss': tensor([2.1145, 2.0558, 2.0873, 2.1270], device='cuda:0')}, {'loss': tensor([2.2522, 2.0026, 2.0661, 2.0751], device='cuda:0')}, {'loss': tensor([2.1828, 1.9834, 2.0507, 2.1183], device='cuda:0')}, {'loss': tensor([2.2309, 1.9640, 2.0506, 2.0867], device='cuda:0')}, {'loss': tensor([2.2491, 2.0448, 2.0423, 2.0587], device='cuda:0')}, {'loss': tensor([2.1701, 2.0224, 2.1213, 2.0589], device='cuda:0')}, {'loss': tensor([2.1471, 2.0271, 2.0575, 2.0141], device='cuda:0')}, {'loss': tensor([2.1341, 2.0223, 2.0882, 1.9617], device='cuda:0')}, {'loss': tensor([2.1516, 2.0287, 2.0132, 2.1051], device='cuda:0')}, {'loss': tensor([2.1514, 1.9344, 2.1139, 2.2019], device='cuda:0')}, {'loss': tensor([2.1525, 1.9798, 1.9396, 2.0119], device='cuda:0')}, {'loss': tensor([2.3717, 1.7053, 2.0386, 2.3706], device='cuda:0')}]\n",
            "\n",
            "Epoch 4: 100%|██████████| 27/27 [00:06<00:00,  4.35it/s, loss=2.2, v_num=0, loss_step=2.370, loss_epoch=2.070]\n",
            "Epoch 4:   0%|          | 0/27 [00:00<?, ?it/s, loss=2.2, v_num=0, loss_step=2.370, loss_epoch=2.070]         \n",
            "Epoch 5:   0%|          | 0/27 [00:00<?, ?it/s, loss=2.2, v_num=0, loss_step=2.370, loss_epoch=2.070]\n",
            "Epoch 5:   4%|▎         | 1/27 [00:00<00:07,  3.30it/s, loss=2.19, v_num=0, loss_step=2.170, loss_epoch=2.070]\n",
            "Epoch 5:   7%|▋         | 2/27 [00:00<00:06,  3.86it/s, loss=2.19, v_num=0, loss_step=2.170, loss_epoch=2.070]\n",
            "Epoch 5:   7%|▋         | 2/27 [00:00<00:06,  3.86it/s, loss=2.19, v_num=0, loss_step=2.180, loss_epoch=2.070]\n",
            "Epoch 5:  11%|█         | 3/27 [00:00<00:06,  3.95it/s, loss=2.19, v_num=0, loss_step=2.120, loss_epoch=2.070]\n",
            "Epoch 5:  15%|█▍        | 4/27 [00:01<00:05,  3.99it/s, loss=2.19, v_num=0, loss_step=2.120, loss_epoch=2.070]\n",
            "Epoch 5:  15%|█▍        | 4/27 [00:01<00:05,  3.99it/s, loss=2.18, v_num=0, loss_step=2.140, loss_epoch=2.070]\n",
            "Epoch 5:  19%|█▊        | 5/27 [00:01<00:05,  4.09it/s, loss=2.18, v_num=0, loss_step=2.120, loss_epoch=2.070]\n",
            "Epoch 5:  22%|██▏       | 6/27 [00:01<00:05,  4.09it/s, loss=2.18, v_num=0, loss_step=2.120, loss_epoch=2.070]\n",
            "Epoch 5:  22%|██▏       | 6/27 [00:01<00:05,  4.08it/s, loss=2.18, v_num=0, loss_step=2.120, loss_epoch=2.070]\n",
            "Epoch 5:  26%|██▌       | 7/27 [00:01<00:04,  4.17it/s, loss=2.17, v_num=0, loss_step=2.080, loss_epoch=2.070]\n",
            "Epoch 5:  30%|██▉       | 8/27 [00:01<00:04,  4.22it/s, loss=2.17, v_num=0, loss_step=2.080, loss_epoch=2.070]\n",
            "Epoch 5:  30%|██▉       | 8/27 [00:01<00:04,  4.22it/s, loss=2.17, v_num=0, loss_step=2.250, loss_epoch=2.070]\n",
            "Epoch 5:  33%|███▎      | 9/27 [00:02<00:04,  4.13it/s, loss=2.18, v_num=0, loss_step=2.220, loss_epoch=2.070]\n",
            "Epoch 5:  37%|███▋      | 10/27 [00:02<00:04,  4.14it/s, loss=2.18, v_num=0, loss_step=2.220, loss_epoch=2.070]\n",
            "Epoch 5:  37%|███▋      | 10/27 [00:02<00:04,  4.14it/s, loss=2.17, v_num=0, loss_step=2.140, loss_epoch=2.070]\n",
            "Epoch 5:  41%|████      | 11/27 [00:02<00:03,  4.12it/s, loss=2.17, v_num=0, loss_step=2.170, loss_epoch=2.070]\n",
            "Epoch 5:  44%|████▍     | 12/27 [00:02<00:03,  4.12it/s, loss=2.17, v_num=0, loss_step=2.170, loss_epoch=2.070]\n",
            "Epoch 5:  44%|████▍     | 12/27 [00:02<00:03,  4.12it/s, loss=2.17, v_num=0, loss_step=2.090, loss_epoch=2.070]\n",
            "Epoch 5:  48%|████▊     | 13/27 [00:03<00:03,  4.11it/s, loss=2.16, v_num=0, loss_step=2.140, loss_epoch=2.070]\n",
            "Epoch 5:  52%|█████▏    | 14/27 [00:03<00:03,  4.11it/s, loss=2.16, v_num=0, loss_step=2.140, loss_epoch=2.070]\n",
            "Epoch 5:  52%|█████▏    | 14/27 [00:03<00:03,  4.11it/s, loss=2.16, v_num=0, loss_step=2.200, loss_epoch=2.070]\n",
            "Epoch 5:  56%|█████▌    | 15/27 [00:03<00:02,  4.13it/s, loss=2.16, v_num=0, loss_step=2.170, loss_epoch=2.070]\n",
            "Epoch 5:  59%|█████▉    | 16/27 [00:03<00:02,  4.16it/s, loss=2.16, v_num=0, loss_step=2.170, loss_epoch=2.070]\n",
            "Epoch 5:  59%|█████▉    | 16/27 [00:03<00:02,  4.16it/s, loss=2.16, v_num=0, loss_step=2.080, loss_epoch=2.070]\n",
            "Epoch 5:  63%|██████▎   | 17/27 [00:04<00:02,  4.17it/s, loss=2.16, v_num=0, loss_step=2.120, loss_epoch=2.070]\n",
            "Epoch 5:  67%|██████▋   | 18/27 [00:04<00:02,  4.18it/s, loss=2.16, v_num=0, loss_step=2.120, loss_epoch=2.070]\n",
            "Epoch 5:  67%|██████▋   | 18/27 [00:04<00:02,  4.18it/s, loss=2.16, v_num=0, loss_step=2.180, loss_epoch=2.070]\n",
            "Epoch 5:  70%|███████   | 19/27 [00:04<00:01,  4.17it/s, loss=2.16, v_num=0, loss_step=2.180, loss_epoch=2.070]\n",
            "Epoch 5:  74%|███████▍  | 20/27 [00:04<00:01,  4.19it/s, loss=2.16, v_num=0, loss_step=2.180, loss_epoch=2.070]\n",
            "Epoch 5:  74%|███████▍  | 20/27 [00:04<00:01,  4.19it/s, loss=2.15, v_num=0, loss_step=2.110, loss_epoch=2.070]\n",
            "Epoch 5:  78%|███████▊  | 21/27 [00:05<00:01,  4.18it/s, loss=2.15, v_num=0, loss_step=2.110, loss_epoch=2.070]\n",
            "Epoch 5:  81%|████████▏ | 22/27 [00:05<00:01,  4.20it/s, loss=2.15, v_num=0, loss_step=2.110, loss_epoch=2.070]\n",
            "Epoch 5:  81%|████████▏ | 22/27 [00:05<00:01,  4.20it/s, loss=2.14, v_num=0, loss_step=2.100, loss_epoch=2.070]\n",
            "Epoch 5:  85%|████████▌ | 23/27 [00:05<00:00,  4.21it/s, loss=2.14, v_num=0, loss_step=2.100, loss_epoch=2.070]\n",
            "Epoch 5:  89%|████████▉ | 24/27 [00:05<00:00,  4.30it/s, loss=2.14, v_num=0, loss_step=2.100, loss_epoch=2.070]\n",
            "Epoch 5:  89%|████████▉ | 24/27 [00:05<00:00,  4.30it/s, loss=2.15, v_num=0, loss_step=2.370, loss_epoch=2.070]\n",
            "\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "\n",
            "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validating:  33%|███▎      | 1/3 [00:00<00:00,  6.96it/s]\u001b[A\n",
            "Epoch 5:  96%|█████████▋| 26/27 [00:05<00:00,  4.54it/s, loss=2.15, v_num=0, loss_step=2.370, loss_epoch=2.070]\n",
            "\n",
            "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  8.01it/s]\u001b[A\n",
            "Epoch 5: 100%|██████████| 27/27 [00:05<00:00,  4.53it/s, loss=2.15, v_num=0, loss_step=2.370, loss_epoch=2.070]\n",
            "\n",
            "                                                         \u001b[A[{'loss': tensor([2.1687, 1.9346, 2.0586, 2.0432], device='cuda:0')}, {'loss': tensor([2.1844, 1.9655, 2.0208, 2.0574], device='cuda:0')}, {'loss': tensor([2.1216, 1.9528, 2.0213, 2.0550], device='cuda:0')}, {'loss': tensor([2.1437, 1.8763, 2.0585, 2.1184], device='cuda:0')}, {'loss': tensor([2.1219, 1.9180, 2.0755, 2.1357], device='cuda:0')}, {'loss': tensor([2.1195, 1.9385, 1.9849, 2.1058], device='cuda:0')}, {'loss': tensor([2.0757, 2.0354, 1.9760, 2.1047], device='cuda:0')}, {'loss': tensor([2.2465, 1.8830, 1.9710, 1.9388], device='cuda:0')}, {'loss': tensor([2.2155, 1.9946, 2.0896, 2.1061], device='cuda:0')}, {'loss': tensor([2.1382, 1.7749, 1.9798, 2.0476], device='cuda:0')}, {'loss': tensor([2.1660, 1.8709, 2.0776, 2.0541], device='cuda:0')}, {'loss': tensor([2.0885, 1.8551, 2.0350, 2.0276], device='cuda:0')}, {'loss': tensor([2.1370, 1.9026, 1.9621, 2.1205], device='cuda:0')}, {'loss': tensor([2.1960, 1.9296, 1.9501, 1.9647], device='cuda:0')}, {'loss': tensor([2.1692, 1.9664, 2.0266, 2.1929], device='cuda:0')}, {'loss': tensor([2.0791, 1.9975, 2.0113, 2.0509], device='cuda:0')}, {'loss': tensor([2.1213, 1.8706, 2.0129, 2.1329], device='cuda:0')}, {'loss': tensor([2.1800, 1.9616, 1.9792, 2.1173], device='cuda:0')}, {'loss': tensor([2.1838, 1.9932, 1.9650, 1.9472], device='cuda:0')}, {'loss': tensor([2.1118, 1.9461, 1.9861, 2.0519], device='cuda:0')}, {'loss': tensor([2.1149, 1.9110, 2.0743, 2.1105], device='cuda:0')}, {'loss': tensor([2.1017, 2.0899, 2.0125, 2.1178], device='cuda:0')}, {'loss': tensor([2.0967, 1.8807, 1.9984, 2.0574], device='cuda:0')}, {'loss': tensor([2.3719, 2.3720, 2.0386, 1.7053], device='cuda:0')}]\n",
            "\n",
            "Epoch 5: 100%|██████████| 27/27 [00:06<00:00,  4.48it/s, loss=2.15, v_num=0, loss_step=2.370, loss_epoch=2.040]\n",
            "Epoch 5:   0%|          | 0/27 [00:00<?, ?it/s, loss=2.15, v_num=0, loss_step=2.370, loss_epoch=2.040]         \n",
            "Epoch 6:   0%|          | 0/27 [00:00<?, ?it/s, loss=2.15, v_num=0, loss_step=2.370, loss_epoch=2.040]\n",
            "Epoch 6:   4%|▎         | 1/27 [00:00<00:06,  4.23it/s, loss=2.15, v_num=0, loss_step=2.180, loss_epoch=2.040]\n",
            "Epoch 6:   7%|▋         | 2/27 [00:00<00:06,  3.87it/s, loss=2.15, v_num=0, loss_step=2.180, loss_epoch=2.040]\n",
            "Epoch 6:   7%|▋         | 2/27 [00:00<00:06,  3.87it/s, loss=2.15, v_num=0, loss_step=2.120, loss_epoch=2.040]\n",
            "Epoch 6:  11%|█         | 3/27 [00:00<00:05,  4.01it/s, loss=2.16, v_num=0, loss_step=2.180, loss_epoch=2.040]\n",
            "Epoch 6:  15%|█▍        | 4/27 [00:00<00:05,  4.10it/s, loss=2.16, v_num=0, loss_step=2.180, loss_epoch=2.040]\n",
            "Epoch 6:  15%|█▍        | 4/27 [00:00<00:05,  4.10it/s, loss=2.16, v_num=0, loss_step=2.180, loss_epoch=2.040]\n",
            "Epoch 6:  19%|█▊        | 5/27 [00:01<00:05,  4.14it/s, loss=2.16, v_num=0, loss_step=2.200, loss_epoch=2.040]\n",
            "Epoch 6:  22%|██▏       | 6/27 [00:01<00:04,  4.21it/s, loss=2.16, v_num=0, loss_step=2.200, loss_epoch=2.040]\n",
            "Epoch 6:  22%|██▏       | 6/27 [00:01<00:04,  4.20it/s, loss=2.15, v_num=0, loss_step=2.060, loss_epoch=2.040]\n",
            "Epoch 6:  26%|██▌       | 7/27 [00:01<00:04,  4.21it/s, loss=2.15, v_num=0, loss_step=2.100, loss_epoch=2.040]\n",
            "Epoch 6:  30%|██▉       | 8/27 [00:01<00:04,  4.23it/s, loss=2.15, v_num=0, loss_step=2.100, loss_epoch=2.040]\n",
            "Epoch 6:  30%|██▉       | 8/27 [00:01<00:04,  4.23it/s, loss=2.15, v_num=0, loss_step=2.120, loss_epoch=2.040]\n",
            "Epoch 6:  33%|███▎      | 9/27 [00:02<00:04,  4.28it/s, loss=2.15, v_num=0, loss_step=2.220, loss_epoch=2.040]\n",
            "Epoch 6:  37%|███▋      | 10/27 [00:02<00:03,  4.27it/s, loss=2.15, v_num=0, loss_step=2.220, loss_epoch=2.040]\n",
            "Epoch 6:  37%|███▋      | 10/27 [00:02<00:03,  4.27it/s, loss=2.15, v_num=0, loss_step=2.060, loss_epoch=2.040]\n",
            "Epoch 6:  41%|████      | 11/27 [00:02<00:03,  4.19it/s, loss=2.15, v_num=0, loss_step=2.150, loss_epoch=2.040]\n",
            "Epoch 6:  44%|████▍     | 12/27 [00:02<00:03,  4.19it/s, loss=2.15, v_num=0, loss_step=2.150, loss_epoch=2.040]\n",
            "Epoch 6:  44%|████▍     | 12/27 [00:02<00:03,  4.18it/s, loss=2.15, v_num=0, loss_step=2.210, loss_epoch=2.040]\n",
            "Epoch 6:  48%|████▊     | 13/27 [00:03<00:03,  4.20it/s, loss=2.16, v_num=0, loss_step=2.160, loss_epoch=2.040]\n",
            "Epoch 6:  52%|█████▏    | 14/27 [00:03<00:03,  4.18it/s, loss=2.16, v_num=0, loss_step=2.160, loss_epoch=2.040]\n",
            "Epoch 6:  52%|█████▏    | 14/27 [00:03<00:03,  4.18it/s, loss=2.15, v_num=0, loss_step=2.110, loss_epoch=2.040]\n",
            "Epoch 6:  56%|█████▌    | 15/27 [00:03<00:02,  4.18it/s, loss=2.15, v_num=0, loss_step=2.200, loss_epoch=2.040]\n",
            "Epoch 6:  59%|█████▉    | 16/27 [00:03<00:02,  4.20it/s, loss=2.15, v_num=0, loss_step=2.200, loss_epoch=2.040]\n",
            "Epoch 6:  59%|█████▉    | 16/27 [00:03<00:02,  4.20it/s, loss=2.16, v_num=0, loss_step=2.280, loss_epoch=2.040]\n",
            "Epoch 6:  63%|██████▎   | 17/27 [00:04<00:02,  4.19it/s, loss=2.17, v_num=0, loss_step=2.240, loss_epoch=2.040]\n",
            "Epoch 6:  67%|██████▋   | 18/27 [00:04<00:02,  4.21it/s, loss=2.17, v_num=0, loss_step=2.240, loss_epoch=2.040]\n",
            "Epoch 6:  67%|██████▋   | 18/27 [00:04<00:02,  4.21it/s, loss=2.17, v_num=0, loss_step=2.240, loss_epoch=2.040]\n",
            "Epoch 6:  70%|███████   | 19/27 [00:04<00:01,  4.19it/s, loss=2.18, v_num=0, loss_step=2.290, loss_epoch=2.040]\n",
            "Epoch 6:  74%|███████▍  | 20/27 [00:04<00:01,  4.18it/s, loss=2.18, v_num=0, loss_step=2.290, loss_epoch=2.040]\n",
            "Epoch 6:  74%|███████▍  | 20/27 [00:04<00:01,  4.18it/s, loss=2.17, v_num=0, loss_step=2.170, loss_epoch=2.040]\n",
            "Epoch 6:  78%|███████▊  | 21/27 [00:05<00:01,  4.19it/s, loss=2.18, v_num=0, loss_step=2.200, loss_epoch=2.040]\n",
            "Epoch 6:  81%|████████▏ | 22/27 [00:05<00:01,  4.20it/s, loss=2.18, v_num=0, loss_step=2.200, loss_epoch=2.040]\n",
            "Epoch 6:  81%|████████▏ | 22/27 [00:05<00:01,  4.20it/s, loss=2.18, v_num=0, loss_step=2.200, loss_epoch=2.040]\n",
            "Epoch 6:  85%|████████▌ | 23/27 [00:05<00:00,  4.20it/s, loss=2.18, v_num=0, loss_step=2.220, loss_epoch=2.040]\n",
            "Epoch 6:  89%|████████▉ | 24/27 [00:05<00:00,  4.30it/s, loss=2.18, v_num=0, loss_step=2.220, loss_epoch=2.040]\n",
            "Epoch 6:  89%|████████▉ | 24/27 [00:05<00:00,  4.30it/s, loss=2.17, v_num=0, loss_step=2.040, loss_epoch=2.040]\n",
            "\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "\n",
            "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validating:  33%|███▎      | 1/3 [00:00<00:00,  6.95it/s]\u001b[A\n",
            "Epoch 6:  96%|█████████▋| 26/27 [00:05<00:00,  4.54it/s, loss=2.17, v_num=0, loss_step=2.040, loss_epoch=2.040]\n",
            "\n",
            "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  8.02it/s]\u001b[A\n",
            "Epoch 6: 100%|██████████| 27/27 [00:05<00:00,  4.53it/s, loss=2.17, v_num=0, loss_step=2.040, loss_epoch=2.040]\n",
            "\n",
            "                                                         \u001b[A[{'loss': tensor([2.1831, 2.0018, 2.0604, 1.9949], device='cuda:0')}, {'loss': tensor([2.1196, 1.8412, 1.9521, 2.0402], device='cuda:0')}, {'loss': tensor([2.1815, 2.0403, 2.0116, 2.0562], device='cuda:0')}, {'loss': tensor([2.1829, 1.9177, 2.0740, 2.0891], device='cuda:0')}, {'loss': tensor([2.1996, 2.0628, 2.1030, 2.0279], device='cuda:0')}, {'loss': tensor([2.0588, 1.9044, 1.9349, 2.0194], device='cuda:0')}, {'loss': tensor([2.1045, 1.9133, 1.9773, 2.1348], device='cuda:0')}, {'loss': tensor([2.1184, 1.9046, 2.0273, 1.9039], device='cuda:0')}, {'loss': tensor([2.2150, 1.9584, 2.0209, 2.0248], device='cuda:0')}, {'loss': tensor([2.0626, 1.8948, 2.0120, 2.0575], device='cuda:0')}, {'loss': tensor([2.1523, 2.0396, 1.9379, 2.0445], device='cuda:0')}, {'loss': tensor([2.2144, 1.9115, 1.9667, 2.0429], device='cuda:0')}, {'loss': tensor([2.1556, 1.9310, 2.0667, 1.9493], device='cuda:0')}, {'loss': tensor([2.1128, 1.9489, 1.9813, 2.1191], device='cuda:0')}, {'loss': tensor([2.2041, 1.9333, 1.9491, 2.0891], device='cuda:0')}, {'loss': tensor([2.2771, 1.9123, 1.8871, 2.1038], device='cuda:0')}, {'loss': tensor([2.2447, 1.9672, 2.1134, 2.0395], device='cuda:0')}, {'loss': tensor([2.2359, 2.0108, 2.0074, 2.0652], device='cuda:0')}, {'loss': tensor([2.2929, 1.8961, 1.9830, 1.9979], device='cuda:0')}, {'loss': tensor([2.1731, 1.9206, 2.0082, 2.0120], device='cuda:0')}, {'loss': tensor([2.1972, 1.9725, 1.9596, 2.0586], device='cuda:0')}, {'loss': tensor([2.1951, 1.9181, 2.0900, 2.0562], device='cuda:0')}, {'loss': tensor([2.2231, 2.0349, 2.0570, 2.0574], device='cuda:0')}, {'loss': tensor([2.0386, 2.3641, 2.0356, 2.0386], device='cuda:0')}]\n",
            "\n",
            "Epoch 6: 100%|██████████| 27/27 [00:06<00:00,  4.45it/s, loss=2.17, v_num=0, loss_step=2.040, loss_epoch=2.040]\n",
            "Epoch 6:   0%|          | 0/27 [00:00<?, ?it/s, loss=2.17, v_num=0, loss_step=2.040, loss_epoch=2.040]         \n",
            "Epoch 7:   0%|          | 0/27 [00:00<?, ?it/s, loss=2.17, v_num=0, loss_step=2.040, loss_epoch=2.040]\n",
            "Epoch 7:   4%|▎         | 1/27 [00:00<00:05,  4.42it/s, loss=2.17, v_num=0, loss_step=2.180, loss_epoch=2.040]\n",
            "Epoch 7:   7%|▋         | 2/27 [00:00<00:05,  4.34it/s, loss=2.17, v_num=0, loss_step=2.180, loss_epoch=2.040]\n",
            "Epoch 7:   7%|▋         | 2/27 [00:00<00:05,  4.34it/s, loss=2.18, v_num=0, loss_step=2.140, loss_epoch=2.040]\n",
            "Epoch 7:  11%|█         | 3/27 [00:00<00:05,  4.21it/s, loss=2.18, v_num=0, loss_step=2.240, loss_epoch=2.040]\n",
            "Epoch 7:  15%|█▍        | 4/27 [00:00<00:05,  4.23it/s, loss=2.18, v_num=0, loss_step=2.240, loss_epoch=2.040]\n",
            "Epoch 7:  15%|█▍        | 4/27 [00:00<00:05,  4.23it/s, loss=2.19, v_num=0, loss_step=2.170, loss_epoch=2.040]\n",
            "Epoch 7:  19%|█▊        | 5/27 [00:01<00:05,  4.31it/s, loss=2.18, v_num=0, loss_step=2.150, loss_epoch=2.040]\n",
            "Epoch 7:  22%|██▏       | 6/27 [00:01<00:04,  4.26it/s, loss=2.18, v_num=0, loss_step=2.150, loss_epoch=2.040]\n",
            "Epoch 7:  22%|██▏       | 6/27 [00:01<00:04,  4.26it/s, loss=2.19, v_num=0, loss_step=2.170, loss_epoch=2.040]\n",
            "Epoch 7:  26%|██▌       | 7/27 [00:01<00:04,  4.33it/s, loss=2.19, v_num=0, loss_step=2.230, loss_epoch=2.040]\n",
            "Epoch 7:  30%|██▉       | 8/27 [00:01<00:04,  4.30it/s, loss=2.19, v_num=0, loss_step=2.230, loss_epoch=2.040]\n",
            "Epoch 7:  30%|██▉       | 8/27 [00:01<00:04,  4.30it/s, loss=2.19, v_num=0, loss_step=2.120, loss_epoch=2.040]\n",
            "Epoch 7:  33%|███▎      | 9/27 [00:02<00:04,  4.27it/s, loss=2.19, v_num=0, loss_step=2.170, loss_epoch=2.040]\n",
            "Epoch 7:  37%|███▋      | 10/27 [00:02<00:04,  4.14it/s, loss=2.19, v_num=0, loss_step=2.170, loss_epoch=2.040]\n",
            "Epoch 7:  37%|███▋      | 10/27 [00:02<00:04,  4.14it/s, loss=2.19, v_num=0, loss_step=2.160, loss_epoch=2.040]\n",
            "Epoch 7:  41%|████      | 11/27 [00:02<00:03,  4.17it/s, loss=2.19, v_num=0, loss_step=2.100, loss_epoch=2.040]\n",
            "Epoch 7:  44%|████▍     | 12/27 [00:02<00:03,  4.18it/s, loss=2.19, v_num=0, loss_step=2.100, loss_epoch=2.040]\n",
            "Epoch 7:  44%|████▍     | 12/27 [00:02<00:03,  4.18it/s, loss=2.18, v_num=0, loss_step=2.170, loss_epoch=2.040]\n",
            "Epoch 7:  48%|████▊     | 13/27 [00:03<00:03,  4.20it/s, loss=2.17, v_num=0, loss_step=2.140, loss_epoch=2.040]\n",
            "Epoch 7:  52%|█████▏    | 14/27 [00:03<00:03,  4.14it/s, loss=2.17, v_num=0, loss_step=2.140, loss_epoch=2.040]\n",
            "Epoch 7:  52%|█████▏    | 14/27 [00:03<00:03,  4.14it/s, loss=2.17, v_num=0, loss_step=2.180, loss_epoch=2.040]\n",
            "Epoch 7:  56%|█████▌    | 15/27 [00:03<00:02,  4.13it/s, loss=2.16, v_num=0, loss_step=2.140, loss_epoch=2.040]\n",
            "Epoch 7:  59%|█████▉    | 16/27 [00:03<00:02,  4.15it/s, loss=2.16, v_num=0, loss_step=2.140, loss_epoch=2.040]\n",
            "Epoch 7:  59%|█████▉    | 16/27 [00:03<00:02,  4.15it/s, loss=2.17, v_num=0, loss_step=2.180, loss_epoch=2.040]\n",
            "Epoch 7:  63%|██████▎   | 17/27 [00:04<00:02,  4.17it/s, loss=2.16, v_num=0, loss_step=2.170, loss_epoch=2.040]\n",
            "Epoch 7:  67%|██████▋   | 18/27 [00:04<00:02,  4.17it/s, loss=2.16, v_num=0, loss_step=2.170, loss_epoch=2.040]\n",
            "Epoch 7:  67%|██████▋   | 18/27 [00:04<00:02,  4.17it/s, loss=2.16, v_num=0, loss_step=2.130, loss_epoch=2.040]\n",
            "Epoch 7:  70%|███████   | 19/27 [00:04<00:01,  4.18it/s, loss=2.16, v_num=0, loss_step=2.140, loss_epoch=2.040]\n",
            "Epoch 7:  74%|███████▍  | 20/27 [00:04<00:01,  4.18it/s, loss=2.16, v_num=0, loss_step=2.140, loss_epoch=2.040]\n",
            "Epoch 7:  74%|███████▍  | 20/27 [00:04<00:01,  4.18it/s, loss=2.16, v_num=0, loss_step=2.170, loss_epoch=2.040]\n",
            "Epoch 7:  78%|███████▊  | 21/27 [00:05<00:01,  4.19it/s, loss=2.16, v_num=0, loss_step=2.200, loss_epoch=2.040]\n",
            "Epoch 7:  81%|████████▏ | 22/27 [00:05<00:01,  4.18it/s, loss=2.16, v_num=0, loss_step=2.200, loss_epoch=2.040]\n",
            "Epoch 7:  81%|████████▏ | 22/27 [00:05<00:01,  4.18it/s, loss=2.17, v_num=0, loss_step=2.210, loss_epoch=2.040]\n",
            "Epoch 7:  85%|████████▌ | 23/27 [00:05<00:00,  4.20it/s, loss=2.16, v_num=0, loss_step=2.160, loss_epoch=2.040]\n",
            "Epoch 7:  89%|████████▉ | 24/27 [00:05<00:00,  4.29it/s, loss=2.16, v_num=0, loss_step=2.160, loss_epoch=2.040]\n",
            "Epoch 7:  89%|████████▉ | 24/27 [00:05<00:00,  4.29it/s, loss=2.14, v_num=0, loss_step=1.710, loss_epoch=2.040]\n",
            "\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "\n",
            "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validating:  33%|███▎      | 1/3 [00:00<00:00,  6.97it/s]\u001b[A\n",
            "Epoch 7:  96%|█████████▋| 26/27 [00:05<00:00,  4.53it/s, loss=2.14, v_num=0, loss_step=1.710, loss_epoch=2.040]\n",
            "\n",
            "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  8.04it/s]\u001b[A\n",
            "Epoch 7: 100%|██████████| 27/27 [00:05<00:00,  4.53it/s, loss=2.14, v_num=0, loss_step=1.710, loss_epoch=2.040]\n",
            "\n",
            "                                                         \u001b[A[{'loss': tensor([2.1825, 1.9750, 2.0512, 2.0929], device='cuda:0')}, {'loss': tensor([2.1394, 1.9544, 2.1150, 2.0121], device='cuda:0')}, {'loss': tensor([2.2413, 1.9502, 2.0437, 2.1203], device='cuda:0')}, {'loss': tensor([2.1670, 1.9983, 2.0273, 2.0721], device='cuda:0')}, {'loss': tensor([2.1514, 1.8722, 1.9331, 1.9948], device='cuda:0')}, {'loss': tensor([2.1664, 1.9810, 1.9811, 2.0001], device='cuda:0')}, {'loss': tensor([2.2304, 1.8601, 1.9981, 2.0802], device='cuda:0')}, {'loss': tensor([2.1245, 1.9170, 2.0250, 2.0428], device='cuda:0')}, {'loss': tensor([2.1685, 1.9499, 1.9026, 1.9901], device='cuda:0')}, {'loss': tensor([2.1579, 2.0675, 2.0042, 2.0384], device='cuda:0')}, {'loss': tensor([2.1026, 1.9389, 2.0271, 1.9992], device='cuda:0')}, {'loss': tensor([2.1661, 2.0715, 2.1363, 2.0581], device='cuda:0')}, {'loss': tensor([2.1412, 1.9015, 2.1046, 1.9035], device='cuda:0')}, {'loss': tensor([2.1835, 1.8976, 1.9863, 1.9954], device='cuda:0')}, {'loss': tensor([2.1446, 1.9472, 1.9011, 2.0270], device='cuda:0')}, {'loss': tensor([2.1842, 1.9804, 1.9961, 2.1062], device='cuda:0')}, {'loss': tensor([2.1682, 1.9966, 1.9962, 2.0890], device='cuda:0')}, {'loss': tensor([2.1297, 1.9168, 2.0545, 2.0415], device='cuda:0')}, {'loss': tensor([2.1353, 2.0040, 2.1038, 2.0890], device='cuda:0')}, {'loss': tensor([2.1658, 1.9288, 2.1208, 1.9952], device='cuda:0')}, {'loss': tensor([2.1977, 1.9328, 1.9976, 2.0726], device='cuda:0')}, {'loss': tensor([2.2150, 1.9501, 1.9649, 2.1190], device='cuda:0')}, {'loss': tensor([2.1643, 1.9642, 2.0186, 2.0604], device='cuda:0')}, {'loss': tensor([1.7053, 1.7053, 1.7053, 2.0386], device='cuda:0')}]\n",
            "\n",
            "Epoch 7: 100%|██████████| 27/27 [00:06<00:00,  4.47it/s, loss=2.14, v_num=0, loss_step=1.710, loss_epoch=2.050]\n",
            "Epoch 7:   0%|          | 0/27 [00:00<?, ?it/s, loss=2.14, v_num=0, loss_step=1.710, loss_epoch=2.050]         \n",
            "Epoch 8:   0%|          | 0/27 [00:00<?, ?it/s, loss=2.14, v_num=0, loss_step=1.710, loss_epoch=2.050]\n",
            "Epoch 8:   4%|▎         | 1/27 [00:00<00:05,  4.37it/s, loss=2.14, v_num=0, loss_step=2.170, loss_epoch=2.050]\n",
            "Epoch 8:   7%|▋         | 2/27 [00:00<00:05,  4.26it/s, loss=2.14, v_num=0, loss_step=2.170, loss_epoch=2.050]\n",
            "Epoch 8:   7%|▋         | 2/27 [00:00<00:05,  4.25it/s, loss=2.14, v_num=0, loss_step=2.110, loss_epoch=2.050]\n",
            "Epoch 8:  11%|█         | 3/27 [00:00<00:05,  4.22it/s, loss=2.13, v_num=0, loss_step=2.160, loss_epoch=2.050]\n",
            "Epoch 8:  15%|█▍        | 4/27 [00:00<00:05,  4.33it/s, loss=2.13, v_num=0, loss_step=2.160, loss_epoch=2.050]\n",
            "Epoch 8:  15%|█▍        | 4/27 [00:00<00:05,  4.32it/s, loss=2.14, v_num=0, loss_step=2.260, loss_epoch=2.050]\n",
            "Epoch 8:  19%|█▊        | 5/27 [00:01<00:05,  4.37it/s, loss=2.14, v_num=0, loss_step=2.160, loss_epoch=2.050]\n",
            "Epoch 8:  22%|██▏       | 6/27 [00:01<00:04,  4.27it/s, loss=2.14, v_num=0, loss_step=2.160, loss_epoch=2.050]\n",
            "Epoch 8:  22%|██▏       | 6/27 [00:01<00:04,  4.27it/s, loss=2.14, v_num=0, loss_step=2.090, loss_epoch=2.050]\n",
            "Epoch 8:  26%|██▌       | 7/27 [00:01<00:04,  4.27it/s, loss=2.14, v_num=0, loss_step=2.250, loss_epoch=2.050]\n",
            "Epoch 8:  30%|██▉       | 8/27 [00:01<00:04,  4.16it/s, loss=2.14, v_num=0, loss_step=2.250, loss_epoch=2.050]\n",
            "Epoch 8:  30%|██▉       | 8/27 [00:01<00:04,  4.15it/s, loss=2.14, v_num=0, loss_step=2.150, loss_epoch=2.050]\n",
            "Epoch 8:  33%|███▎      | 9/27 [00:02<00:04,  4.21it/s, loss=2.14, v_num=0, loss_step=2.140, loss_epoch=2.050]\n",
            "Epoch 8:  37%|███▋      | 10/27 [00:02<00:04,  4.19it/s, loss=2.14, v_num=0, loss_step=2.140, loss_epoch=2.050]\n",
            "Epoch 8:  37%|███▋      | 10/27 [00:02<00:04,  4.19it/s, loss=2.14, v_num=0, loss_step=2.200, loss_epoch=2.050]\n",
            "Epoch 8:  41%|████      | 11/27 [00:02<00:03,  4.19it/s, loss=2.14, v_num=0, loss_step=2.150, loss_epoch=2.050]\n",
            "Epoch 8:  44%|████▍     | 12/27 [00:02<00:03,  4.18it/s, loss=2.14, v_num=0, loss_step=2.150, loss_epoch=2.050]\n",
            "Epoch 8:  44%|████▍     | 12/27 [00:02<00:03,  4.18it/s, loss=2.15, v_num=0, loss_step=2.260, loss_epoch=2.050]\n",
            "Epoch 8:  48%|████▊     | 13/27 [00:03<00:03,  4.21it/s, loss=2.15, v_num=0, loss_step=2.150, loss_epoch=2.050]\n",
            "Epoch 8:  52%|█████▏    | 14/27 [00:03<00:03,  4.22it/s, loss=2.15, v_num=0, loss_step=2.150, loss_epoch=2.050]\n",
            "Epoch 8:  52%|█████▏    | 14/27 [00:03<00:03,  4.22it/s, loss=2.14, v_num=0, loss_step=2.060, loss_epoch=2.050]\n",
            "Epoch 8:  56%|█████▌    | 15/27 [00:03<00:02,  4.21it/s, loss=2.15, v_num=0, loss_step=2.230, loss_epoch=2.050]\n",
            "Epoch 8:  59%|█████▉    | 16/27 [00:03<00:02,  4.23it/s, loss=2.15, v_num=0, loss_step=2.230, loss_epoch=2.050]\n",
            "Epoch 8:  59%|█████▉    | 16/27 [00:03<00:02,  4.23it/s, loss=2.15, v_num=0, loss_step=2.100, loss_epoch=2.050]\n",
            "Epoch 8:  63%|██████▎   | 17/27 [00:04<00:02,  4.24it/s, loss=2.14, v_num=0, loss_step=2.180, loss_epoch=2.050]\n",
            "Epoch 8:  67%|██████▋   | 18/27 [00:04<00:02,  4.23it/s, loss=2.14, v_num=0, loss_step=2.180, loss_epoch=2.050]\n",
            "Epoch 8:  67%|██████▋   | 18/27 [00:04<00:02,  4.23it/s, loss=2.14, v_num=0, loss_step=2.100, loss_epoch=2.050]\n",
            "Epoch 8:  70%|███████   | 19/27 [00:04<00:01,  4.22it/s, loss=2.14, v_num=0, loss_step=2.180, loss_epoch=2.050]\n",
            "Epoch 8:  74%|███████▍  | 20/27 [00:04<00:01,  4.22it/s, loss=2.14, v_num=0, loss_step=2.180, loss_epoch=2.050]\n",
            "Epoch 8:  74%|███████▍  | 20/27 [00:04<00:01,  4.22it/s, loss=2.16, v_num=0, loss_step=2.090, loss_epoch=2.050]\n",
            "Epoch 8:  78%|███████▊  | 21/27 [00:04<00:01,  4.24it/s, loss=2.16, v_num=0, loss_step=2.140, loss_epoch=2.050]\n",
            "Epoch 8:  81%|████████▏ | 22/27 [00:05<00:01,  4.23it/s, loss=2.16, v_num=0, loss_step=2.140, loss_epoch=2.050]\n",
            "Epoch 8:  81%|████████▏ | 22/27 [00:05<00:01,  4.23it/s, loss=2.16, v_num=0, loss_step=2.080, loss_epoch=2.050]\n",
            "Epoch 8:  85%|████████▌ | 23/27 [00:05<00:00,  4.24it/s, loss=2.16, v_num=0, loss_step=2.180, loss_epoch=2.050]\n",
            "Epoch 8:  89%|████████▉ | 24/27 [00:05<00:00,  4.34it/s, loss=2.16, v_num=0, loss_step=2.180, loss_epoch=2.050]\n",
            "Epoch 8:  89%|████████▉ | 24/27 [00:05<00:00,  4.34it/s, loss=2.15, v_num=0, loss_step=2.040, loss_epoch=2.050]\n",
            "\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "\n",
            "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validating:  33%|███▎      | 1/3 [00:00<00:00,  6.98it/s]\u001b[A\n",
            "Epoch 8:  96%|█████████▋| 26/27 [00:05<00:00,  4.58it/s, loss=2.15, v_num=0, loss_step=2.040, loss_epoch=2.050]\n",
            "\n",
            "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  8.04it/s]\u001b[A\n",
            "Epoch 8: 100%|██████████| 27/27 [00:05<00:00,  4.57it/s, loss=2.15, v_num=0, loss_step=2.040, loss_epoch=2.050]\n",
            "\n",
            "                                                         \u001b[A[{'loss': tensor([2.1659, 1.9498, 2.0999, 2.0884], device='cuda:0')}, {'loss': tensor([2.1073, 1.8406, 2.0130, 2.0709], device='cuda:0')}, {'loss': tensor([2.1552, 1.9123, 1.9958, 2.1109], device='cuda:0')}, {'loss': tensor([2.2612, 1.8302, 1.9811, 2.0335], device='cuda:0')}, {'loss': tensor([2.1644, 1.8568, 2.0592, 2.1058], device='cuda:0')}, {'loss': tensor([2.0880, 1.9750, 1.9504, 2.0208], device='cuda:0')}, {'loss': tensor([2.2459, 2.0294, 2.0294, 1.9337], device='cuda:0')}, {'loss': tensor([2.1528, 1.9809, 2.0266, 2.0282], device='cuda:0')}, {'loss': tensor([2.1352, 1.8874, 2.0875, 2.0570], device='cuda:0')}, {'loss': tensor([2.2001, 1.8472, 2.0436, 2.0724], device='cuda:0')}, {'loss': tensor([2.1516, 1.9328, 2.0304, 2.1077], device='cuda:0')}, {'loss': tensor([2.2608, 1.9743, 1.9491, 2.1199], device='cuda:0')}, {'loss': tensor([2.1530, 1.8900, 2.1220, 2.0642], device='cuda:0')}, {'loss': tensor([2.0593, 1.9269, 1.9656, 2.0103], device='cuda:0')}, {'loss': tensor([2.2271, 1.9401, 2.0903, 2.0964], device='cuda:0')}, {'loss': tensor([2.0961, 1.8782, 1.9489, 2.0901], device='cuda:0')}, {'loss': tensor([2.1830, 1.9967, 1.9956, 2.1262], device='cuda:0')}, {'loss': tensor([2.0960, 1.8233, 2.0184, 2.1069], device='cuda:0')}, {'loss': tensor([2.1819, 1.9806, 2.0340, 2.0870], device='cuda:0')}, {'loss': tensor([2.0901, 1.7969, 1.9467, 2.0587], device='cuda:0')}, {'loss': tensor([2.1415, 1.9342, 2.0602, 2.0335], device='cuda:0')}, {'loss': tensor([2.0812, 1.9420, 2.0750, 2.0734], device='cuda:0')}, {'loss': tensor([2.1800, 2.0108, 2.1050, 1.9849], device='cuda:0')}, {'loss': tensor([2.0386, 2.0386, 2.0386, 2.3720], device='cuda:0')}]\n",
            "\n",
            "Epoch 8: 100%|██████████| 27/27 [00:05<00:00,  4.51it/s, loss=2.15, v_num=0, loss_step=2.040, loss_epoch=2.040]\n"
          ]
        }
      ],
      "source": [
        "# 実行\n",
        "run = Experiment(ws, experiment_name).submit(src)\n",
        "run.wait_for_completion(show_output=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1621417896422
        }
      },
      "outputs": [
        {
          "ename": "ModelPathNotFoundException",
          "evalue": "ModelPathNotFoundException:\n\tMessage: Could not locate the provided model_path outputs/model.onnx in the set of files uploaded to the run: ['azureml-logs/55_azureml-execution-tvmps_0f93e9792dd9ffbd80a0b0cbeb00a8fab0b14be474a32b815609bb1f4bffa494_d.txt', 'azureml-logs/55_azureml-execution-tvmps_6ad0f50cd79742bed158768f299d376ef743927df3983464d8dc993376693eb2_d.txt', 'azureml-logs/65_job_prep-tvmps_0f93e9792dd9ffbd80a0b0cbeb00a8fab0b14be474a32b815609bb1f4bffa494_d.txt', 'azureml-logs/65_job_prep-tvmps_6ad0f50cd79742bed158768f299d376ef743927df3983464d8dc993376693eb2_d.txt', 'azureml-logs/70_driver_log_0.txt', 'azureml-logs/70_driver_log_1.txt', 'azureml-logs/70_mpi_log.txt', 'azureml-logs/75_job_post-tvmps_0f93e9792dd9ffbd80a0b0cbeb00a8fab0b14be474a32b815609bb1f4bffa494_d.txt', 'azureml-logs/75_job_post-tvmps_6ad0f50cd79742bed158768f299d376ef743927df3983464d8dc993376693eb2_d.txt', 'azureml-logs/process_info.json', 'azureml-logs/process_status.json', 'logs/azureml/0_140_azureml.log', 'logs/azureml/1_119_azureml.log', 'logs/azureml/job_prep_azureml.log', 'logs/azureml/job_release_azureml.log', 'outputs/model.ckpt']\n                See https://aka.ms/run-logging for more details.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Could not locate the provided model_path outputs/model.onnx in the set of files uploaded to the run: ['azureml-logs/55_azureml-execution-tvmps_0f93e9792dd9ffbd80a0b0cbeb00a8fab0b14be474a32b815609bb1f4bffa494_d.txt', 'azureml-logs/55_azureml-execution-tvmps_6ad0f50cd79742bed158768f299d376ef743927df3983464d8dc993376693eb2_d.txt', 'azureml-logs/65_job_prep-tvmps_0f93e9792dd9ffbd80a0b0cbeb00a8fab0b14be474a32b815609bb1f4bffa494_d.txt', 'azureml-logs/65_job_prep-tvmps_6ad0f50cd79742bed158768f299d376ef743927df3983464d8dc993376693eb2_d.txt', 'azureml-logs/70_driver_log_0.txt', 'azureml-logs/70_driver_log_1.txt', 'azureml-logs/70_mpi_log.txt', 'azureml-logs/75_job_post-tvmps_0f93e9792dd9ffbd80a0b0cbeb00a8fab0b14be474a32b815609bb1f4bffa494_d.txt', 'azureml-logs/75_job_post-tvmps_6ad0f50cd79742bed158768f299d376ef743927df3983464d8dc993376693eb2_d.txt', 'azureml-logs/process_info.json', 'azureml-logs/process_status.json', 'logs/azureml/0_140_azureml.log', 'logs/azureml/1_119_azureml.log', 'logs/azureml/job_prep_azureml.log', 'logs/azureml/job_release_azureml.log', 'outputs/model.ckpt']\\n                See https://aka.ms/run-logging for more details.\"\n    }\n}",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModelPathNotFoundException\u001b[0m                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-67703e415f2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# モデル登録\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m run.register_model(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bert-livedoor-model\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'outputs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model.onnx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel_framework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFramework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mONNX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36mregister_model\u001b[0;34m(self, model_name, model_path, tags, properties, model_framework, model_framework_version, description, datasets, sample_input_dataset, sample_output_dataset, resource_configuration, **kwargs)\u001b[0m\n\u001b[1;32m   2191\u001b[0m         \"\"\"\n\u001b[1;32m   2192\u001b[0m         \u001b[0mmodel_name_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2193\u001b[0;31m         return self._client.register_model(\n\u001b[0m\u001b[1;32m   2194\u001b[0m             \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_framework\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_framework_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2195\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_input_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_input_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_run_impl/run_history_facade.py\u001b[0m in \u001b[0;36mregister_model\u001b[0;34m(self, model_name, model_path, tags, properties, model_framework, model_framework_version, asset_id, sample_input_dataset, sample_output_dataset, resource_configuration, **kwargs)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcloud_file_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0mrun_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martifacts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_file_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_origin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_container_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             raise ModelPathNotFoundException(\n\u001b[0m\u001b[1;32m    444\u001b[0m                 \"\"\"Could not locate the provided model_path {} in the set of files uploaded to the run: {}\n\u001b[1;32m    445\u001b[0m                 See https://aka.ms/run-logging for more details.\"\"\".format(model_path, str(run_files)))\n",
            "\u001b[0;31mModelPathNotFoundException\u001b[0m: ModelPathNotFoundException:\n\tMessage: Could not locate the provided model_path outputs/model.onnx in the set of files uploaded to the run: ['azureml-logs/55_azureml-execution-tvmps_0f93e9792dd9ffbd80a0b0cbeb00a8fab0b14be474a32b815609bb1f4bffa494_d.txt', 'azureml-logs/55_azureml-execution-tvmps_6ad0f50cd79742bed158768f299d376ef743927df3983464d8dc993376693eb2_d.txt', 'azureml-logs/65_job_prep-tvmps_0f93e9792dd9ffbd80a0b0cbeb00a8fab0b14be474a32b815609bb1f4bffa494_d.txt', 'azureml-logs/65_job_prep-tvmps_6ad0f50cd79742bed158768f299d376ef743927df3983464d8dc993376693eb2_d.txt', 'azureml-logs/70_driver_log_0.txt', 'azureml-logs/70_driver_log_1.txt', 'azureml-logs/70_mpi_log.txt', 'azureml-logs/75_job_post-tvmps_0f93e9792dd9ffbd80a0b0cbeb00a8fab0b14be474a32b815609bb1f4bffa494_d.txt', 'azureml-logs/75_job_post-tvmps_6ad0f50cd79742bed158768f299d376ef743927df3983464d8dc993376693eb2_d.txt', 'azureml-logs/process_info.json', 'azureml-logs/process_status.json', 'logs/azureml/0_140_azureml.log', 'logs/azureml/1_119_azureml.log', 'logs/azureml/job_prep_azureml.log', 'logs/azureml/job_release_azureml.log', 'outputs/model.ckpt']\n                See https://aka.ms/run-logging for more details.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Could not locate the provided model_path outputs/model.onnx in the set of files uploaded to the run: ['azureml-logs/55_azureml-execution-tvmps_0f93e9792dd9ffbd80a0b0cbeb00a8fab0b14be474a32b815609bb1f4bffa494_d.txt', 'azureml-logs/55_azureml-execution-tvmps_6ad0f50cd79742bed158768f299d376ef743927df3983464d8dc993376693eb2_d.txt', 'azureml-logs/65_job_prep-tvmps_0f93e9792dd9ffbd80a0b0cbeb00a8fab0b14be474a32b815609bb1f4bffa494_d.txt', 'azureml-logs/65_job_prep-tvmps_6ad0f50cd79742bed158768f299d376ef743927df3983464d8dc993376693eb2_d.txt', 'azureml-logs/70_driver_log_0.txt', 'azureml-logs/70_driver_log_1.txt', 'azureml-logs/70_mpi_log.txt', 'azureml-logs/75_job_post-tvmps_0f93e9792dd9ffbd80a0b0cbeb00a8fab0b14be474a32b815609bb1f4bffa494_d.txt', 'azureml-logs/75_job_post-tvmps_6ad0f50cd79742bed158768f299d376ef743927df3983464d8dc993376693eb2_d.txt', 'azureml-logs/process_info.json', 'azureml-logs/process_status.json', 'logs/azureml/0_140_azureml.log', 'logs/azureml/1_119_azureml.log', 'logs/azureml/job_prep_azureml.log', 'logs/azureml/job_release_azureml.log', 'outputs/model.ckpt']\\n                See https://aka.ms/run-logging for more details.\"\n    }\n}"
          ]
        }
      ],
      "source": [
        "# モデル登録\n",
        "run.register_model(\n",
        "    model_name=\"bert-livedoor-model\",\n",
        "    model_path=os.path.join('outputs', 'model.ckpt'),\n",
        "    model_framework=Model.Framework.PYTORCH,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
