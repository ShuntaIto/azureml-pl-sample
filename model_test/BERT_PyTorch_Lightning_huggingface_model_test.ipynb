{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0955a9e46ddbd40183737b0407937cba8340df4839a34630809b37eda4d8ebe94",
   "display_name": "Python 3.8.8 64-bit ('py38-pt180': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from transformers import BertJapaneseTokenizer\n",
    "from transformers import BertModel\n",
    "\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "from glob import glob\n",
    "import linecache\n",
    "from tqdm import tqdm\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_path = \"livedoor_news_corpus.tar.gz\"\n",
    "extract_path = \"livedoor/\"\n",
    "\n",
    "if not os.path.isfile(\"livedoor_news_corpus.tar.gz\"):\n",
    "    urllib.request.urlretrieve(\"https://www.rondhuit.com/download/ldcc-20140209.tar.gz\",download_path)\n",
    "\n",
    "with tarfile.open(download_path, \"r:gz\") as t:\n",
    "    t.extractall(extract_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               title      category\n",
       "0  NTTドコモ、MEDIAS PP N-01Dにて特定のブラウザを利用したときに不具合でソフト...          smax\n",
       "1       大切な投稿を見逃さない　Facebookに親友の投稿だけを表示する【知っ得！虎の巻】\\n  it-life-hack\n",
       "2  大画面スマホ時代はデジタル・ドクショが一気に快適に！大幅リニューアルで使える便利すぎる機能満...          smax\n",
       "3        おはこんこん、ふぉっくす紺子です！アキバで流れる動画が決まりました【紺子にゅうす】\\n  it-life-hack\n",
       "4     雑誌をPDF化してiPadで読む裏技！スキャナー活用のノウハウを伝授【新スタイル活用術】\\n  it-life-hack"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NTTドコモ、MEDIAS PP N-01Dにて特定のブラウザを利用したときに不具合でソフト...</td>\n      <td>smax</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>大切な投稿を見逃さない　Facebookに親友の投稿だけを表示する【知っ得！虎の巻】\\n</td>\n      <td>it-life-hack</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>大画面スマホ時代はデジタル・ドクショが一気に快適に！大幅リニューアルで使える便利すぎる機能満...</td>\n      <td>smax</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>おはこんこん、ふぉっくす紺子です！アキバで流れる動画が決まりました【紺子にゅうす】\\n</td>\n      <td>it-life-hack</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>雑誌をPDF化してiPadで読む裏技！スキャナー活用のノウハウを伝授【新スタイル活用術】\\n</td>\n      <td>it-life-hack</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "## https://qiita.com/m__k/items/841950a57a0d7ff05506\n",
    "\n",
    "categories = [name for name in os.listdir(extract_path + \"text\") if os.path.isdir(extract_path + \"text/\" + name)]\n",
    "\n",
    "datasets = pd.DataFrame(columns=[\"title\", \"category\"])\n",
    "for cat in categories:\n",
    "    path = extract_path + \"text/\" + cat + \"/*.txt\"\n",
    "    files = glob(path)\n",
    "    for text_name in files:\n",
    "        title = linecache.getline(text_name, 3)\n",
    "        s = pd.Series([title, cat], index=datasets.columns)\n",
    "        datasets = datasets.append(s, ignore_index=True)\n",
    "\n",
    "datasets = datasets.sample(frac=1).reset_index(drop=True)\n",
    "datasets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               title  category_id\n",
       "0  NTTドコモ、MEDIAS PP N-01Dにて特定のブラウザを利用したときに不具合でソフト...            0\n",
       "1       大切な投稿を見逃さない　Facebookに親友の投稿だけを表示する【知っ得！虎の巻】\\n            2\n",
       "2  大画面スマホ時代はデジタル・ドクショが一気に快適に！大幅リニューアルで使える便利すぎる機能満...            0\n",
       "3        おはこんこん、ふぉっくす紺子です！アキバで流れる動画が決まりました【紺子にゅうす】\\n            2\n",
       "4     雑誌をPDF化してiPadで読む裏技！スキャナー活用のノウハウを伝授【新スタイル活用術】\\n            2"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>category_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NTTドコモ、MEDIAS PP N-01Dにて特定のブラウザを利用したときに不具合でソフト...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>大切な投稿を見逃さない　Facebookに親友の投稿だけを表示する【知っ得！虎の巻】\\n</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>大画面スマホ時代はデジタル・ドクショが一気に快適に！大幅リニューアルで使える便利すぎる機能満...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>おはこんこん、ふぉっくす紺子です！アキバで流れる動画が決まりました【紺子にゅうす】\\n</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>雑誌をPDF化してiPadで読む裏技！スキャナー活用のノウハウを伝授【新スタイル活用術】\\n</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "## https://qiita.com/m__k/items/e312ddcf9a3d0ea64d72\n",
    "\n",
    "categories = list(set(datasets['category']))\n",
    "id2cat = dict(zip(list(range(len(categories))), categories))\n",
    "cat2id = dict(zip(categories, list(range(len(categories)))))\n",
    "\n",
    "datasets['category_id'] = datasets['category'].map(cat2id)\n",
    "datasets = datasets[['title', 'category_id']]\n",
    "\n",
    "datasets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[2, 1325, 9, 12453, 2992, 8, 3]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "tokenizer.encode(\"私は元気です。\",padding=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LivedoorDatasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, transform = None):\n",
    "        self.transform = transform\n",
    "\n",
    "        self.data = list(datasets[\"title\"])\n",
    "        self.label = list(datasets[\"category_id\"])\n",
    "        \n",
    "        if not len(self.data) == len(self.label):\n",
    "            raise ValueError(\"Invalid dataset\")\n",
    "        self.datanum = len(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        out_data = self.data[idx]\n",
    "        out_label = self.label[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            out_data = self.transform([\"input_ids\"][0])\n",
    "\n",
    "        return out_data, out_label   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "livedoor_datasets = LivedoorDatasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7376\n7376\n"
     ]
    }
   ],
   "source": [
    "print(len(list(datasets[\"category_id\"])))\n",
    "print(len(list(datasets[\"title\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('NTTドコモ、MEDIAS PP N-01Dにて特定のブラウザを利用したときに不具合でソフトウェア更新を提供開始\\n', 0)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "livedoor_datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizerCollate:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        input = [item[0] for item in batch]\n",
    "        input = self.tokenizer(\n",
    "            input,\n",
    "            padding=True,\n",
    "            max_length=512,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\")\n",
    "        targets = torch.tensor([item[1] for item in batch])\n",
    "        return input, targets\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        return self.collate_fn(batch)\n",
    "\n",
    "train_loader = DataLoader(livedoor_datasets, batch_size=16, collate_fn=TokenizerCollate(tokenizer=tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
    "        self.output = nn.Linear(768, 9)\n",
    "        \n",
    "        self.train_acc = pl.metrics.Accuracy()\n",
    "        self.val_acc = pl.metrics.Accuracy()\n",
    "        self.test_acc = pl.metrics.Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.bert(**x).last_hidden_state\n",
    "        ## cls token相当部分のhidden_stateのみ抜粋\n",
    "        y = y[:,0,:]\n",
    "        y = y.view(-1, 768)\n",
    "        y = self.output(y)\n",
    "        return y\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, t = batch\n",
    "        y = self(x)\n",
    "        loss = F.cross_entropy(y, t)\n",
    "        self.log(\"loss\", loss, prog_bar=True, logger=True, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_nb): \n",
    "        x, t = batch\n",
    "        y = self(x)\n",
    "        loss = F.cross_entropy(y, t)\n",
    "        preds = torch.argmax(y, dim=1)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', self.val_acc(y,t), prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_nb):\n",
    "        return self.validation_step(batch, batch_nb)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1,max_epochs=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/anaconda/envs/py38-pt180/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | bert      | BertModel | 110 M \n",
      "1 | output    | Linear    | 6.9 K \n",
      "2 | train_acc | Accuracy  | 0     \n",
      "3 | val_acc   | Accuracy  | 0     \n",
      "4 | test_acc  | Accuracy  | 0     \n",
      "----------------------------------------\n",
      "6.9 K     Trainable params\n",
      "110 M     Non-trainable params\n",
      "110 M     Total params\n",
      "442.497   Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validation sanity check: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "860c88cebdc548a6978679c204d67cfd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/anaconda/envs/py38-pt180/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3977a56d35b24dd4b4fbc49e05898f4d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "trainer.fit(model, train_loader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_loader:\n",
    "    print(i[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}